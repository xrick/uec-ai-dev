{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369d21d4-2c2f-4ebf-b987-d28aef031497",
   "metadata": {},
   "source": [
    "## QAT過程問題集\n",
    "- can't convert float NaN (actually 0.00000) to int:\n",
    "  - 與weight-decay設定值可能有關，設定太大倒導致錯誤。\n",
    "  - 可能是同時開啟三個訓練程式造成記憶體不足造成。\n",
    "- 訓練時必需要用cpu不能用cuda，原因是qnnpack不支援。\n",
    "- 若出現labels values error，可能是因為載入的batch size超過記憶體，將batch size降低即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d582be4b-1b35-4dfc-a20d-b68077cb88b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import random;\n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d3cae9-1208-4e00-bbcf-b7b5c2f91304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "737226ae-820b-4739-ab00-755bfe323ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b701027a-c7e0-4908-8d3b-6c8cdf91746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.opts as opts;\n",
    "import common.utils as U;\n",
    "# import th.resources.models as models;\n",
    "import th.resources.no_softmax_quant_model as models;\n",
    "import th.resources.calculator as calc;\n",
    "from SharedLibs.datestring import getDateStr, genDataTimeStr;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55848bf9-571e-4995-bba6-c85fd888664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d9d813-5a9d-4595-a25b-b0fcef8f351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "from tinynn.converter import TFLiteConverter\n",
    "from tinynn.graph.quantization.quantizer import PostQuantizer\n",
    "from tinynn.graph.tracer import model_tracer\n",
    "from tinynn.util.train_util import DLContext, get_device\n",
    "from tinynn.graph.quantization.algorithm.cross_layer_equalization import cross_layer_equalize\n",
    "from tinynn.converter import TFLiteConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cce7e38-1de4-4782-9a3e-6a1fc3cad987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref site:https://discuss.pytorch.org/t/how-to-generate-a-fully-quantized-model/175185\n",
    "# from torch.ao.quantization.backend_config import BackendConfig, BackendPatternConfig, DTypeConfig, ObservationType\n",
    "# from torch.quantization import quantize_fx\n",
    "# from torch.ao.quantization import QConfigMapping\n",
    "# from torch.ao.quantization.fx.custom_config import PrepareCustomConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aa078a1-193d-419e-a154-eb69dd598cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aeb4481-8d39-4ed5-b432-d04802e4ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask8 = 0x4000 # >> 8 : 16384\n",
    "mask7 = 0x2000 # >> 7 :  8192\n",
    "mask6 = 0x1000 # >> 6 :  4096\n",
    "mask5 = 0x0800 # >> 5 :  2048\n",
    "mask4 = 0x0400 # >> 4 :  1024\n",
    "mask3 = 0x0200 # >> 3 :   512\n",
    "mask2 = 0x0100 # >> 2 :   256\n",
    "mask1 = 0x0080 # >> 1 :   128\n",
    "mask0 = 0x0040 # >> 0 :    64 below the value, drop the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbce076-92c6-4b5e-97cc-a76f874c6539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70785c76-3485-48fd-b052-f33ea13876c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskOP(x):\n",
    "    x = np.int16(x)\n",
    "    # print(f\"begin:x:{x}\")\n",
    "    if (mask8&x):\n",
    "        return x >> 8\n",
    "    elif (mask7&x):\n",
    "        return x >> 7\n",
    "    elif (mask6&x):\n",
    "        return x >> 6\n",
    "    elif (mask5&x):\n",
    "        return x >> 5\n",
    "    elif (mask4&x):\n",
    "        return x >> 4\n",
    "    elif (mask3&x):\n",
    "        return x >> 3\n",
    "    elif (mask2&x):\n",
    "        return x >> 2\n",
    "    elif (mask1&x):\n",
    "        return x >> 1\n",
    "    elif (mask0&x):\n",
    "        return x\n",
    "    else:\n",
    "        return 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa9d71f-76e1-43c0-bf2f-a278115274db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_int8(x, axis):\n",
    "    len_of_x = len(x[0][0][0])\n",
    "    print(f\"len_of_x:{len_of_x}\")\n",
    "    for i in range(len_of_x):\n",
    "        nflag = 2; #positive\n",
    "        print(\"{}:{}\".format(i,x[0][0][0][i]))\n",
    "        tmp_x = x[0][0][0][i]\n",
    "        if tmp_x < 0:\n",
    "            tmp_x = np.abs(tmp_x)\n",
    "            nflag = 1\n",
    "        tmp_x = maskOP(tmp_x)\n",
    "        if(nflag==1):\n",
    "            tmp_x = -1 * (tmp_x)\n",
    "        print(\"{}:{}\".format(i,x[0][0][0][i]))\n",
    "        print(\"*********************************\")\n",
    "        x[0][0][0][i] = tmp_x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85b1c0f-4596-4d69-bc5d-94af3243dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('71',3),('99',4)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess_setup_without_normalization(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength)\n",
    "                  ]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f89d02-367f-4058-addf-3b9befa7988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(\"../../../../uec_iot_models_datasets/version11/single_fold_train_20240603063535.npz\", allow_pickle=True);#office\n",
    "    dataset = np.load(\"../../../../uec_iot_ai_models_datasets/generated_datasets/train/version11/single_fold_train_20240603063535.npz\", allow_pickle=True);#home\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de21f9-4fcd-4f11-8110-a78aedfeea20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6ab99b-1937-49d1-a1e9-7cf45adfa155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    \"\"\"\n",
    "   \n",
    "    \"\"\"\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 64;\n",
    "    opt.weightDecay = 5e-4;\n",
    "    opt.LR = 0.1;\n",
    "    opt.momentum = 0.9;\n",
    "    opt.nEpochs = 1600;#2000;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 4#50;\n",
    "    opt.nFolds = 1;#5;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    # opt.ch_config = [8,64,32,64,64,128,128,256,256,512,512,2];\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "207352a5-4f18-4809-9215-7eb4fbd16c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_info(opt):\n",
    "    print('+------------------------------+');\n",
    "    print('| {} Sound classification'.format(opt.netType));\n",
    "    print('+------------------------------+');\n",
    "    print('| dataset  : {}'.format(opt.dataset));\n",
    "    print('| nEpochs  : {}'.format(opt.nEpochs));\n",
    "    print('| LRInit   : {}'.format(opt.LR));\n",
    "    print('| schedule : {}'.format(opt.schedule));\n",
    "    print('| warmup   : {}'.format(opt.warmup));\n",
    "    print('| batchSize: {}'.format(opt.batchSize));\n",
    "    print('| nFolds: {}'.format(opt.nFolds));\n",
    "    print('| Splits: {}'.format(opt.splits));\n",
    "    print('| Device: {}'.format(opt.device));\n",
    "    print('| Model Path: {}'.format(opt.model_path));\n",
    "    print('| Model Name: {}'.format(opt.model_name));\n",
    "    print('+------------------------------+');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce696bd8-42c8-4408-9d39-8fe42665011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QATTrainer:\n",
    "    def __init__(self, opt=None, split=0):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.trainX = None;\n",
    "        self.trainY = None;\n",
    "        # self.opt.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.opt.device = torch.device(\"cpu\")\n",
    "        self.trainGen = getTrainGen(self.opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.qunt_nClass = opt.nClasses;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "\n",
    "    def load_train_data(self):\n",
    "        print('Preparing calibration dataset..');\n",
    "        x,y = self.trainGen.__getitem__(0);\n",
    "        self.trainX = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "        \"\"\"\n",
    "        trainX size:torch.Size([1, 1, 30225]), but must be [1,1,1,30225]\n",
    "        Due to the reason: raise ValueError(\"Input shape must be `(N, C, H, W)`!\")\n",
    "        \"\"\"\n",
    "        # print(f\"trainX[0] shape:{self.trainX[0].shape}\")\n",
    "        self.trainY = torch.tensor(y).to(self.opt.device);\n",
    "        print('Calibration dataset is ready');\n",
    "        # self.opt.batchSize = 32;\n",
    "\n",
    "    # def load_test_data(self):\n",
    "    #     if(self.testX is None):\n",
    "    #         data = np.load('../../datasets/CurrentUse/forOneClassModel_alarm/test_val/final_val_test_npz/final_valSet_20240119004614.npz', allow_pickle=True);\n",
    "    #         dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "    #         self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "    #         self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "\n",
    "    def load_test_data(self):\n",
    "        # testData = '../../../../uec_iot_models_datasets/version11/final_single_val_20240603063755.npz';#office\n",
    "        testData = '../../../../uec_iot_ai_models_datasets/generated_datasets/val/version11/final_single_val_20240603063755.npz';#home\n",
    "        data = np.load(testData, allow_pickle=True);\n",
    "        print(f\"device is :{self.opt.device}\")\n",
    "        print(f\"len of Y:{len(data['y'])}\")\n",
    "        # self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "        dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "        self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "        self.testY = torch.tensor(data['y']).type(torch.float32).to(self.opt.device);\n",
    "\n",
    "    def __validate_test(self, net, qat_done, testX, testY):\n",
    "        net.eval();\n",
    "        # if qat_done:\n",
    "        #     testX.to('cpu');\n",
    "        #     testY.to('cpu');\n",
    "        # else:\n",
    "        #     testX.to('cuda:0');\n",
    "        #     testY.to('cuda:0');\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = len(self.testX);\n",
    "            x = self.testX[:];\n",
    "            scores = net(x);\n",
    "            y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "            acc = self.__compute_accuracy_2(y_pred, self.testY);\n",
    "        return acc;\n",
    "\n",
    "    \n",
    "    def __validate(self, net, lossFunc):\n",
    "        if self.testX is None:\n",
    "            self.load_test_data();\n",
    "        net.eval();\n",
    "        acc=0.0; \n",
    "        loss = 0.0;\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = len(self.testX);#(self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            x = self.testX[:];\n",
    "            try:\n",
    "                scores = net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "                acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "            except ValueError:\n",
    "                print(f\"error data:{x}\")\n",
    "        net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy_2(self, y_pred, y_target):\n",
    "        print(y_pred.shape);\n",
    "        with torch.no_grad():\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1);\n",
    "\n",
    "            y_pred = y_pred.argmax(dim=1);\n",
    "            y_target = y_target.argmax(dim=1);\n",
    "\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "        return acc;\n",
    "        \n",
    "\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        print(f\"shape of y_pred:{y_pred.shape}\");\n",
    "        print(f\"shape of y_target:{y_target.shape}\");\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            if self.opt.nCrops == 1:\n",
    "                y_pred = y_pred.argmax(dim=1);\n",
    "                y_target = y_target.argmax(dim=1);\n",
    "            else:\n",
    "                y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                print(f\"after: len of y_pred:{len(y_pred)}, len of y_target:{len(y_target)}\")\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "        \n",
    "\n",
    "    def __load_model(self, quant=True):\n",
    "        state = torch.load(self.opt.model_path, map_location=self.opt.device);\n",
    "        print(state['config']);\n",
    "        net = None;\n",
    "        net = models.GetACDNetQuantModel(input_len=self.opt.inputLength, nclass=self.qunt_nClass, sr=self.opt.sr, channel_config=state['config']).to(self.opt.device);\n",
    "        calc.summary(net, (1,1,self.opt.inputLength));\n",
    "        net.load_state_dict(state['weight']);\n",
    "        return net;\n",
    "\n",
    "    \n",
    "    def __train(self, net):\n",
    "        self.load_train_data();\n",
    "        # net.eval();\n",
    "        # calc.summary(net, (1,1,self.opt.inputLength));\n",
    "        lossFunc = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True);\n",
    "        train_start_time = time.time();\n",
    "        for epochIdx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epochIdx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            for batchIdx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batchIdx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "                y = torch.tensor(y).to(self.opt.device);\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                try:\n",
    "                    outputs = torch.softmax(input=net(x),dim=1); #need to check float NaN value?\n",
    "                    running_acc += (((outputs.data.argmax(dim=1) == y.argmax(dim=1))*1).float().mean()).item();\n",
    "                    loss = lossFunc(outputs.log(), y);\n",
    "                    loss.backward();\n",
    "                    optimizer.step();\n",
    "                    running_loss += loss.item();\n",
    "                except ValueError:\n",
    "                    print(f\"error label:{y}\")\n",
    "                    print(f\"error data:{x}\")\n",
    "                    continue\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, lossFunc);\n",
    "            #Save best model\n",
    "            self.__chk_bestAcc(val_acc, epochIdx, net);\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epochIdx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - train_start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "\n",
    "    def __chk_bestAcc(self, acc, epochIdx, net):\n",
    "        print(\"__chk_bestAcc is called\")\n",
    "        print(f\"current best Acc is {self.bestAcc}\")\n",
    "        print(f\"pass in acc is {acc}\")\n",
    "        if acc > self.bestAcc:\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            print(f\"model saved....., acc: {acc}\")\n",
    "            \n",
    "    def __on_epoch_end(self, start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        line = 'SP-{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.splits, epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "        \n",
    "    \n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __get_batch(self, index):\n",
    "        x = self.trainX[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        y = self.trainY[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        return x.to(self.opt.device), y.to(self.opt.device);\n",
    "    \n",
    "    \n",
    "    def __calibrate(self, net):\n",
    "        self.load_train_data();\n",
    "        net.eval();\n",
    "        with torch.no_grad():\n",
    "            for i in range(1,2):\n",
    "                x_pred = None;\n",
    "                for idx in range(math.ceil(len(self.trainX)/self.opt.batchSize)):\n",
    "                    x = self.trainX[idx*self.opt.batchSize : (idx+1)*self.opt.batchSize];\n",
    "                    scores = net(x);\n",
    "                    x_pred = scores.data if x_pred is None else torch.cat((x_pred, scores.data));\n",
    "                x_pred = x_pred.argmax(dim=1);\n",
    "                x_target = self.trainY.argmax(dim=1);\n",
    "                acc = (((x_pred==x_target)*1).float().mean()*100).item();\n",
    "                print('calibrate accuracy is: {:.2f}'.format(acc));\n",
    "        return acc;\n",
    "\n",
    "    def QuantizeModel(self):\n",
    "        net = self.__load_model(True);\n",
    "        # net = self.__load_model(False);\n",
    "        config = net.ch_config;\n",
    "        net.eval();\n",
    "        \n",
    "        #Fuse modules to\n",
    "        torch.quantization.fuse_modules(net.sfeb, ['0','1','2'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.sfeb, ['3','4','5'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['0','1','2'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['4','5','6'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['7','8','9'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['11','12','13'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['14','15','16'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['18','19','20'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['21','22','23'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['25','26','27'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['28','29','30'], inplace=True);\n",
    "        torch.quantization.fuse_modules(net.tfeb, ['33','34','35'], inplace=True);\n",
    "\n",
    "        net.train();\n",
    "        net.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "        torch.backends.quantized.engine = 'qnnpack';\n",
    "        print(f\"net.qconfig : {net.qconfig}\");\n",
    "        torch.quantization.prepare_qat(net, inplace=True);\n",
    "        \n",
    "        # Calibrate with the training data\n",
    "        # self.__calibrate(net);\n",
    "        self.__train(net);\n",
    "\n",
    "        #place trained model to cpu\n",
    "        net.to('cpu');\n",
    "        # Convert to quantized model\n",
    "        torch.quantization.convert(net, inplace=True);\n",
    "        print('Post Training Quantization: Convert done');\n",
    "\n",
    "        print(\"Size of model after quantization\");\n",
    "        torch.save(net.state_dict(), \"temp.p\")\n",
    "        print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "        os.remove('temp.p')\n",
    "\n",
    "        self.load_test_data();\n",
    "        val_acc = self.__validate_test(net, True, self.testX, self.testY);\n",
    "        print('Testing: Acc(top1) {:.2f}%'.format(val_acc));\n",
    "        net.to('cpu');\n",
    "        # torch.jit.save(torch.jit.script(net), '{}/th/quantized_models/{}.pt'.format(os.getcwd(), self.opt.model_name.format()));\n",
    "        torch.jit.save(torch.jit.script(net), '../../../trained_models/step_6_QAT_and_Convert2TFLite/{}.pt'.format(self.opt.model_name));\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, '../../../trained_models/step_6_QAT_and_Convert2TFLite/uncompressed_qat_models/uncompress_{}.pt'.format(self.opt.model_name));\n",
    "        \n",
    "        # **************convert to tflite**********\n",
    "        with torch.no_grad():\n",
    "            # dummy_input = torch.randn(1, 1, 30225, 1); wrong: RuntimeError: quantized::conv2d (qnnpack): each dimension of output tensor should be greater than 0.\n",
    "            dummy_input = torch.FloatTensor(quantize_int8(torch.randn(1, 1, 1, 30225).numpy(),3)); #correct,workable\n",
    "            # dummy_input = torch.FloatTensor(maskOP((torch.randn(1, 1, 1, 30225).numpy(),3))); #correct,workable\n",
    "            # dummy_input = torch.randn(30225,1,1,1); wrong: RuntimeError: quantized::conv2d (qnnpack): each dimension of output tensor should be greater than 0.\n",
    "            # dummy_input = torch.randn(1,30225,1,1); wrong:RuntimeError: Input channel size of weight and bias must match.\n",
    "            #the followng setting for TFLiteConverter, especially quantize_input_output_type='int8',fuse_quant_dequant=True,\n",
    "            #we need to remove softmax layer from ACDQuantModel to satisfy the output is int8 type\n",
    "            converter = TFLiteConverter(net,\n",
    "                                        dummy_input,\n",
    "                                        quantize_input_output_type='int8',#設定此欄，輸入會強制為int8\n",
    "                                        fuse_quant_dequant=True,\n",
    "                                        quantize_target_type='int8',\n",
    "                                        hybrid_conv=False,\n",
    "                                        float16_quantization=True,\n",
    "                                        optimize=5,\n",
    "                                        tflite_path=\"../../../trained_models/step_6_QAT_and_Convert2TFLite/{}.tflite\".format(self.opt.model_name))\n",
    "            converter.convert()\n",
    "\n",
    "        \n",
    "    def TestModel(self, quant=False):\n",
    "        if quant:\n",
    "            print(f\"the model name:{self.opt.model_name}\");\n",
    "            net = torch.jit.load('../../../trained_models/step_6_QAT_and_Convert2TFLite/{}.pt'.format(self.opt.model_name))\n",
    "        else:\n",
    "            print(\"has not quanted, load unquanted model...\");\n",
    "            net = self.__load_model();\n",
    "            # calc.summary(net, (1,1,self.opt.inputLength));\n",
    "        self.load_test_data();\n",
    "        net.eval();\n",
    "        val_acc = self.__validate_test(net, False, self.testX, self.testY);\n",
    "        print('Testing: Acc(top1) {:.2f}%'.format(val_acc));\n",
    "\n",
    "    def GetModelSize(self):\n",
    "        orig_net_path = self.opt.model_path;\n",
    "        print('Full precision model size (KB):', os.path.getsize(orig_net_path)/(1024));\n",
    "        save_onnx_name = \"../../../trained_models/step_6_QAT_and_Convert2TFLite/{}.onnx\".format(self.opt.model_name);\n",
    "        quant_net_path = \"../has_qat_models/onnx_models/\"+save_onnx_name;\n",
    "        print('Quantized model size (KB):', os.path.getsize(quant_net_path)/(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d22c1a-75b7-49c1-855f-7021a5ad68b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : 87.46\\nepoch: \\nself.opt.LR = 0.1;\\nopt.momentum = 0.09;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n===================================\\n#this is bad settings\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nopt.batchSize = 128;\\nopt.weightDecay = 5e-4;\\nopt.LR = 0.5;\\nopt.momentum = 0.9;\\nopt.nEpochs = 1000;#2000;\\nopt.schedule = [0.6, 0.8, 0.9];\\nopt.warmup = 10;\\n===================================\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nopt.batchSize = 128;\\nopt.weightDecay = 5e-3;\\nopt.LR = 0.1;\\nopt.momentum = 0.9;\\nopt.nEpochs = 600;#2000;\\nopt.schedule = [0.6, 0.8, 0.9];\\nopt.warmup = 10;\\n############################################Training DataSet Version 4##########################\\n============================\\nopt.batchSize = 64;\\nopt.weightDecay = 5e-4;\\nopt.LR = 0.05;\\nopt.momentum = 0.9;\\nopt.nEpochs = 800;#2000;\\nopt.schedule = [0.1, 0.8, 0.9];\\nopt.warmup = 10;\\n===========================\\nno use\\nopt.batchSize = 128;\\nopt.weightDecay = 5e-4;\\nopt.LR = 0.5;\\nopt.momentum = 0.5;\\nopt.nEpochs = 800;#2000;\\nopt.schedule = [0.3, 0.6\\n==========================\\npruning ration : 0.85\\nfinal accuracy : \\nepoch:\\ntest acc:\\nopt.batchSize = 128;\\nopt.weightDecay = 5e-3;\\nopt.LR = 0.1;\\nopt.momentum = 0.09;\\nopt.nEpochs = 800;#2000;\\nopt.schedule = [0.3, 0.6, 0.9];\\nopt.warmup = 10;\\n==========================dataset v11\\npruning ration : 0.85\\nfinal accuracy: train: val:\\nepoch:\\ntest acc:\\nopt.batchSize = 64;\\nopt.weightDecay = 5e-4;\\nopt.LR = 0.1;\\nopt.momentum = 0.9;\\nopt.nEpochs = 1600;#2000;\\nopt.schedule = [0.3, 0.6, 0.9];\\nopt.warmup = 10;\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : 87.46\n",
    "epoch: \n",
    "self.opt.LR = 0.1;\n",
    "opt.momentum = 0.09;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "===================================\n",
    "#this is bad settings\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "opt.batchSize = 128;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.LR = 0.5;\n",
    "opt.momentum = 0.9;\n",
    "opt.nEpochs = 1000;#2000;\n",
    "opt.schedule = [0.6, 0.8, 0.9];\n",
    "opt.warmup = 10;\n",
    "===================================\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "opt.batchSize = 128;\n",
    "opt.weightDecay = 5e-3;\n",
    "opt.LR = 0.1;\n",
    "opt.momentum = 0.9;\n",
    "opt.nEpochs = 600;#2000;\n",
    "opt.schedule = [0.6, 0.8, 0.9];\n",
    "opt.warmup = 10;\n",
    "############################################Training DataSet Version 4##########################\n",
    "============================\n",
    "opt.batchSize = 64;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.LR = 0.05;\n",
    "opt.momentum = 0.9;\n",
    "opt.nEpochs = 800;#2000;\n",
    "opt.schedule = [0.1, 0.8, 0.9];\n",
    "opt.warmup = 10;\n",
    "===========================\n",
    "no use\n",
    "opt.batchSize = 128;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.LR = 0.5;\n",
    "opt.momentum = 0.5;\n",
    "opt.nEpochs = 800;#2000;\n",
    "opt.schedule = [0.3, 0.6\n",
    "==========================\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch:\n",
    "test acc:\n",
    "opt.batchSize = 128;\n",
    "opt.weightDecay = 5e-3;\n",
    "opt.LR = 0.1;\n",
    "opt.momentum = 0.09;\n",
    "opt.nEpochs = 800;#2000;\n",
    "opt.schedule = [0.3, 0.6, 0.9];\n",
    "opt.warmup = 10;\n",
    "==========================dataset v11\n",
    "pruning ration : 0.85\n",
    "final accuracy: train: val:\n",
    "epoch:\n",
    "test acc:\n",
    "opt.batchSize = 64;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.LR = 0.1;\n",
    "opt.momentum = 0.9;\n",
    "opt.nEpochs = 1600;#2000;\n",
    "opt.schedule = [0.3, 0.6, 0.9];\n",
    "opt.warmup = 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b75e728-df29-4468-ae40-06defe6836b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts();#opts.parse();\n",
    "    opt.device = 'cpu';\n",
    "    opt.saveInfo = \"uec4C_val94.2_tr_82.9_epoch995_prunInfo_0.8_0.85_ds_ver11\"\n",
    "    opt.model_path = \"../../../trained_models/step_5_retrain_after_step_4/retrain_4C_after_2nd_pruning_prunratio0.85_2024060419/retrained_4Cmodel_ratio85.0_vaacc93.96134948730469_tracc_84.70394736842105@922epoch_20240604234410.pt\"\n",
    "    timeStr = genDataTimeStr();\n",
    "    opt.model_name = \"qat_model_{}_{}\".format(opt.saveInfo,timeStr);\n",
    "   \n",
    "    opt.split = 1;\n",
    "    opt.hasQuated = False;\n",
    "    display_info(opt);\n",
    "    trainer = QATTrainer(opt);\n",
    "\n",
    "    print('Testing performance of the provided model.....');\n",
    "    trainer.TestModel();\n",
    "\n",
    "    print('Quantization process is started.....');\n",
    "    trainer.QuantizeModel();\n",
    "    print('Quantization done');\n",
    "\n",
    "    print('Testing quantized model.');\n",
    "    trainer.TestModel(True);\n",
    "    print('Finished');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76313483-5605-4e87-97aa-30d3ca9e1a8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "| TLACDNet Sound classification\n",
      "+------------------------------+\n",
      "| dataset  : uec_iot\n",
      "| nEpochs  : 1600\n",
      "| LRInit   : 0.1\n",
      "| schedule : [0.3, 0.6, 0.9]\n",
      "| warmup   : 10\n",
      "| batchSize: 64\n",
      "| nFolds: 1\n",
      "| Splits: [1]\n",
      "| Device: cpu\n",
      "| Model Path: ../../../trained_models/step_5_retrain_after_step_4/retrain_4C_after_2nd_pruning_prunratio0.85_2024060419/retrained_4Cmodel_ratio85.0_vaacc93.96134948730469_tracc_84.70394736842105@922epoch_20240604234410.pt\n",
      "| Model Name: qat_model_uec4C_val94.2_tr_82.9_epoch995_prunInfo_0.8_0.85_ds_ver11_20240606135410\n",
      "+------------------------------+\n",
      "length of samples:1205\n",
      "Testing performance of the provided model.....\n",
      "has not quanted, load unquanted model...\n",
      "[8, 32, 13, 25, 28, 32, 34, 36, 34, 28, 32, 4]\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (32, 1, 7553)      1,280    9,667,840\n",
      "  BatchNorm2d-5     (32, 1, 7553)     (32, 1, 7553)         64            0\n",
      "         ReLu-6     (32, 1, 7553)     (32, 1, 7553)          0      241,696\n",
      "    MaxPool2d-7     (32, 1, 7553)      (32, 1, 151)          0      241,600\n",
      "      Permute-8      (32, 1, 151)      (1, 32, 151)          0            0\n",
      "       Conv2d-9      (1, 32, 151)     (13, 32, 151)        117      565,344\n",
      " BatchNorm2d-10     (13, 32, 151)     (13, 32, 151)         26            0\n",
      "        ReLu-11     (13, 32, 151)     (13, 32, 151)          0       62,816\n",
      "   MaxPool2d-12     (13, 32, 151)      (13, 16, 75)          0       62,400\n",
      "      Conv2d-13      (13, 16, 75)      (25, 16, 75)      2,925    3,510,000\n",
      " BatchNorm2d-14      (25, 16, 75)      (25, 16, 75)         50            0\n",
      "        ReLu-15      (25, 16, 75)      (25, 16, 75)          0       30,000\n",
      "      Conv2d-16      (25, 16, 75)      (28, 16, 75)      6,300    7,560,000\n",
      " BatchNorm2d-17      (28, 16, 75)      (28, 16, 75)         56            0\n",
      "        ReLu-18      (28, 16, 75)      (28, 16, 75)          0       33,600\n",
      "   MaxPool2d-19      (28, 16, 75)       (28, 8, 37)          0       33,152\n",
      "      Conv2d-20       (28, 8, 37)       (32, 8, 37)      8,064    2,386,944\n",
      " BatchNorm2d-21       (32, 8, 37)       (32, 8, 37)         64            0\n",
      "        ReLu-22       (32, 8, 37)       (32, 8, 37)          0        9,472\n",
      "      Conv2d-23       (32, 8, 37)       (34, 8, 37)      9,792    2,898,432\n",
      " BatchNorm2d-24       (34, 8, 37)       (34, 8, 37)         68            0\n",
      "        ReLu-25       (34, 8, 37)       (34, 8, 37)          0       10,064\n",
      "   MaxPool2d-26       (34, 8, 37)       (34, 4, 18)          0        9,792\n",
      "      Conv2d-27       (34, 4, 18)       (36, 4, 18)     11,016      793,152\n",
      " BatchNorm2d-28       (36, 4, 18)       (36, 4, 18)         72            0\n",
      "        ReLu-29       (36, 4, 18)       (36, 4, 18)          0        2,592\n",
      "      Conv2d-30       (36, 4, 18)       (34, 4, 18)     11,016      793,152\n",
      " BatchNorm2d-31       (34, 4, 18)       (34, 4, 18)         68            0\n",
      "        ReLu-32       (34, 4, 18)       (34, 4, 18)          0        2,448\n",
      "   MaxPool2d-33       (34, 4, 18)        (34, 2, 9)          0        2,448\n",
      "      Conv2d-34        (34, 2, 9)        (28, 2, 9)      8,568      154,224\n",
      " BatchNorm2d-35        (28, 2, 9)        (28, 2, 9)         56            0\n",
      "        ReLu-36        (28, 2, 9)        (28, 2, 9)          0          504\n",
      "      Conv2d-37        (28, 2, 9)        (32, 2, 9)      8,064      145,152\n",
      " BatchNorm2d-38        (32, 2, 9)        (32, 2, 9)         64            0\n",
      "        ReLu-39        (32, 2, 9)        (32, 2, 9)          0          576\n",
      "   MaxPool2d-40        (32, 2, 9)        (32, 1, 4)          0          512\n",
      "      Conv2d-41        (32, 1, 4)         (4, 1, 4)        128          512\n",
      " BatchNorm2d-42         (4, 1, 4)         (4, 1, 4)          8            0\n",
      "        ReLu-43         (4, 1, 4)         (4, 1, 4)          0           16\n",
      "   AvgPool2d-44         (4, 1, 4)         (4, 1, 1)          0           16\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 67,974\n",
      "Total FLOPs : 30,427,200\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 0.26\n",
      "Total size (MB) : 0.37\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "device is :cpu\n",
      "len of Y:828\n",
      "torch.Size([828, 4])\n",
      "Testing: Acc(top1) 93.96%\n",
      "Quantization process is started.....\n",
      "[8, 32, 13, 25, 28, 32, 34, 36, 34, 28, 32, 4]\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (32, 1, 7553)      1,280    9,667,840\n",
      "  BatchNorm2d-5     (32, 1, 7553)     (32, 1, 7553)         64            0\n",
      "         ReLu-6     (32, 1, 7553)     (32, 1, 7553)          0      241,696\n",
      "    MaxPool2d-7     (32, 1, 7553)      (32, 1, 151)          0      241,600\n",
      "      Permute-8      (32, 1, 151)      (1, 32, 151)          0            0\n",
      "       Conv2d-9      (1, 32, 151)     (13, 32, 151)        117      565,344\n",
      " BatchNorm2d-10     (13, 32, 151)     (13, 32, 151)         26            0\n",
      "        ReLu-11     (13, 32, 151)     (13, 32, 151)          0       62,816\n",
      "   MaxPool2d-12     (13, 32, 151)      (13, 16, 75)          0       62,400\n",
      "      Conv2d-13      (13, 16, 75)      (25, 16, 75)      2,925    3,510,000\n",
      " BatchNorm2d-14      (25, 16, 75)      (25, 16, 75)         50            0\n",
      "        ReLu-15      (25, 16, 75)      (25, 16, 75)          0       30,000\n",
      "      Conv2d-16      (25, 16, 75)      (28, 16, 75)      6,300    7,560,000\n",
      " BatchNorm2d-17      (28, 16, 75)      (28, 16, 75)         56            0\n",
      "        ReLu-18      (28, 16, 75)      (28, 16, 75)          0       33,600\n",
      "   MaxPool2d-19      (28, 16, 75)       (28, 8, 37)          0       33,152\n",
      "      Conv2d-20       (28, 8, 37)       (32, 8, 37)      8,064    2,386,944\n",
      " BatchNorm2d-21       (32, 8, 37)       (32, 8, 37)         64            0\n",
      "        ReLu-22       (32, 8, 37)       (32, 8, 37)          0        9,472\n",
      "      Conv2d-23       (32, 8, 37)       (34, 8, 37)      9,792    2,898,432\n",
      " BatchNorm2d-24       (34, 8, 37)       (34, 8, 37)         68            0\n",
      "        ReLu-25       (34, 8, 37)       (34, 8, 37)          0       10,064\n",
      "   MaxPool2d-26       (34, 8, 37)       (34, 4, 18)          0        9,792\n",
      "      Conv2d-27       (34, 4, 18)       (36, 4, 18)     11,016      793,152\n",
      " BatchNorm2d-28       (36, 4, 18)       (36, 4, 18)         72            0\n",
      "        ReLu-29       (36, 4, 18)       (36, 4, 18)          0        2,592\n",
      "      Conv2d-30       (36, 4, 18)       (34, 4, 18)     11,016      793,152\n",
      " BatchNorm2d-31       (34, 4, 18)       (34, 4, 18)         68            0\n",
      "        ReLu-32       (34, 4, 18)       (34, 4, 18)          0        2,448\n",
      "   MaxPool2d-33       (34, 4, 18)        (34, 2, 9)          0        2,448\n",
      "      Conv2d-34        (34, 2, 9)        (28, 2, 9)      8,568      154,224\n",
      " BatchNorm2d-35        (28, 2, 9)        (28, 2, 9)         56            0\n",
      "        ReLu-36        (28, 2, 9)        (28, 2, 9)          0          504\n",
      "      Conv2d-37        (28, 2, 9)        (32, 2, 9)      8,064      145,152\n",
      " BatchNorm2d-38        (32, 2, 9)        (32, 2, 9)         64            0\n",
      "        ReLu-39        (32, 2, 9)        (32, 2, 9)          0          576\n",
      "   MaxPool2d-40        (32, 2, 9)        (32, 1, 4)          0          512\n",
      "      Conv2d-41        (32, 1, 4)         (4, 1, 4)        128          512\n",
      " BatchNorm2d-42         (4, 1, 4)         (4, 1, 4)          8            0\n",
      "        ReLu-43         (4, 1, 4)         (4, 1, 4)          0           16\n",
      "   AvgPool2d-44         (4, 1, 4)         (4, 1, 1)          0           16\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 67,974\n",
      "Total FLOPs : 30,427,200\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 0.26\n",
      "Total size (MB) : 0.37\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "net.qconfig : QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=False){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n",
      "Preparing calibration dataset..\n",
      "Calibration dataset is ready\n",
      "shape of y_pred:torch.Size([828, 4])\n",
      "shape of y_target:torch.Size([828, 4])\n",
      "after: len of y_pred:414, len of y_target:414\n",
      "__chk_bestAcc is called\n",
      "current best Acc is 0.0\n",
      "pass in acc is 89.13043975830078\n",
      "model saved....., acc: 89.13043975830078\n",
      "SP-[1] Epoch: 1/1600 | Time: 0m15s (Train 0m13s  Val 0m02s) | Train: LR 0.010000000000000002  Loss 0.42  Acc 72.29% | Val: Loss nan  Acc(top1) 89.13% | HA 89.13@1\n",
      "shape of y_pred:torch.Size([828, 4])\n",
      "shape of y_target:torch.Size([828, 4])\n",
      "after: len of y_pred:414, len of y_target:414\n",
      "__chk_bestAcc is called\n",
      "current best Acc is 89.13043975830078\n",
      "pass in acc is 90.82125091552734\n",
      "model saved....., acc: 90.82125091552734\n",
      "SP-[1] Epoch: 2/1600 | Time: 0m15s (Train 0m13s  Val 0m02s) | Train: LR 0.010000000000000002  Loss 0.35  Acc 76.73% | Val: Loss nan  Acc(top1) 90.82% | HA 90.82@2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m trainer\u001b[38;5;241m.\u001b[39mTestModel();\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantization process is started.....\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQuantizeModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuantization done\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting quantized model.\u001b[39m\u001b[38;5;124m'\u001b[39m);\n",
      "Cell \u001b[0;32mIn[16], line 260\u001b[0m, in \u001b[0;36mQATTrainer.QuantizeModel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mprepare_qat(net, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m);\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Calibrate with the training data\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# self.__calibrate(net);\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m#place trained model to cpu\u001b[39;00m\n\u001b[1;32m    263\u001b[0m net\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m);\n",
      "Cell \u001b[0;32mIn[16], line 152\u001b[0m, in \u001b[0;36mQATTrainer.__train\u001b[0;34m(self, net)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m); \u001b[38;5;66;03m#need to check float NaN value?\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     running_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (((outputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m.\u001b[39mitem();\n\u001b[1;32m    154\u001b[0m     loss \u001b[38;5;241m=\u001b[39m lossFunc(outputs\u001b[38;5;241m.\u001b[39mlog(), y);\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/WorkSpaces/Work/Projects/uec-iot-ai-models/src/Training/Step_5_Quant_and_Retrain_and_Convert2TFLite/../../th/resources/no_softmax_quant_model.py:92\u001b[0m, in \u001b[0;36mACDNetQuant.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m#Quantize input\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant(x);\n\u001b[0;32m---> 92\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msfeb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m#swapaxes\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m));\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1568\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1565\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1566\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1568\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1570\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1572\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1573\u001b[0m     ):\n\u001b[1;32m   1574\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/ao/nn/intrinsic/qat/modules/conv_fused.py:621\u001b[0m, in \u001b[0;36mConvReLU2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mrelu(\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_fake_quant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3176d2-4a2d-4ed6-85c8-20c1c925d73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b9046-02c3-4ea8-a107-b6498c4487af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
