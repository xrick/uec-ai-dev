{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../src/\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00a2415-5a75-4b21-aca7-aa4ad28798ac",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('71',3),('99',4)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        # batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX, batchY = self.generate_batch_select_fixed_class(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def generate_batch_select_fixed_class(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        #two variables recording alarm and moaning sounds count\n",
    "        alarm_selected = 0;\n",
    "        moaning_selected = 0;\n",
    "        help_eng_selected = 0;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                # print(\"enter while true\")\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                lbl1_int = np.int16(label1);\n",
    "                lbl2_int = np.int16(label2);\n",
    "                # print(f\"label1:{label1} and label2:{label2}\")\n",
    "                # print(f\"label1:{type(label1)} and label2:{type(label2)}\")\n",
    "                if (lbl1_int == 52 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int ==52):\n",
    "                    # if (alarm_selected < moaning_selected) or (alarm_selected == moaning_selected):\n",
    "                    if (alarm_selected == moaning_selected) and (alarm_selected == help_eng_selected):\n",
    "                        alarm_selected += 1;\n",
    "                        break;\n",
    "                if (lbl1_int == 56 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 56):\n",
    "                    if (moaning_selected < alarm_selected) and (moaning_selected == help_eng_selected):\n",
    "                        moaning_selected += 1;\n",
    "                        break;\n",
    "                if (lbl1_int == 71 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 71):\n",
    "                    if (help_eng_selected < alarm_selected) and (help_eng_selected < moaning_selected):\n",
    "                        help_eng_selected += 1;\n",
    "                        break;\n",
    "            # print(f\"escape for loop\");\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random());\n",
    "            #######make wanted class mix ration above 0.5##########\n",
    "            # iLbl1 = np.int16(label1);\n",
    "            # iLbl2 = np.int16(label2);\n",
    "            # r = 1.0;\n",
    "            # p_ratio1 = 0.4\n",
    "            # p_ratio2 = 0.6\n",
    "            # while True:\n",
    "            #     r = np.array(random.random());\n",
    "            #     if r > p_ratio1 and iLbl1 != 99 :\n",
    "            #         break;\n",
    "            #     if r < p_ratio2 and iLbl2 != 99 :\n",
    "            #         break;\n",
    "            #######################End#######################\n",
    "            # print(f\"r:{r}, lbl1:{label1}, lbl2:{label2}\")  \n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            \n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        # print(f\"alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess_setup_withoutt_normalize(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength)\n",
    "                 ]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['{}'.format(opt.current_fold)].item()['sounds']\n",
    "    train_labels = dataset['{}'.format(opt.current_fold)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392ff48-c5c7-4e0f-a7f5-4eb243d1ab56",
   "metadata": {},
   "source": [
    "### option object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='None',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9873d-61b4-47b1-a0e5-95d8f156a7f2",
   "metadata": {},
   "source": [
    "### ACDNet Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  self.ch_config[-1];#n_class #self.ch_config[-1];\n",
    "        # ch_confing_10 = 512 #8 * 64\n",
    "        # ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=20150, nclass=4, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = opt.prun_type; #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        # self.opt.device = 'cuda:0'#office\n",
    "        self.opt.device = opt.device;#home\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        print(f\"Start to Prune and Train Using device:{self.opt.device}\");\n",
    "        dir = os.getcwd();\n",
    "        \n",
    "        trained_model = \"../../../trained_models/step_2_first_stage_pruning/multifold/s2_wprun_4C_fold5_2024072310_prunratio85.0/selected/uec_4C_weight_prun_fold5_haacc_95.62841033935547_valacc94.53551483154297_tracc91.19318181818183_epoch_1078_20240723111906.pt\"\n",
    "        state= torch.load(trained_model, map_location=self.opt.device);\n",
    "        self.net = GetCustomedACDNetModel(channel_config=state[\"config\"]).to(self.opt.device);\n",
    "        self.net.load_state_dict(state['weight']);#home\n",
    "        self.net = self.net.to(self.opt.device);\n",
    "        \n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda();\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);#in office, use cuda(better) or cpu\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = y_target.cuda();\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                label = label.cpu() #use apple m2, in office use cuda\n",
    "                output = output.cpu() #use apple m2, in office use cuda\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                x = x.type(torch.cuda.FloatTensor);\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);\n",
    "\n",
    "        \n",
    "    # def __save_model(self, acc, train_acc, epochIdx, net):\n",
    "    #     if acc > self.bestAcc:\n",
    "    #         self.bestAcc = acc;\n",
    "    #         self.bestAccEpoch = epochIdx +1;\n",
    "    #         __do_save_model(self, acc, train_acc, self.bestAccEpoch, net);\n",
    "    #     else:\n",
    "    #         if acc > 94.0 or train_acc > 85.0: \n",
    "    #             __do_save_model(self, acc, train_acc, epochIdx, net);\n",
    "    #         else:\n",
    "    #             pass\n",
    "\n",
    "    # def __do_save_model(self, acc, tr_acc, bestAccIdx, net):\n",
    "    #     save_model_name = self.opt.model_name.format(self.bestAcc, acc, train_acc, epochIdx, genDataTimeStr());\n",
    "    #     save_model_fullpath = self.opt.save_dir + save_model_name;\n",
    "    #     print(f\"save model to {save_model_fullpath}\")\n",
    "    #     torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "    #     logObj.write(f\"save model:{model_name}, bestAcc:{self.bestAcc}@{self.}, currentAcc:{acc}@{epochIdx}\");\n",
    "    #     logObj.write(\"\\n\");\n",
    "    #     logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n===============================================\\nprune_type = Magnitude Pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n=============================================\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "===============================================\n",
    "prune_type = Magnitude Pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "=============================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 64;\n",
    "    #set train and validation sets\n",
    "    # opt.trainSet = \"../../../../uec_iot_models_datasets/version11/single_fold_train_20240603063535.npz\" #office\n",
    "    # opt.valSet = \"../../../../uec_iot_models_datasets/version11/final_single_val_20240603063755.npz\" #office\n",
    "    opt.trainSet = \"../../../../uec_iot_models_datasets/multifold/train/version15_multifold_home_fold5/fold5_train_20240721013721.npz\";#home\n",
    "    opt.valSet = \"../../../../uec_iot_models_datasets/multifold/val/version15_multifold_home_fold5/final_fold5_val_version15_multifold_home_20240721024402.npz\";#home\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    opt.prun_type = 2; #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "    opt.nClasses = 4\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 20150;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.trainer = None\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    # opt.device = 'mps';#home\n",
    "    # tlopts.display_info(opt)\n",
    "    opt.current_fold='fold5';\n",
    "    save_dir = \"../../../trained_models/step_4_second_stage_pruning/multifold/s3_prun_{}_4C_{}_prunratio{}/\".format(opt.current_fold,getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    # \"uec_4C_weight_prun_{}_\".format(opt.current_fold)+\"haacc_{}_valacc{}_tracc{}_epoch_{}_{}.pt\"\n",
    "    model_name = \"uec_4C_IterPrun_{}_ratio{}_{}.pt\".format(opt.current_fold, (opt.prune_ratio*100), genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "\n",
    "    print(f\"save model full path:{opt.model_name}\")\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model full path:../../../trained_models/step_4_second_stage_pruning/multifold/s3_prun_fold5_4C_2024072314_prunratio85.0/uec_4C_IterPrun_fold5_ratio85.0_20240723140833.pt\n",
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:704\n",
      "Start to pruning.....\n",
      "Start to Prune and Train Using device:cuda:0\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.536%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 20150)     (8, 1, 10071)         72      725,112\n",
      "  BatchNorm2d-2     (8, 1, 10071)     (8, 1, 10071)         16            0\n",
      "         ReLu-3     (8, 1, 10071)     (8, 1, 10071)          0       80,568\n",
      "       Conv2d-4     (8, 1, 10071)     (64, 1, 5034)      2,560   12,887,040\n",
      "  BatchNorm2d-5     (64, 1, 5034)     (64, 1, 5034)        128            0\n",
      "         ReLu-6     (64, 1, 5034)     (64, 1, 5034)          0      322,176\n",
      "    MaxPool2d-7     (64, 1, 5034)      (64, 1, 100)          0      320,000\n",
      "      Permute-8      (64, 1, 100)      (1, 64, 100)          0            0\n",
      "       Conv2d-9      (1, 64, 100)     (32, 64, 100)        288    1,843,200\n",
      " BatchNorm2d-10     (32, 64, 100)     (32, 64, 100)         64            0\n",
      "        ReLu-11     (32, 64, 100)     (32, 64, 100)          0      204,800\n",
      "   MaxPool2d-12     (32, 64, 100)      (32, 32, 50)          0      204,800\n",
      "      Conv2d-13      (32, 32, 50)      (64, 32, 50)     18,432   29,491,200\n",
      " BatchNorm2d-14      (64, 32, 50)      (64, 32, 50)        128            0\n",
      "        ReLu-15      (64, 32, 50)      (64, 32, 50)          0      102,400\n",
      "      Conv2d-16      (64, 32, 50)      (64, 32, 50)     36,864   58,982,400\n",
      " BatchNorm2d-17      (64, 32, 50)      (64, 32, 50)        128            0\n",
      "        ReLu-18      (64, 32, 50)      (64, 32, 50)          0      102,400\n",
      "   MaxPool2d-19      (64, 32, 50)      (64, 16, 25)          0      102,400\n",
      "      Conv2d-20      (64, 16, 25)     (128, 16, 25)     73,728   29,491,200\n",
      " BatchNorm2d-21     (128, 16, 25)     (128, 16, 25)        256            0\n",
      "        ReLu-22     (128, 16, 25)     (128, 16, 25)          0       51,200\n",
      "      Conv2d-23     (128, 16, 25)     (128, 16, 25)    147,456   58,982,400\n",
      " BatchNorm2d-24     (128, 16, 25)     (128, 16, 25)        256            0\n",
      "        ReLu-25     (128, 16, 25)     (128, 16, 25)          0       51,200\n",
      "   MaxPool2d-26     (128, 16, 25)      (128, 8, 12)          0       49,152\n",
      "      Conv2d-27      (128, 8, 12)      (256, 8, 12)    294,912   28,311,552\n",
      " BatchNorm2d-28      (256, 8, 12)      (256, 8, 12)        512            0\n",
      "        ReLu-29      (256, 8, 12)      (256, 8, 12)          0       24,576\n",
      "      Conv2d-30      (256, 8, 12)      (256, 8, 12)    589,824   56,623,104\n",
      " BatchNorm2d-31      (256, 8, 12)      (256, 8, 12)        512            0\n",
      "        ReLu-32      (256, 8, 12)      (256, 8, 12)          0       24,576\n",
      "   MaxPool2d-33      (256, 8, 12)       (256, 4, 6)          0       24,576\n",
      "      Conv2d-34       (256, 4, 6)       (512, 4, 6)  1,179,648   28,311,552\n",
      " BatchNorm2d-35       (512, 4, 6)       (512, 4, 6)      1,024            0\n",
      "        ReLu-36       (512, 4, 6)       (512, 4, 6)          0       12,288\n",
      "      Conv2d-37       (512, 4, 6)       (512, 4, 6)  2,359,296   56,623,104\n",
      " BatchNorm2d-38       (512, 4, 6)       (512, 4, 6)      1,024            0\n",
      "        ReLu-39       (512, 4, 6)       (512, 4, 6)          0       12,288\n",
      "   MaxPool2d-40       (512, 4, 6)       (512, 2, 3)          0       12,288\n",
      "      Conv2d-41       (512, 2, 3)         (4, 2, 3)      2,048       12,288\n",
      " BatchNorm2d-42         (4, 2, 3)         (4, 2, 3)          8            0\n",
      "        ReLu-43         (4, 2, 3)         (4, 2, 3)          0           24\n",
      "   AvgPool2d-44         (4, 2, 3)         (4, 1, 1)          0           24\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 4,709,204\n",
      "Total FLOPs : 363,985,912\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.08\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.04\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2028, Prunable: 2028, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (85%): 1722\n",
      "Total iterations required: 1722\n",
      "\n",
      "Iteration 1 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 5)]\n",
      "Input: 0.077 MB, Params: 4,709,162 (17.964 MB), Total: 18.04 MB, FLOPs: 323,535,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 28.415%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.077 MB, Params: 4,709,120 (17.964 MB), Total: 18.04 MB, FLOPs: 323,291,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1724 finished in 0m09s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.077 MB, Params: 4,709,078 (17.964 MB), Total: 18.04 MB, FLOPs: 320,270,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1724 finished in 0m09s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 30)]\n",
      "Input: 0.077 MB, Params: 4,709,036 (17.964 MB), Total: 18.04 MB, FLOPs: 320,027,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1724 finished in 0m09s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 31)]\n",
      "Input: 0.077 MB, Params: 4,708,994 (17.963 MB), Total: 18.04 MB, FLOPs: 311,463,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1724 finished in 0m09s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 38)]\n",
      "Input: 0.077 MB, Params: 4,708,952 (17.963 MB), Total: 18.04 MB, FLOPs: 311,220,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1724 finished in 0m09s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.077 MB, Params: 4,708,365 (17.961 MB), Total: 18.04 MB, FLOPs: 310,321,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1724 finished in 0m09s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.077 MB, Params: 4,707,778 (17.959 MB), Total: 18.04 MB, FLOPs: 309,422,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1724 finished in 0m09s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.077 MB, Params: 4,707,191 (17.957 MB), Total: 18.03 MB, FLOPs: 308,523,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1724 finished in 0m09s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.077 MB, Params: 4,703,733 (17.943 MB), Total: 18.02 MB, FLOPs: 308,233,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1724 finished in 0m09s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.077 MB, Params: 4,699,119 (17.926 MB), Total: 18.00 MB, FLOPs: 308,150,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1724 finished in 0m09s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.077 MB, Params: 4,694,505 (17.908 MB), Total: 17.98 MB, FLOPs: 308,067,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1724 finished in 0m09s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.077 MB, Params: 4,689,891 (17.891 MB), Total: 17.97 MB, FLOPs: 307,984,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1724 finished in 0m09s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 399)]\n",
      "Input: 0.077 MB, Params: 4,685,277 (17.873 MB), Total: 17.95 MB, FLOPs: 307,901,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1724 finished in 0m09s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 444)]\n",
      "Input: 0.077 MB, Params: 4,680,663 (17.855 MB), Total: 17.93 MB, FLOPs: 307,818,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1724 finished in 0m09s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 12)]\n",
      "Input: 0.077 MB, Params: 4,678,933 (17.849 MB), Total: 17.93 MB, FLOPs: 306,576,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1724 finished in 0m09s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 366)]\n",
      "Input: 0.077 MB, Params: 4,674,319 (17.831 MB), Total: 17.91 MB, FLOPs: 306,494,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1724 finished in 0m09s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.077 MB, Params: 4,667,459 (17.805 MB), Total: 17.88 MB, FLOPs: 306,370,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1724 finished in 0m09s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.077 MB, Params: 4,662,854 (17.787 MB), Total: 17.86 MB, FLOPs: 306,287,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1724 finished in 0m09s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.077 MB, Params: 4,656,003 (17.761 MB), Total: 17.84 MB, FLOPs: 306,164,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1724 finished in 0m09s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 4,651,407 (17.744 MB), Total: 17.82 MB, FLOPs: 306,081,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1724 finished in 0m09s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.077 MB, Params: 4,644,520 (17.717 MB), Total: 17.79 MB, FLOPs: 305,806,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1724 finished in 0m09s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 126)]\n",
      "Input: 0.077 MB, Params: 4,641,071 (17.704 MB), Total: 17.78 MB, FLOPs: 305,516,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1724 finished in 0m09s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 368)]\n",
      "Input: 0.077 MB, Params: 4,636,475 (17.687 MB), Total: 17.76 MB, FLOPs: 305,433,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1724 finished in 0m09s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 1)]\n",
      "Input: 0.077 MB, Params: 4,635,645 (17.684 MB), Total: 17.76 MB, FLOPs: 304,231,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1724 finished in 0m09s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.077 MB, Params: 4,628,821 (17.658 MB), Total: 17.73 MB, FLOPs: 304,109,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1724 finished in 0m09s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.077 MB, Params: 4,621,997 (17.632 MB), Total: 17.71 MB, FLOPs: 303,986,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1724 finished in 0m09s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 239)]\n",
      "Input: 0.077 MB, Params: 4,615,173 (17.605 MB), Total: 17.68 MB, FLOPs: 303,863,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1724 finished in 0m09s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 148)]\n",
      "Input: 0.077 MB, Params: 4,608,322 (17.579 MB), Total: 17.66 MB, FLOPs: 303,589,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1724 finished in 0m09s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 341)]\n",
      "Input: 0.077 MB, Params: 4,601,507 (17.553 MB), Total: 17.63 MB, FLOPs: 303,466,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1724 finished in 0m09s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 82)]\n",
      "Input: 0.077 MB, Params: 4,598,067 (17.540 MB), Total: 17.62 MB, FLOPs: 302,870,544\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1724 finished in 0m09s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 406)]\n",
      "Input: 0.077 MB, Params: 4,593,507 (17.523 MB), Total: 17.60 MB, FLOPs: 302,788,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1724 finished in 0m09s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 4,591,795 (17.516 MB), Total: 17.59 MB, FLOPs: 302,189,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1724 finished in 0m09s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.077 MB, Params: 4,584,989 (17.490 MB), Total: 17.57 MB, FLOPs: 302,067,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1724 finished in 0m09s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 301)]\n",
      "Input: 0.077 MB, Params: 4,578,183 (17.464 MB), Total: 17.54 MB, FLOPs: 301,944,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1724 finished in 0m09s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 428)]\n",
      "Input: 0.077 MB, Params: 4,571,377 (17.438 MB), Total: 17.52 MB, FLOPs: 301,822,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1724 finished in 0m09s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 466)]\n",
      "Input: 0.077 MB, Params: 4,566,844 (17.421 MB), Total: 17.50 MB, FLOPs: 301,740,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1724 finished in 0m09s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 154)]\n",
      "Input: 0.077 MB, Params: 4,563,413 (17.408 MB), Total: 17.48 MB, FLOPs: 301,452,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1724 finished in 0m09s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 59)]\n",
      "Input: 0.077 MB, Params: 4,561,701 (17.402 MB), Total: 17.48 MB, FLOPs: 300,853,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1724 finished in 0m09s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 465)]\n",
      "Input: 0.077 MB, Params: 4,557,168 (17.384 MB), Total: 17.46 MB, FLOPs: 300,772,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1724 finished in 0m09s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 180)]\n",
      "Input: 0.077 MB, Params: 4,550,362 (17.358 MB), Total: 17.44 MB, FLOPs: 300,499,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1724 finished in 0m09s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.077 MB, Params: 4,545,829 (17.341 MB), Total: 17.42 MB, FLOPs: 300,417,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1724 finished in 0m09s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.077 MB, Params: 4,539,059 (17.315 MB), Total: 17.39 MB, FLOPs: 300,295,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1724 finished in 0m09s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.077 MB, Params: 4,532,289 (17.289 MB), Total: 17.37 MB, FLOPs: 300,174,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1724 finished in 0m09s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 225)]\n",
      "Input: 0.077 MB, Params: 4,527,774 (17.272 MB), Total: 17.35 MB, FLOPs: 300,092,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1724 finished in 0m09s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.077 MB, Params: 4,523,259 (17.255 MB), Total: 17.33 MB, FLOPs: 300,011,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1724 finished in 0m09s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.077 MB, Params: 4,518,744 (17.238 MB), Total: 17.31 MB, FLOPs: 299,930,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1724 finished in 0m09s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 267)]\n",
      "Input: 0.077 MB, Params: 4,512,001 (17.212 MB), Total: 17.29 MB, FLOPs: 299,809,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1724 finished in 0m09s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.077 MB, Params: 4,507,495 (17.195 MB), Total: 17.27 MB, FLOPs: 299,728,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1724 finished in 0m09s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 30)]\n",
      "Input: 0.077 MB, Params: 4,507,453 (17.195 MB), Total: 17.27 MB, FLOPs: 296,867,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1724 finished in 0m09s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 0)]\n",
      "Input: 0.077 MB, Params: 4,504,040 (17.182 MB), Total: 17.26 MB, FLOPs: 296,278,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1724 finished in 0m09s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 491)]\n",
      "Input: 0.077 MB, Params: 4,497,306 (17.156 MB), Total: 17.23 MB, FLOPs: 296,157,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1724 finished in 0m09s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 249)]\n",
      "Input: 0.077 MB, Params: 4,492,809 (17.139 MB), Total: 17.22 MB, FLOPs: 296,076,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1724 finished in 0m09s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.077 MB, Params: 4,488,312 (17.122 MB), Total: 17.20 MB, FLOPs: 295,995,550\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1724 finished in 0m09s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 152)]\n",
      "Input: 0.077 MB, Params: 4,484,899 (17.109 MB), Total: 17.19 MB, FLOPs: 295,708,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1724 finished in 0m09s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 400)]\n",
      "Input: 0.077 MB, Params: 4,480,402 (17.091 MB), Total: 17.17 MB, FLOPs: 295,628,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1724 finished in 0m09s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.077 MB, Params: 4,475,905 (17.074 MB), Total: 17.15 MB, FLOPs: 295,547,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1724 finished in 0m09s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.077 MB, Params: 4,471,408 (17.057 MB), Total: 17.13 MB, FLOPs: 295,466,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1724 finished in 0m09s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 196)]\n",
      "Input: 0.077 MB, Params: 4,464,647 (17.031 MB), Total: 17.11 MB, FLOPs: 295,194,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1724 finished in 0m09s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.077 MB, Params: 4,457,886 (17.005 MB), Total: 17.08 MB, FLOPs: 294,923,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1724 finished in 0m09s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 231)]\n",
      "Input: 0.077 MB, Params: 4,453,389 (16.988 MB), Total: 17.07 MB, FLOPs: 294,842,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1724 finished in 0m09s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.077 MB, Params: 4,449,994 (16.975 MB), Total: 17.05 MB, FLOPs: 294,557,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1724 finished in 0m09s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 416)]\n",
      "Input: 0.077 MB, Params: 4,443,332 (16.950 MB), Total: 17.03 MB, FLOPs: 294,437,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1724 finished in 0m09s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 269)]\n",
      "Input: 0.077 MB, Params: 4,436,670 (16.925 MB), Total: 17.00 MB, FLOPs: 294,317,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1724 finished in 0m09s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 468)]\n",
      "Input: 0.077 MB, Params: 4,432,191 (16.907 MB), Total: 16.98 MB, FLOPs: 294,236,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1724 finished in 0m09s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.077 MB, Params: 4,428,796 (16.895 MB), Total: 16.97 MB, FLOPs: 293,951,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1724 finished in 0m09s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 396)]\n",
      "Input: 0.077 MB, Params: 4,422,143 (16.869 MB), Total: 16.95 MB, FLOPs: 293,832,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1724 finished in 0m09s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 401)]\n",
      "Input: 0.077 MB, Params: 4,415,490 (16.844 MB), Total: 16.92 MB, FLOPs: 293,712,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1724 finished in 0m09s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 248)]\n",
      "Input: 0.077 MB, Params: 4,411,029 (16.827 MB), Total: 16.90 MB, FLOPs: 293,632,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1724 finished in 0m09s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 51)]\n",
      "Input: 0.077 MB, Params: 4,409,326 (16.820 MB), Total: 16.90 MB, FLOPs: 292,438,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1724 finished in 0m09s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 282)]\n",
      "Input: 0.077 MB, Params: 4,404,865 (16.803 MB), Total: 16.88 MB, FLOPs: 292,358,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1724 finished in 0m09s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 381)]\n",
      "Input: 0.077 MB, Params: 4,400,404 (16.786 MB), Total: 16.86 MB, FLOPs: 292,278,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1724 finished in 0m09s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.077 MB, Params: 4,398,710 (16.780 MB), Total: 16.86 MB, FLOPs: 291,685,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1724 finished in 0m09s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 405)]\n",
      "Input: 0.077 MB, Params: 4,392,084 (16.754 MB), Total: 16.83 MB, FLOPs: 291,566,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1724 finished in 0m09s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 493)]\n",
      "Input: 0.077 MB, Params: 4,385,458 (16.729 MB), Total: 16.81 MB, FLOPs: 291,447,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1724 finished in 0m09s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 390)]\n",
      "Input: 0.077 MB, Params: 4,381,015 (16.712 MB), Total: 16.79 MB, FLOPs: 291,367,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1724 finished in 0m09s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.077 MB, Params: 4,374,326 (16.687 MB), Total: 16.76 MB, FLOPs: 291,098,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1724 finished in 0m09s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.077 MB, Params: 4,372,632 (16.680 MB), Total: 16.76 MB, FLOPs: 289,907,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1724 finished in 0m09s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 398)]\n",
      "Input: 0.077 MB, Params: 4,368,189 (16.663 MB), Total: 16.74 MB, FLOPs: 289,827,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1724 finished in 0m09s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 185)]\n",
      "Input: 0.077 MB, Params: 4,363,746 (16.646 MB), Total: 16.72 MB, FLOPs: 289,748,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1724 finished in 0m09s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 360)]\n",
      "Input: 0.077 MB, Params: 4,357,156 (16.621 MB), Total: 16.70 MB, FLOPs: 289,629,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1724 finished in 0m09s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.077 MB, Params: 4,352,722 (16.604 MB), Total: 16.68 MB, FLOPs: 289,549,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1724 finished in 0m09s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.077 MB, Params: 4,348,288 (16.587 MB), Total: 16.66 MB, FLOPs: 289,469,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1724 finished in 0m09s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 254)]\n",
      "Input: 0.077 MB, Params: 4,341,716 (16.562 MB), Total: 16.64 MB, FLOPs: 289,351,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1724 finished in 0m09s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 419)]\n",
      "Input: 0.077 MB, Params: 4,335,144 (16.537 MB), Total: 16.61 MB, FLOPs: 289,233,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1724 finished in 0m09s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 278)]\n",
      "Input: 0.077 MB, Params: 4,328,572 (16.512 MB), Total: 16.59 MB, FLOPs: 289,115,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1724 finished in 0m09s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 227)]\n",
      "Input: 0.077 MB, Params: 4,321,919 (16.487 MB), Total: 16.56 MB, FLOPs: 288,846,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1724 finished in 0m09s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.077 MB, Params: 4,318,542 (16.474 MB), Total: 16.55 MB, FLOPs: 288,563,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1724 finished in 0m09s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 478)]\n",
      "Input: 0.077 MB, Params: 4,314,135 (16.457 MB), Total: 16.53 MB, FLOPs: 288,483,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1724 finished in 0m09s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.077 MB, Params: 4,309,728 (16.440 MB), Total: 16.52 MB, FLOPs: 288,404,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1724 finished in 0m09s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.077 MB, Params: 4,303,183 (16.415 MB), Total: 16.49 MB, FLOPs: 288,286,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1724 finished in 0m09s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.077 MB, Params: 4,298,785 (16.399 MB), Total: 16.48 MB, FLOPs: 288,207,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1724 finished in 0m09s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.077 MB, Params: 4,292,249 (16.374 MB), Total: 16.45 MB, FLOPs: 288,090,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1724 finished in 0m09s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 307)]\n",
      "Input: 0.077 MB, Params: 4,285,713 (16.349 MB), Total: 16.43 MB, FLOPs: 287,972,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1724 finished in 0m09s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 4,279,096 (16.323 MB), Total: 16.40 MB, FLOPs: 287,705,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1724 finished in 0m09s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.077 MB, Params: 4,274,716 (16.307 MB), Total: 16.38 MB, FLOPs: 287,626,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1724 finished in 0m09s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 210)]\n",
      "Input: 0.077 MB, Params: 4,268,099 (16.282 MB), Total: 16.36 MB, FLOPs: 287,359,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1724 finished in 0m09s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 262)]\n",
      "Input: 0.077 MB, Params: 4,261,590 (16.257 MB), Total: 16.33 MB, FLOPs: 287,242,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1724 finished in 0m09s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.077 MB, Params: 4,254,982 (16.231 MB), Total: 16.31 MB, FLOPs: 286,975,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1724 finished in 0m09s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 17)]\n",
      "Input: 0.077 MB, Params: 4,254,404 (16.229 MB), Total: 16.31 MB, FLOPs: 286,118,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1724 finished in 0m09s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.077 MB, Params: 4,250,033 (16.213 MB), Total: 16.29 MB, FLOPs: 286,040,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1724 finished in 0m09s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 105)]\n",
      "Input: 0.077 MB, Params: 4,246,665 (16.200 MB), Total: 16.28 MB, FLOPs: 285,457,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1724 finished in 0m09s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 4,242,294 (16.183 MB), Total: 16.26 MB, FLOPs: 285,379,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1724 finished in 0m09s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.077 MB, Params: 4,235,812 (16.158 MB), Total: 16.24 MB, FLOPs: 285,262,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1724 finished in 0m09s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 341)]\n",
      "Input: 0.077 MB, Params: 4,229,330 (16.134 MB), Total: 16.21 MB, FLOPs: 285,145,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1724 finished in 0m09s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 438)]\n",
      "Input: 0.077 MB, Params: 4,224,977 (16.117 MB), Total: 16.19 MB, FLOPs: 285,067,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1724 finished in 0m09s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 195)]\n",
      "Input: 0.077 MB, Params: 4,221,636 (16.104 MB), Total: 16.18 MB, FLOPs: 284,786,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1724 finished in 0m09s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 388)]\n",
      "Input: 0.077 MB, Params: 4,217,283 (16.088 MB), Total: 16.16 MB, FLOPs: 284,708,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1724 finished in 0m09s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 420)]\n",
      "Input: 0.077 MB, Params: 4,210,819 (16.063 MB), Total: 16.14 MB, FLOPs: 284,592,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1724 finished in 0m09s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 143)]\n",
      "Input: 0.077 MB, Params: 4,207,478 (16.050 MB), Total: 16.13 MB, FLOPs: 284,311,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1724 finished in 0m09s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.077 MB, Params: 4,201,014 (16.026 MB), Total: 16.10 MB, FLOPs: 284,195,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1724 finished in 0m09s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.077 MB, Params: 4,194,550 (16.001 MB), Total: 16.08 MB, FLOPs: 284,079,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1724 finished in 0m09s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 4,188,005 (15.976 MB), Total: 16.05 MB, FLOPs: 283,814,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1724 finished in 0m09s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.077 MB, Params: 4,183,679 (15.959 MB), Total: 16.04 MB, FLOPs: 283,736,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1724 finished in 0m09s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 401)]\n",
      "Input: 0.077 MB, Params: 4,179,353 (15.943 MB), Total: 16.02 MB, FLOPs: 283,658,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1724 finished in 0m09s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.077 MB, Params: 4,176,021 (15.930 MB), Total: 16.01 MB, FLOPs: 283,378,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1724 finished in 0m09s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 125)]\n",
      "Input: 0.077 MB, Params: 4,169,584 (15.906 MB), Total: 15.98 MB, FLOPs: 283,263,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1724 finished in 0m09s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 182)]\n",
      "Input: 0.077 MB, Params: 4,166,252 (15.893 MB), Total: 15.97 MB, FLOPs: 282,983,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1724 finished in 0m09s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 306)]\n",
      "Input: 0.077 MB, Params: 4,161,935 (15.877 MB), Total: 15.95 MB, FLOPs: 282,905,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1724 finished in 0m09s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 94)]\n",
      "Input: 0.077 MB, Params: 4,158,603 (15.864 MB), Total: 15.94 MB, FLOPs: 282,326,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1724 finished in 0m09s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.077 MB, Params: 4,154,286 (15.847 MB), Total: 15.92 MB, FLOPs: 282,248,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1724 finished in 0m09s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 109)]\n",
      "Input: 0.077 MB, Params: 4,147,768 (15.822 MB), Total: 15.90 MB, FLOPs: 281,985,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1724 finished in 0m09s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 278)]\n",
      "Input: 0.077 MB, Params: 4,141,358 (15.798 MB), Total: 15.87 MB, FLOPs: 281,870,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1724 finished in 0m09s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 4,138,044 (15.785 MB), Total: 15.86 MB, FLOPs: 281,591,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1724 finished in 0m09s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 4,133,736 (15.769 MB), Total: 15.85 MB, FLOPs: 281,514,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1724 finished in 0m09s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 4,130,413 (15.756 MB), Total: 15.83 MB, FLOPs: 280,935,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1724 finished in 0m09s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 4,126,105 (15.740 MB), Total: 15.82 MB, FLOPs: 280,857,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1724 finished in 0m09s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 289)]\n",
      "Input: 0.077 MB, Params: 4,121,797 (15.723 MB), Total: 15.80 MB, FLOPs: 280,780,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1724 finished in 0m09s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.077 MB, Params: 4,117,489 (15.707 MB), Total: 15.78 MB, FLOPs: 280,702,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1724 finished in 0m09s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 69)]\n",
      "Input: 0.077 MB, Params: 4,110,989 (15.682 MB), Total: 15.76 MB, FLOPs: 280,440,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1724 finished in 0m09s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 412)]\n",
      "Input: 0.077 MB, Params: 4,104,624 (15.658 MB), Total: 15.73 MB, FLOPs: 280,326,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1724 finished in 0m09s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.077 MB, Params: 4,100,325 (15.641 MB), Total: 15.72 MB, FLOPs: 280,249,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1724 finished in 0m09s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.077 MB, Params: 4,096,026 (15.625 MB), Total: 15.70 MB, FLOPs: 280,171,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1724 finished in 0m09s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 4,089,679 (15.601 MB), Total: 15.68 MB, FLOPs: 280,057,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1724 finished in 0m09s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 445)]\n",
      "Input: 0.077 MB, Params: 4,083,332 (15.577 MB), Total: 15.65 MB, FLOPs: 279,943,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1724 finished in 0m09s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.077 MB, Params: 4,076,985 (15.552 MB), Total: 15.63 MB, FLOPs: 279,829,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1724 finished in 0m09s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.077 MB, Params: 4,075,327 (15.546 MB), Total: 15.62 MB, FLOPs: 279,249,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1724 finished in 0m09s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.077 MB, Params: 4,073,669 (15.540 MB), Total: 15.62 MB, FLOPs: 278,669,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1724 finished in 0m09s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 94)]\n",
      "Input: 0.077 MB, Params: 4,070,364 (15.527 MB), Total: 15.60 MB, FLOPs: 278,096,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1724 finished in 0m09s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 122)]\n",
      "Input: 0.077 MB, Params: 4,068,715 (15.521 MB), Total: 15.60 MB, FLOPs: 277,519,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1724 finished in 0m09s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 327)]\n",
      "Input: 0.077 MB, Params: 4,062,368 (15.497 MB), Total: 15.57 MB, FLOPs: 277,405,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1724 finished in 0m09s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 420)]\n",
      "Input: 0.077 MB, Params: 4,056,021 (15.472 MB), Total: 15.55 MB, FLOPs: 277,291,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1724 finished in 0m09s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 4,049,674 (15.448 MB), Total: 15.53 MB, FLOPs: 277,177,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1724 finished in 0m09s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.077 MB, Params: 4,043,327 (15.424 MB), Total: 15.50 MB, FLOPs: 277,062,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1724 finished in 0m09s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.077 MB, Params: 4,036,980 (15.400 MB), Total: 15.48 MB, FLOPs: 276,948,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1724 finished in 0m09s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 364)]\n",
      "Input: 0.077 MB, Params: 4,032,753 (15.384 MB), Total: 15.46 MB, FLOPs: 276,872,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1724 finished in 0m09s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.077 MB, Params: 4,026,334 (15.359 MB), Total: 15.44 MB, FLOPs: 276,611,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1724 finished in 0m09s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.077 MB, Params: 4,022,107 (15.343 MB), Total: 15.42 MB, FLOPs: 276,535,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1724 finished in 0m09s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.077 MB, Params: 4,015,688 (15.319 MB), Total: 15.40 MB, FLOPs: 276,275,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1724 finished in 0m09s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 308)]\n",
      "Input: 0.077 MB, Params: 4,011,461 (15.303 MB), Total: 15.38 MB, FLOPs: 276,199,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1724 finished in 0m09s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 406)]\n",
      "Input: 0.077 MB, Params: 4,005,159 (15.278 MB), Total: 15.36 MB, FLOPs: 276,085,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1724 finished in 0m09s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.077 MB, Params: 3,998,749 (15.254 MB), Total: 15.33 MB, FLOPs: 275,825,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1724 finished in 0m09s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 152)]\n",
      "Input: 0.077 MB, Params: 3,992,339 (15.230 MB), Total: 15.31 MB, FLOPs: 275,565,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1724 finished in 0m09s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 56)]\n",
      "Input: 0.077 MB, Params: 3,992,297 (15.229 MB), Total: 15.31 MB, FLOPs: 275,325,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1724 finished in 0m09s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 457)]\n",
      "Input: 0.077 MB, Params: 3,988,079 (15.213 MB), Total: 15.29 MB, FLOPs: 275,249,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1724 finished in 0m09s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 129)]\n",
      "Input: 0.077 MB, Params: 3,983,861 (15.197 MB), Total: 15.27 MB, FLOPs: 275,173,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1724 finished in 0m09s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.077 MB, Params: 3,979,643 (15.181 MB), Total: 15.26 MB, FLOPs: 275,098,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1724 finished in 0m09s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 351)]\n",
      "Input: 0.077 MB, Params: 3,973,386 (15.157 MB), Total: 15.23 MB, FLOPs: 274,985,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1724 finished in 0m09s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 347)]\n",
      "Input: 0.077 MB, Params: 3,969,177 (15.141 MB), Total: 15.22 MB, FLOPs: 274,909,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1724 finished in 0m09s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.077 MB, Params: 3,967,528 (15.135 MB), Total: 15.21 MB, FLOPs: 274,332,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1724 finished in 0m09s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.077 MB, Params: 3,963,319 (15.119 MB), Total: 15.20 MB, FLOPs: 274,257,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1724 finished in 0m09s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 49)]\n",
      "Input: 0.077 MB, Params: 3,963,277 (15.119 MB), Total: 15.20 MB, FLOPs: 256,963,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1724 finished in 0m09s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.077 MB, Params: 3,959,068 (15.103 MB), Total: 15.18 MB, FLOPs: 256,888,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1724 finished in 0m09s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.077 MB, Params: 3,952,838 (15.079 MB), Total: 15.16 MB, FLOPs: 256,776,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1724 finished in 0m09s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.077 MB, Params: 3,946,608 (15.055 MB), Total: 15.13 MB, FLOPs: 256,663,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1724 finished in 0m09s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.077 MB, Params: 3,940,378 (15.031 MB), Total: 15.11 MB, FLOPs: 256,551,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1724 finished in 0m09s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 32)]\n",
      "Input: 0.077 MB, Params: 3,938,720 (15.025 MB), Total: 15.10 MB, FLOPs: 255,429,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1724 finished in 0m09s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 351)]\n",
      "Input: 0.077 MB, Params: 3,934,538 (15.009 MB), Total: 15.09 MB, FLOPs: 255,354,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1724 finished in 0m09s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 185)]\n",
      "Input: 0.077 MB, Params: 3,928,317 (14.985 MB), Total: 15.06 MB, FLOPs: 255,242,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1724 finished in 0m09s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.077 MB, Params: 3,922,096 (14.962 MB), Total: 15.04 MB, FLOPs: 255,130,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1724 finished in 0m09s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.077 MB, Params: 3,915,875 (14.938 MB), Total: 15.01 MB, FLOPs: 255,018,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1724 finished in 0m09s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.077 MB, Params: 3,911,720 (14.922 MB), Total: 15.00 MB, FLOPs: 254,943,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1724 finished in 0m09s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.077 MB, Params: 3,905,508 (14.898 MB), Total: 14.98 MB, FLOPs: 254,832,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1724 finished in 0m09s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.077 MB, Params: 3,899,296 (14.875 MB), Total: 14.95 MB, FLOPs: 254,720,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1724 finished in 0m09s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.077 MB, Params: 3,893,084 (14.851 MB), Total: 14.93 MB, FLOPs: 254,608,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1724 finished in 0m09s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.077 MB, Params: 3,891,426 (14.845 MB), Total: 14.92 MB, FLOPs: 253,486,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1724 finished in 0m09s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 229)]\n",
      "Input: 0.077 MB, Params: 3,885,214 (14.821 MB), Total: 14.90 MB, FLOPs: 253,374,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1724 finished in 0m09s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 328)]\n",
      "Input: 0.077 MB, Params: 3,881,095 (14.805 MB), Total: 14.88 MB, FLOPs: 253,300,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1724 finished in 0m09s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.077 MB, Params: 3,876,976 (14.789 MB), Total: 14.87 MB, FLOPs: 253,226,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1724 finished in 0m09s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.077 MB, Params: 3,872,857 (14.774 MB), Total: 14.85 MB, FLOPs: 253,152,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1724 finished in 0m09s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 413)]\n",
      "Input: 0.077 MB, Params: 3,866,672 (14.750 MB), Total: 14.83 MB, FLOPs: 253,041,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1724 finished in 0m09s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 45)]\n",
      "Input: 0.077 MB, Params: 3,865,041 (14.744 MB), Total: 14.82 MB, FLOPs: 252,511,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1724 finished in 0m09s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 231)]\n",
      "Input: 0.077 MB, Params: 3,861,790 (14.732 MB), Total: 14.81 MB, FLOPs: 252,277,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1724 finished in 0m09s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.077 MB, Params: 3,857,680 (14.716 MB), Total: 14.79 MB, FLOPs: 252,203,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1724 finished in 0m09s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 409)]\n",
      "Input: 0.077 MB, Params: 3,853,570 (14.700 MB), Total: 14.78 MB, FLOPs: 252,129,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1724 finished in 0m09s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 318)]\n",
      "Input: 0.077 MB, Params: 3,849,460 (14.685 MB), Total: 14.76 MB, FLOPs: 252,055,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1724 finished in 0m09s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 215)]\n",
      "Input: 0.077 MB, Params: 3,843,167 (14.661 MB), Total: 14.74 MB, FLOPs: 251,824,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1724 finished in 0m09s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 352)]\n",
      "Input: 0.077 MB, Params: 3,837,018 (14.637 MB), Total: 14.71 MB, FLOPs: 251,713,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1724 finished in 0m09s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.077 MB, Params: 3,832,917 (14.621 MB), Total: 14.70 MB, FLOPs: 251,639,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1724 finished in 0m09s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.077 MB, Params: 3,826,777 (14.598 MB), Total: 14.67 MB, FLOPs: 251,529,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1724 finished in 0m09s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 385)]\n",
      "Input: 0.077 MB, Params: 3,820,637 (14.575 MB), Total: 14.65 MB, FLOPs: 251,418,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1724 finished in 0m09s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.077 MB, Params: 3,816,554 (14.559 MB), Total: 14.64 MB, FLOPs: 251,345,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1724 finished in 0m09s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 345)]\n",
      "Input: 0.077 MB, Params: 3,810,423 (14.536 MB), Total: 14.61 MB, FLOPs: 251,235,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1724 finished in 0m09s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.077 MB, Params: 3,806,349 (14.520 MB), Total: 14.60 MB, FLOPs: 251,161,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1724 finished in 0m09s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 197)]\n",
      "Input: 0.077 MB, Params: 3,800,092 (14.496 MB), Total: 14.57 MB, FLOPs: 250,930,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1724 finished in 0m09s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 3,793,979 (14.473 MB), Total: 14.55 MB, FLOPs: 250,820,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1724 finished in 0m09s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 312)]\n",
      "Input: 0.077 MB, Params: 3,789,914 (14.457 MB), Total: 14.53 MB, FLOPs: 250,747,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1724 finished in 0m09s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.077 MB, Params: 3,783,810 (14.434 MB), Total: 14.51 MB, FLOPs: 250,637,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1724 finished in 0m09s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.077 MB, Params: 3,780,577 (14.422 MB), Total: 14.50 MB, FLOPs: 250,405,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1724 finished in 0m09s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.077 MB, Params: 3,774,473 (14.398 MB), Total: 14.48 MB, FLOPs: 250,295,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1724 finished in 0m09s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.077 MB, Params: 3,768,252 (14.375 MB), Total: 14.45 MB, FLOPs: 250,065,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1724 finished in 0m09s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 395)]\n",
      "Input: 0.077 MB, Params: 3,764,205 (14.359 MB), Total: 14.44 MB, FLOPs: 249,992,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1724 finished in 0m09s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 447)]\n",
      "Input: 0.077 MB, Params: 3,758,119 (14.336 MB), Total: 14.41 MB, FLOPs: 249,883,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1724 finished in 0m09s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.077 MB, Params: 3,754,081 (14.321 MB), Total: 14.40 MB, FLOPs: 249,810,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1724 finished in 0m09s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 397)]\n",
      "Input: 0.077 MB, Params: 3,750,043 (14.305 MB), Total: 14.38 MB, FLOPs: 249,738,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.082%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.082%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1724 finished in 0m09s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 3,743,975 (14.282 MB), Total: 14.36 MB, FLOPs: 249,628,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1724 finished in 0m09s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 64)]\n",
      "Input: 0.077 MB, Params: 3,740,751 (14.270 MB), Total: 14.35 MB, FLOPs: 249,396,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1724 finished in 0m09s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.077 MB, Params: 3,734,683 (14.247 MB), Total: 14.32 MB, FLOPs: 249,287,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1724 finished in 0m09s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.077 MB, Params: 3,730,663 (14.231 MB), Total: 14.31 MB, FLOPs: 249,215,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1724 finished in 0m09s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 132)]\n",
      "Input: 0.077 MB, Params: 3,724,604 (14.208 MB), Total: 14.29 MB, FLOPs: 249,106,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1724 finished in 0m09s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 66)]\n",
      "Input: 0.077 MB, Params: 3,718,428 (14.185 MB), Total: 14.26 MB, FLOPs: 248,877,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1724 finished in 0m09s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.077 MB, Params: 3,715,177 (14.172 MB), Total: 14.25 MB, FLOPs: 248,370,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1724 finished in 0m09s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 425)]\n",
      "Input: 0.077 MB, Params: 3,709,127 (14.149 MB), Total: 14.23 MB, FLOPs: 248,261,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1724 finished in 0m09s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 355)]\n",
      "Input: 0.077 MB, Params: 3,705,125 (14.134 MB), Total: 14.21 MB, FLOPs: 248,189,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1724 finished in 0m09s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 435)]\n",
      "Input: 0.077 MB, Params: 3,701,123 (14.119 MB), Total: 14.20 MB, FLOPs: 248,117,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.082%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1724 finished in 0m09s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.077 MB, Params: 3,694,956 (14.095 MB), Total: 14.17 MB, FLOPs: 247,889,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.536%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1724 finished in 0m09s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.077 MB, Params: 3,694,171 (14.092 MB), Total: 14.17 MB, FLOPs: 246,830,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1724 finished in 0m09s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.077 MB, Params: 3,688,148 (14.069 MB), Total: 14.15 MB, FLOPs: 246,722,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1724 finished in 0m09s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.077 MB, Params: 3,682,125 (14.046 MB), Total: 14.12 MB, FLOPs: 246,613,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1724 finished in 0m09s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 81)]\n",
      "Input: 0.077 MB, Params: 3,678,874 (14.034 MB), Total: 14.11 MB, FLOPs: 246,106,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1724 finished in 0m09s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.077 MB, Params: 3,672,725 (14.010 MB), Total: 14.09 MB, FLOPs: 245,878,214\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1724 finished in 0m09s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 177)]\n",
      "Input: 0.077 MB, Params: 3,666,711 (13.987 MB), Total: 14.06 MB, FLOPs: 245,769,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1724 finished in 0m09s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 95)]\n",
      "Input: 0.077 MB, Params: 3,663,532 (13.975 MB), Total: 14.05 MB, FLOPs: 245,541,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1724 finished in 0m09s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 11)]\n",
      "Input: 0.077 MB, Params: 3,663,490 (13.975 MB), Total: 14.05 MB, FLOPs: 245,301,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1724 finished in 0m09s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 3,657,359 (13.952 MB), Total: 14.03 MB, FLOPs: 245,074,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1724 finished in 0m09s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.077 MB, Params: 3,651,228 (13.928 MB), Total: 14.01 MB, FLOPs: 244,847,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1724 finished in 0m09s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.077 MB, Params: 3,645,232 (13.905 MB), Total: 13.98 MB, FLOPs: 244,739,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1724 finished in 0m09s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 242)]\n",
      "Input: 0.077 MB, Params: 3,639,236 (13.883 MB), Total: 13.96 MB, FLOPs: 244,631,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1724 finished in 0m09s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.077 MB, Params: 3,633,123 (13.859 MB), Total: 13.94 MB, FLOPs: 244,404,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1724 finished in 0m09s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 115)]\n",
      "Input: 0.077 MB, Params: 3,629,881 (13.847 MB), Total: 13.92 MB, FLOPs: 243,897,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1724 finished in 0m09s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 222)]\n",
      "Input: 0.077 MB, Params: 3,623,768 (13.824 MB), Total: 13.90 MB, FLOPs: 243,671,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1724 finished in 0m09s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 228)]\n",
      "Input: 0.077 MB, Params: 3,620,634 (13.812 MB), Total: 13.89 MB, FLOPs: 243,445,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1724 finished in 0m09s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.077 MB, Params: 3,619,030 (13.806 MB), Total: 13.88 MB, FLOPs: 242,924,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1724 finished in 0m09s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 216)]\n",
      "Input: 0.077 MB, Params: 3,613,052 (13.783 MB), Total: 13.86 MB, FLOPs: 242,816,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1724 finished in 0m09s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 184)]\n",
      "Input: 0.077 MB, Params: 3,607,074 (13.760 MB), Total: 13.84 MB, FLOPs: 242,709,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1724 finished in 0m09s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.077 MB, Params: 3,601,096 (13.737 MB), Total: 13.81 MB, FLOPs: 242,601,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1724 finished in 0m09s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.077 MB, Params: 3,595,118 (13.714 MB), Total: 13.79 MB, FLOPs: 242,494,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1724 finished in 0m09s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 246)]\n",
      "Input: 0.077 MB, Params: 3,591,197 (13.699 MB), Total: 13.78 MB, FLOPs: 242,423,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1724 finished in 0m09s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.077 MB, Params: 3,585,129 (13.676 MB), Total: 13.75 MB, FLOPs: 242,198,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1724 finished in 0m09s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 160)]\n",
      "Input: 0.077 MB, Params: 3,579,169 (13.653 MB), Total: 13.73 MB, FLOPs: 242,090,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1724 finished in 0m09s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 349)]\n",
      "Input: 0.077 MB, Params: 3,573,209 (13.631 MB), Total: 13.71 MB, FLOPs: 241,983,624\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1724 finished in 0m09s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 86)]\n",
      "Input: 0.077 MB, Params: 3,567,159 (13.608 MB), Total: 13.68 MB, FLOPs: 241,758,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1724 finished in 0m09s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.077 MB, Params: 3,561,109 (13.585 MB), Total: 13.66 MB, FLOPs: 241,533,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1724 finished in 0m09s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 355)]\n",
      "Input: 0.077 MB, Params: 3,557,206 (13.570 MB), Total: 13.65 MB, FLOPs: 241,463,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1724 finished in 0m09s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 308)]\n",
      "Input: 0.077 MB, Params: 3,553,303 (13.555 MB), Total: 13.63 MB, FLOPs: 241,392,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1724 finished in 0m09s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 209)]\n",
      "Input: 0.077 MB, Params: 3,550,196 (13.543 MB), Total: 13.62 MB, FLOPs: 241,169,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1724 finished in 0m09s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.077 MB, Params: 3,544,272 (13.520 MB), Total: 13.60 MB, FLOPs: 241,062,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1724 finished in 0m09s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.077 MB, Params: 3,541,165 (13.508 MB), Total: 13.59 MB, FLOPs: 240,839,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1724 finished in 0m09s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 45)]\n",
      "Input: 0.077 MB, Params: 3,538,058 (13.497 MB), Total: 13.57 MB, FLOPs: 240,615,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1724 finished in 0m09s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 3,532,134 (13.474 MB), Total: 13.55 MB, FLOPs: 240,508,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1724 finished in 0m09s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.077 MB, Params: 3,526,210 (13.451 MB), Total: 13.53 MB, FLOPs: 240,402,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1724 finished in 0m09s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.077 MB, Params: 3,523,103 (13.440 MB), Total: 13.52 MB, FLOPs: 240,178,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1724 finished in 0m09s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 154)]\n",
      "Input: 0.077 MB, Params: 3,517,116 (13.417 MB), Total: 13.49 MB, FLOPs: 239,956,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1724 finished in 0m09s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 313)]\n",
      "Input: 0.077 MB, Params: 3,511,201 (13.394 MB), Total: 13.47 MB, FLOPs: 239,850,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1724 finished in 0m09s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.077 MB, Params: 3,507,334 (13.379 MB), Total: 13.46 MB, FLOPs: 239,780,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1724 finished in 0m09s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 84)]\n",
      "Input: 0.077 MB, Params: 3,501,356 (13.357 MB), Total: 13.43 MB, FLOPs: 239,558,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1724 finished in 0m09s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 197)]\n",
      "Input: 0.077 MB, Params: 3,498,267 (13.345 MB), Total: 13.42 MB, FLOPs: 239,336,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1724 finished in 0m09s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 229)]\n",
      "Input: 0.077 MB, Params: 3,495,178 (13.333 MB), Total: 13.41 MB, FLOPs: 239,113,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1724 finished in 0m09s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 405)]\n",
      "Input: 0.077 MB, Params: 3,491,311 (13.318 MB), Total: 13.40 MB, FLOPs: 239,044,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1724 finished in 0m09s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.077 MB, Params: 3,487,444 (13.304 MB), Total: 13.38 MB, FLOPs: 238,974,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1724 finished in 0m09s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.077 MB, Params: 3,483,577 (13.289 MB), Total: 13.37 MB, FLOPs: 238,905,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1724 finished in 0m09s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 345)]\n",
      "Input: 0.077 MB, Params: 3,477,707 (13.266 MB), Total: 13.34 MB, FLOPs: 238,799,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1724 finished in 0m09s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 248)]\n",
      "Input: 0.077 MB, Params: 3,471,837 (13.244 MB), Total: 13.32 MB, FLOPs: 238,693,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1724 finished in 0m09s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 406)]\n",
      "Input: 0.077 MB, Params: 3,465,967 (13.222 MB), Total: 13.30 MB, FLOPs: 238,588,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1724 finished in 0m09s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 391)]\n",
      "Input: 0.077 MB, Params: 3,460,097 (13.199 MB), Total: 13.28 MB, FLOPs: 238,482,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1724 finished in 0m09s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 101)]\n",
      "Input: 0.077 MB, Params: 3,458,493 (13.193 MB), Total: 13.27 MB, FLOPs: 237,961,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1724 finished in 0m09s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.077 MB, Params: 3,452,569 (13.171 MB), Total: 13.25 MB, FLOPs: 237,741,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1724 finished in 0m09s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 208)]\n",
      "Input: 0.077 MB, Params: 3,449,489 (13.159 MB), Total: 13.24 MB, FLOPs: 237,520,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1724 finished in 0m09s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 211)]\n",
      "Input: 0.077 MB, Params: 3,443,574 (13.136 MB), Total: 13.21 MB, FLOPs: 237,300,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1724 finished in 0m09s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 230)]\n",
      "Input: 0.077 MB, Params: 3,439,743 (13.122 MB), Total: 13.20 MB, FLOPs: 237,231,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1724 finished in 0m09s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 262)]\n",
      "Input: 0.077 MB, Params: 3,435,912 (13.107 MB), Total: 13.18 MB, FLOPs: 237,162,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1724 finished in 0m09s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.077 MB, Params: 3,432,081 (13.092 MB), Total: 13.17 MB, FLOPs: 237,094,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1724 finished in 0m09s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 283)]\n",
      "Input: 0.077 MB, Params: 3,426,256 (13.070 MB), Total: 13.15 MB, FLOPs: 236,989,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1724 finished in 0m09s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.077 MB, Params: 3,422,434 (13.056 MB), Total: 13.13 MB, FLOPs: 236,920,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1724 finished in 0m09s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 130)]\n",
      "Input: 0.077 MB, Params: 3,416,528 (13.033 MB), Total: 13.11 MB, FLOPs: 236,701,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1724 finished in 0m09s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.077 MB, Params: 3,412,706 (13.018 MB), Total: 13.10 MB, FLOPs: 236,632,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1724 finished in 0m09s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.077 MB, Params: 3,408,884 (13.004 MB), Total: 13.08 MB, FLOPs: 236,563,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1724 finished in 0m09s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 383)]\n",
      "Input: 0.077 MB, Params: 3,403,095 (12.982 MB), Total: 13.06 MB, FLOPs: 236,459,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1724 finished in 0m09s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.077 MB, Params: 3,397,306 (12.960 MB), Total: 13.04 MB, FLOPs: 236,355,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1724 finished in 0m09s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.077 MB, Params: 3,393,502 (12.945 MB), Total: 13.02 MB, FLOPs: 236,287,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1724 finished in 0m09s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.077 MB, Params: 3,387,722 (12.923 MB), Total: 13.00 MB, FLOPs: 236,183,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1724 finished in 0m09s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.077 MB, Params: 3,383,927 (12.909 MB), Total: 12.99 MB, FLOPs: 236,114,819\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1724 finished in 0m09s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 310)]\n",
      "Input: 0.077 MB, Params: 3,380,132 (12.894 MB), Total: 12.97 MB, FLOPs: 236,046,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1724 finished in 0m09s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 160)]\n",
      "Input: 0.077 MB, Params: 3,374,370 (12.872 MB), Total: 12.95 MB, FLOPs: 235,942,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1724 finished in 0m09s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 210)]\n",
      "Input: 0.077 MB, Params: 3,371,308 (12.861 MB), Total: 12.94 MB, FLOPs: 235,722,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1724 finished in 0m09s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 290)]\n",
      "Input: 0.077 MB, Params: 3,365,546 (12.839 MB), Total: 12.92 MB, FLOPs: 235,618,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1724 finished in 0m09s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 367)]\n",
      "Input: 0.077 MB, Params: 3,359,784 (12.817 MB), Total: 12.89 MB, FLOPs: 235,515,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1724 finished in 0m09s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.077 MB, Params: 3,354,022 (12.795 MB), Total: 12.87 MB, FLOPs: 235,411,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1724 finished in 0m09s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 155)]\n",
      "Input: 0.077 MB, Params: 3,348,188 (12.772 MB), Total: 12.85 MB, FLOPs: 235,194,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1724 finished in 0m09s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 226)]\n",
      "Input: 0.077 MB, Params: 3,342,435 (12.750 MB), Total: 12.83 MB, FLOPs: 235,090,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1724 finished in 0m09s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.077 MB, Params: 3,340,831 (12.744 MB), Total: 12.82 MB, FLOPs: 234,569,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1724 finished in 0m09s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 400)]\n",
      "Input: 0.077 MB, Params: 3,337,081 (12.730 MB), Total: 12.81 MB, FLOPs: 234,502,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1724 finished in 0m09s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.077 MB, Params: 3,333,331 (12.716 MB), Total: 12.79 MB, FLOPs: 234,434,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1724 finished in 0m09s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 343)]\n",
      "Input: 0.077 MB, Params: 3,327,596 (12.694 MB), Total: 12.77 MB, FLOPs: 234,331,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1724 finished in 0m09s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.077 MB, Params: 3,324,543 (12.682 MB), Total: 12.76 MB, FLOPs: 234,111,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1724 finished in 0m09s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 10)]\n",
      "Input: 0.077 MB, Params: 3,324,501 (12.682 MB), Total: 12.76 MB, FLOPs: 231,433,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1724 finished in 0m09s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.077 MB, Params: 3,320,760 (12.668 MB), Total: 12.74 MB, FLOPs: 231,366,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1724 finished in 0m09s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 87)]\n",
      "Input: 0.077 MB, Params: 3,317,635 (12.656 MB), Total: 12.73 MB, FLOPs: 230,874,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1724 finished in 0m09s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.077 MB, Params: 3,317,066 (12.654 MB), Total: 12.73 MB, FLOPs: 230,090,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 31.148%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1724 finished in 0m09s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 144)]\n",
      "Input: 0.077 MB, Params: 3,314,022 (12.642 MB), Total: 12.72 MB, FLOPs: 229,871,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1724 finished in 0m09s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 258)]\n",
      "Input: 0.077 MB, Params: 3,310,281 (12.628 MB), Total: 12.70 MB, FLOPs: 229,804,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1724 finished in 0m09s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 355)]\n",
      "Input: 0.077 MB, Params: 3,304,564 (12.606 MB), Total: 12.68 MB, FLOPs: 229,701,320\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1724 finished in 0m09s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.077 MB, Params: 3,300,832 (12.592 MB), Total: 12.67 MB, FLOPs: 229,634,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1724 finished in 0m09s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 86)]\n",
      "Input: 0.077 MB, Params: 3,299,237 (12.586 MB), Total: 12.66 MB, FLOPs: 229,116,160\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1724 finished in 0m09s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.077 MB, Params: 3,295,505 (12.571 MB), Total: 12.65 MB, FLOPs: 229,049,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1724 finished in 0m09s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 3,291,773 (12.557 MB), Total: 12.63 MB, FLOPs: 228,981,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1724 finished in 0m09s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 321)]\n",
      "Input: 0.077 MB, Params: 3,286,083 (12.535 MB), Total: 12.61 MB, FLOPs: 228,879,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1724 finished in 0m09s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 379)]\n",
      "Input: 0.077 MB, Params: 3,282,360 (12.521 MB), Total: 12.60 MB, FLOPs: 228,812,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1724 finished in 0m09s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 117)]\n",
      "Input: 0.077 MB, Params: 3,276,679 (12.500 MB), Total: 12.58 MB, FLOPs: 228,710,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1724 finished in 0m09s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.077 MB, Params: 3,272,965 (12.485 MB), Total: 12.56 MB, FLOPs: 228,643,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1724 finished in 0m09s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.077 MB, Params: 3,267,293 (12.464 MB), Total: 12.54 MB, FLOPs: 228,541,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1724 finished in 0m09s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 356)]\n",
      "Input: 0.077 MB, Params: 3,261,621 (12.442 MB), Total: 12.52 MB, FLOPs: 228,439,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1724 finished in 0m09s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 12)]\n",
      "Input: 0.077 MB, Params: 3,261,052 (12.440 MB), Total: 12.52 MB, FLOPs: 227,655,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1724 finished in 0m09s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 405)]\n",
      "Input: 0.077 MB, Params: 3,255,380 (12.418 MB), Total: 12.50 MB, FLOPs: 227,553,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1724 finished in 0m09s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 164)]\n",
      "Input: 0.077 MB, Params: 3,249,636 (12.396 MB), Total: 12.47 MB, FLOPs: 227,338,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1724 finished in 0m09s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.077 MB, Params: 3,243,973 (12.375 MB), Total: 12.45 MB, FLOPs: 227,237,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1724 finished in 0m09s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.077 MB, Params: 3,240,866 (12.363 MB), Total: 12.44 MB, FLOPs: 226,748,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1724 finished in 0m09s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.077 MB, Params: 3,235,203 (12.341 MB), Total: 12.42 MB, FLOPs: 226,646,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1724 finished in 0m09s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.077 MB, Params: 3,229,540 (12.320 MB), Total: 12.40 MB, FLOPs: 226,544,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1724 finished in 0m09s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 405)]\n",
      "Input: 0.077 MB, Params: 3,223,877 (12.298 MB), Total: 12.37 MB, FLOPs: 226,442,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1724 finished in 0m09s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.077 MB, Params: 3,222,291 (12.292 MB), Total: 12.37 MB, FLOPs: 225,927,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1724 finished in 0m09s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 8)]\n",
      "Input: 0.077 MB, Params: 3,220,696 (12.286 MB), Total: 12.36 MB, FLOPs: 224,863,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1724 finished in 0m09s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 237)]\n",
      "Input: 0.077 MB, Params: 3,217,045 (12.272 MB), Total: 12.35 MB, FLOPs: 224,797,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1724 finished in 0m09s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 50)]\n",
      "Input: 0.077 MB, Params: 3,217,003 (12.272 MB), Total: 12.35 MB, FLOPs: 224,560,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1724 finished in 0m09s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.077 MB, Params: 3,211,295 (12.250 MB), Total: 12.33 MB, FLOPs: 224,346,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1724 finished in 0m09s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 34)]\n",
      "Input: 0.077 MB, Params: 3,210,537 (12.247 MB), Total: 12.32 MB, FLOPs: 223,362,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1724 finished in 0m09s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 18)]\n",
      "Input: 0.077 MB, Params: 3,208,951 (12.241 MB), Total: 12.32 MB, FLOPs: 222,309,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1724 finished in 0m09s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.077 MB, Params: 3,208,909 (12.241 MB), Total: 12.32 MB, FLOPs: 215,268,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1724 finished in 0m09s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 213)]\n",
      "Input: 0.077 MB, Params: 3,205,892 (12.230 MB), Total: 12.31 MB, FLOPs: 215,051,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1724 finished in 0m09s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 3,200,247 (12.208 MB), Total: 12.28 MB, FLOPs: 214,950,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1724 finished in 0m09s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 323)]\n",
      "Input: 0.077 MB, Params: 3,194,602 (12.186 MB), Total: 12.26 MB, FLOPs: 214,848,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1724 finished in 0m09s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.077 MB, Params: 3,193,016 (12.180 MB), Total: 12.26 MB, FLOPs: 213,849,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1724 finished in 0m09s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.077 MB, Params: 3,189,999 (12.169 MB), Total: 12.25 MB, FLOPs: 213,632,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1724 finished in 0m09s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 117)]\n",
      "Input: 0.077 MB, Params: 3,184,327 (12.147 MB), Total: 12.22 MB, FLOPs: 213,419,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1724 finished in 0m09s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 286)]\n",
      "Input: 0.077 MB, Params: 3,178,691 (12.126 MB), Total: 12.20 MB, FLOPs: 213,318,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1724 finished in 0m09s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 104)]\n",
      "Input: 0.077 MB, Params: 3,175,683 (12.114 MB), Total: 12.19 MB, FLOPs: 213,101,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1724 finished in 0m09s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.077 MB, Params: 3,172,059 (12.100 MB), Total: 12.18 MB, FLOPs: 213,036,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1724 finished in 0m09s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.077 MB, Params: 3,169,051 (12.089 MB), Total: 12.17 MB, FLOPs: 212,820,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1724 finished in 0m09s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 11)]\n",
      "Input: 0.077 MB, Params: 3,167,492 (12.083 MB), Total: 12.16 MB, FLOPs: 212,352,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1724 finished in 0m09s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.077 MB, Params: 3,165,933 (12.077 MB), Total: 12.15 MB, FLOPs: 211,885,288\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1724 finished in 0m09s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 15)]\n",
      "Input: 0.077 MB, Params: 3,162,889 (12.065 MB), Total: 12.14 MB, FLOPs: 211,433,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1724 finished in 0m09s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.077 MB, Params: 3,157,262 (12.044 MB), Total: 12.12 MB, FLOPs: 211,332,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1724 finished in 0m09s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 179)]\n",
      "Input: 0.077 MB, Params: 3,151,635 (12.023 MB), Total: 12.10 MB, FLOPs: 211,231,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1724 finished in 0m09s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 196)]\n",
      "Input: 0.077 MB, Params: 3,146,008 (12.001 MB), Total: 12.08 MB, FLOPs: 211,020,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1724 finished in 0m09s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 298)]\n",
      "Input: 0.077 MB, Params: 3,140,390 (11.980 MB), Total: 12.06 MB, FLOPs: 210,919,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1724 finished in 0m09s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.077 MB, Params: 3,137,400 (11.968 MB), Total: 12.05 MB, FLOPs: 210,704,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1724 finished in 0m09s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.077 MB, Params: 3,131,782 (11.947 MB), Total: 12.02 MB, FLOPs: 210,603,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1724 finished in 0m09s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 43)]\n",
      "Input: 0.077 MB, Params: 3,131,042 (11.944 MB), Total: 12.02 MB, FLOPs: 209,679,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1724 finished in 0m09s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 243)]\n",
      "Input: 0.077 MB, Params: 3,125,424 (11.923 MB), Total: 12.00 MB, FLOPs: 209,578,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1724 finished in 0m09s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.077 MB, Params: 3,122,434 (11.911 MB), Total: 11.99 MB, FLOPs: 209,363,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1724 finished in 0m09s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.077 MB, Params: 3,119,444 (11.900 MB), Total: 11.98 MB, FLOPs: 209,147,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1724 finished in 0m09s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 323)]\n",
      "Input: 0.077 MB, Params: 3,115,865 (11.886 MB), Total: 11.96 MB, FLOPs: 209,083,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1724 finished in 0m09s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 138)]\n",
      "Input: 0.077 MB, Params: 3,110,292 (11.865 MB), Total: 11.94 MB, FLOPs: 208,875,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1724 finished in 0m09s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.077 MB, Params: 3,104,692 (11.843 MB), Total: 11.92 MB, FLOPs: 208,774,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1724 finished in 0m09s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.077 MB, Params: 3,104,650 (11.843 MB), Total: 11.92 MB, FLOPs: 208,536,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1724 finished in 0m09s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.077 MB, Params: 3,099,086 (11.822 MB), Total: 11.90 MB, FLOPs: 208,328,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1724 finished in 0m09s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.077 MB, Params: 3,097,536 (11.816 MB), Total: 11.89 MB, FLOPs: 207,864,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1724 finished in 0m09s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.077 MB, Params: 3,091,945 (11.795 MB), Total: 11.87 MB, FLOPs: 207,763,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1724 finished in 0m09s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.077 MB, Params: 3,088,384 (11.781 MB), Total: 11.86 MB, FLOPs: 207,699,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1724 finished in 0m09s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 328)]\n",
      "Input: 0.077 MB, Params: 3,084,823 (11.768 MB), Total: 11.84 MB, FLOPs: 207,635,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1724 finished in 0m09s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.077 MB, Params: 3,079,250 (11.746 MB), Total: 11.82 MB, FLOPs: 207,535,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1724 finished in 0m09s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 351)]\n",
      "Input: 0.077 MB, Params: 3,073,677 (11.725 MB), Total: 11.80 MB, FLOPs: 207,434,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1724 finished in 0m09s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 3,070,705 (11.714 MB), Total: 11.79 MB, FLOPs: 207,220,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1724 finished in 0m09s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.077 MB, Params: 3,067,162 (11.700 MB), Total: 11.78 MB, FLOPs: 207,157,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1724 finished in 0m09s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 249)]\n",
      "Input: 0.077 MB, Params: 3,061,598 (11.679 MB), Total: 11.76 MB, FLOPs: 207,057,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1724 finished in 0m09s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 299)]\n",
      "Input: 0.077 MB, Params: 3,058,064 (11.666 MB), Total: 11.74 MB, FLOPs: 206,993,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1724 finished in 0m09s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 92)]\n",
      "Input: 0.077 MB, Params: 3,055,092 (11.654 MB), Total: 11.73 MB, FLOPs: 206,779,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1724 finished in 0m09s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 295)]\n",
      "Input: 0.077 MB, Params: 3,049,537 (11.633 MB), Total: 11.71 MB, FLOPs: 206,679,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1724 finished in 0m09s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.077 MB, Params: 3,046,012 (11.620 MB), Total: 11.70 MB, FLOPs: 206,616,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1724 finished in 0m09s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 113)]\n",
      "Input: 0.077 MB, Params: 3,040,466 (11.598 MB), Total: 11.68 MB, FLOPs: 206,516,476\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1724 finished in 0m09s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.077 MB, Params: 3,034,920 (11.577 MB), Total: 11.65 MB, FLOPs: 206,416,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1724 finished in 0m09s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.077 MB, Params: 3,029,374 (11.556 MB), Total: 11.63 MB, FLOPs: 206,316,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1724 finished in 0m09s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 3,025,876 (11.543 MB), Total: 11.62 MB, FLOPs: 206,253,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1724 finished in 0m09s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 125)]\n",
      "Input: 0.077 MB, Params: 3,020,339 (11.522 MB), Total: 11.60 MB, FLOPs: 206,154,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1724 finished in 0m09s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 3,016,850 (11.508 MB), Total: 11.59 MB, FLOPs: 206,091,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1724 finished in 0m09s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 129)]\n",
      "Input: 0.077 MB, Params: 3,011,385 (11.488 MB), Total: 11.56 MB, FLOPs: 205,886,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1724 finished in 0m09s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 88)]\n",
      "Input: 0.077 MB, Params: 3,008,422 (11.476 MB), Total: 11.55 MB, FLOPs: 205,672,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1724 finished in 0m09s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 266)]\n",
      "Input: 0.077 MB, Params: 3,004,933 (11.463 MB), Total: 11.54 MB, FLOPs: 205,610,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1724 finished in 0m09s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.077 MB, Params: 2,999,423 (11.442 MB), Total: 11.52 MB, FLOPs: 205,511,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1724 finished in 0m09s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 311)]\n",
      "Input: 0.077 MB, Params: 2,993,913 (11.421 MB), Total: 11.50 MB, FLOPs: 205,411,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1724 finished in 0m09s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.077 MB, Params: 2,988,403 (11.400 MB), Total: 11.48 MB, FLOPs: 205,312,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1724 finished in 0m09s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 53)]\n",
      "Input: 0.077 MB, Params: 2,985,440 (11.389 MB), Total: 11.47 MB, FLOPs: 205,099,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1724 finished in 0m09s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 209)]\n",
      "Input: 0.077 MB, Params: 2,982,477 (11.377 MB), Total: 11.45 MB, FLOPs: 204,886,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1724 finished in 0m09s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.077 MB, Params: 2,976,967 (11.356 MB), Total: 11.43 MB, FLOPs: 204,787,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1724 finished in 0m09s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 54)]\n",
      "Input: 0.077 MB, Params: 2,971,457 (11.335 MB), Total: 11.41 MB, FLOPs: 204,687,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1724 finished in 0m09s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 150)]\n",
      "Input: 0.077 MB, Params: 2,966,064 (11.315 MB), Total: 11.39 MB, FLOPs: 204,485,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1724 finished in 0m09s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.077 MB, Params: 2,960,563 (11.294 MB), Total: 11.37 MB, FLOPs: 204,386,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1724 finished in 0m09s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.077 MB, Params: 2,957,128 (11.281 MB), Total: 11.36 MB, FLOPs: 204,324,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1724 finished in 0m09s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 132)]\n",
      "Input: 0.077 MB, Params: 2,953,693 (11.267 MB), Total: 11.34 MB, FLOPs: 204,262,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1724 finished in 0m09s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.077 MB, Params: 2,950,739 (11.256 MB), Total: 11.33 MB, FLOPs: 204,050,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1724 finished in 0m09s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 220)]\n",
      "Input: 0.077 MB, Params: 2,945,256 (11.235 MB), Total: 11.31 MB, FLOPs: 203,951,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1724 finished in 0m09s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.077 MB, Params: 2,939,773 (11.214 MB), Total: 11.29 MB, FLOPs: 203,852,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1724 finished in 0m09s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 94)]\n",
      "Input: 0.077 MB, Params: 2,936,819 (11.203 MB), Total: 11.28 MB, FLOPs: 203,640,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1724 finished in 0m09s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 348)]\n",
      "Input: 0.077 MB, Params: 2,931,336 (11.182 MB), Total: 11.26 MB, FLOPs: 203,541,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1724 finished in 0m09s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.077 MB, Params: 2,927,928 (11.169 MB), Total: 11.25 MB, FLOPs: 203,480,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1724 finished in 0m09s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.077 MB, Params: 2,922,454 (11.148 MB), Total: 11.23 MB, FLOPs: 203,381,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1724 finished in 0m09s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.077 MB, Params: 2,921,714 (11.145 MB), Total: 11.22 MB, FLOPs: 202,457,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1724 finished in 0m09s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 140)]\n",
      "Input: 0.077 MB, Params: 2,918,760 (11.134 MB), Total: 11.21 MB, FLOPs: 202,245,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1724 finished in 0m09s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 111)]\n",
      "Input: 0.077 MB, Params: 2,915,806 (11.123 MB), Total: 11.20 MB, FLOPs: 202,032,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1724 finished in 0m09s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 134)]\n",
      "Input: 0.077 MB, Params: 2,912,852 (11.112 MB), Total: 11.19 MB, FLOPs: 201,820,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1724 finished in 0m09s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.077 MB, Params: 2,907,549 (11.091 MB), Total: 11.17 MB, FLOPs: 201,621,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1724 finished in 0m09s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.077 MB, Params: 2,902,084 (11.071 MB), Total: 11.15 MB, FLOPs: 201,523,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1724 finished in 0m09s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 327)]\n",
      "Input: 0.077 MB, Params: 2,896,619 (11.050 MB), Total: 11.13 MB, FLOPs: 201,424,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1724 finished in 0m09s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 362)]\n",
      "Input: 0.077 MB, Params: 2,891,154 (11.029 MB), Total: 11.11 MB, FLOPs: 201,326,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1724 finished in 0m09s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.077 MB, Params: 2,885,689 (11.008 MB), Total: 11.08 MB, FLOPs: 201,228,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1724 finished in 0m09s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 383)]\n",
      "Input: 0.077 MB, Params: 2,882,326 (10.995 MB), Total: 11.07 MB, FLOPs: 201,167,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1724 finished in 0m09s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.077 MB, Params: 2,876,870 (10.974 MB), Total: 11.05 MB, FLOPs: 201,069,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1724 finished in 0m09s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.077 MB, Params: 2,873,925 (10.963 MB), Total: 11.04 MB, FLOPs: 200,857,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1724 finished in 0m09s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.077 MB, Params: 2,872,384 (10.957 MB), Total: 11.03 MB, FLOPs: 199,888,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1724 finished in 0m09s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.077 MB, Params: 2,866,928 (10.936 MB), Total: 11.01 MB, FLOPs: 199,790,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1724 finished in 0m09s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 144)]\n",
      "Input: 0.077 MB, Params: 2,863,983 (10.925 MB), Total: 11.00 MB, FLOPs: 199,578,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1724 finished in 0m09s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 55)]\n",
      "Input: 0.077 MB, Params: 2,863,252 (10.922 MB), Total: 11.00 MB, FLOPs: 198,666,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1724 finished in 0m09s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.077 MB, Params: 2,859,907 (10.910 MB), Total: 10.99 MB, FLOPs: 198,605,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1724 finished in 0m09s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.077 MB, Params: 2,858,366 (10.904 MB), Total: 10.98 MB, FLOPs: 198,143,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1724 finished in 0m09s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.077 MB, Params: 2,852,919 (10.883 MB), Total: 10.96 MB, FLOPs: 198,045,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1724 finished in 0m09s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.077 MB, Params: 2,849,583 (10.870 MB), Total: 10.95 MB, FLOPs: 197,985,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1724 finished in 0m09s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 308)]\n",
      "Input: 0.077 MB, Params: 2,844,145 (10.850 MB), Total: 10.93 MB, FLOPs: 197,888,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1724 finished in 0m09s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.077 MB, Params: 2,838,932 (10.830 MB), Total: 10.91 MB, FLOPs: 197,692,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1724 finished in 0m09s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 165)]\n",
      "Input: 0.077 MB, Params: 2,833,719 (10.810 MB), Total: 10.89 MB, FLOPs: 197,496,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1724 finished in 0m09s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 194)]\n",
      "Input: 0.077 MB, Params: 2,828,299 (10.789 MB), Total: 10.87 MB, FLOPs: 197,398,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1724 finished in 0m09s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 90)]\n",
      "Input: 0.077 MB, Params: 2,825,408 (10.778 MB), Total: 10.85 MB, FLOPs: 196,962,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1724 finished in 0m09s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 167)]\n",
      "Input: 0.077 MB, Params: 2,822,090 (10.765 MB), Total: 10.84 MB, FLOPs: 196,902,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1724 finished in 0m09s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 89)]\n",
      "Input: 0.077 MB, Params: 2,816,679 (10.745 MB), Total: 10.82 MB, FLOPs: 196,805,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1724 finished in 0m09s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 384)]\n",
      "Input: 0.077 MB, Params: 2,813,370 (10.732 MB), Total: 10.81 MB, FLOPs: 196,745,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1724 finished in 0m09s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 229)]\n",
      "Input: 0.077 MB, Params: 2,807,968 (10.712 MB), Total: 10.79 MB, FLOPs: 196,648,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1724 finished in 0m09s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.077 MB, Params: 2,802,566 (10.691 MB), Total: 10.77 MB, FLOPs: 196,551,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1724 finished in 0m09s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.077 MB, Params: 2,799,275 (10.678 MB), Total: 10.76 MB, FLOPs: 196,492,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1724 finished in 0m09s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 169)]\n",
      "Input: 0.077 MB, Params: 2,796,357 (10.667 MB), Total: 10.74 MB, FLOPs: 196,282,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1724 finished in 0m09s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 2,790,964 (10.647 MB), Total: 10.72 MB, FLOPs: 196,184,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1724 finished in 0m09s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 315)]\n",
      "Input: 0.077 MB, Params: 2,785,571 (10.626 MB), Total: 10.70 MB, FLOPs: 196,087,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1724 finished in 0m09s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 149)]\n",
      "Input: 0.077 MB, Params: 2,782,653 (10.615 MB), Total: 10.69 MB, FLOPs: 195,877,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1724 finished in 0m09s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.077 MB, Params: 2,777,260 (10.594 MB), Total: 10.67 MB, FLOPs: 195,780,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1724 finished in 0m09s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.077 MB, Params: 2,771,867 (10.574 MB), Total: 10.65 MB, FLOPs: 195,683,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1724 finished in 0m09s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.077 MB, Params: 2,768,612 (10.561 MB), Total: 10.64 MB, FLOPs: 195,625,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1724 finished in 0m09s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 256)]\n",
      "Input: 0.077 MB, Params: 2,765,357 (10.549 MB), Total: 10.63 MB, FLOPs: 195,566,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1724 finished in 0m09s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 2,760,234 (10.529 MB), Total: 10.61 MB, FLOPs: 195,373,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1724 finished in 0m09s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.077 MB, Params: 2,756,979 (10.517 MB), Total: 10.59 MB, FLOPs: 195,314,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1724 finished in 0m09s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 33)]\n",
      "Input: 0.077 MB, Params: 2,756,937 (10.517 MB), Total: 10.59 MB, FLOPs: 192,952,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1724 finished in 0m09s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.077 MB, Params: 2,751,580 (10.496 MB), Total: 10.57 MB, FLOPs: 192,856,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1724 finished in 0m09s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 199)]\n",
      "Input: 0.077 MB, Params: 2,746,466 (10.477 MB), Total: 10.55 MB, FLOPs: 192,662,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1724 finished in 0m09s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 40)]\n",
      "Input: 0.077 MB, Params: 2,741,352 (10.457 MB), Total: 10.53 MB, FLOPs: 192,469,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1724 finished in 0m09s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 60)]\n",
      "Input: 0.077 MB, Params: 2,738,461 (10.446 MB), Total: 10.52 MB, FLOPs: 192,261,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1724 finished in 0m09s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.077 MB, Params: 2,735,570 (10.435 MB), Total: 10.51 MB, FLOPs: 192,053,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1724 finished in 0m09s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 261)]\n",
      "Input: 0.077 MB, Params: 2,730,231 (10.415 MB), Total: 10.49 MB, FLOPs: 191,957,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1724 finished in 0m09s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.077 MB, Params: 2,726,994 (10.403 MB), Total: 10.48 MB, FLOPs: 191,899,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1724 finished in 0m09s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 35)]\n",
      "Input: 0.077 MB, Params: 2,726,952 (10.402 MB), Total: 10.48 MB, FLOPs: 191,661,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1724 finished in 0m09s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 225)]\n",
      "Input: 0.077 MB, Params: 2,723,715 (10.390 MB), Total: 10.47 MB, FLOPs: 191,603,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1724 finished in 0m09s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 2,718,394 (10.370 MB), Total: 10.45 MB, FLOPs: 191,507,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1724 finished in 0m09s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.077 MB, Params: 2,716,862 (10.364 MB), Total: 10.44 MB, FLOPs: 191,048,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1724 finished in 0m09s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 274)]\n",
      "Input: 0.077 MB, Params: 2,713,634 (10.352 MB), Total: 10.43 MB, FLOPs: 190,990,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1724 finished in 0m09s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 6)]\n",
      "Input: 0.077 MB, Params: 2,712,120 (10.346 MB), Total: 10.42 MB, FLOPs: 190,064,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1724 finished in 0m09s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.077 MB, Params: 2,708,892 (10.334 MB), Total: 10.41 MB, FLOPs: 190,006,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1724 finished in 0m09s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 177)]\n",
      "Input: 0.077 MB, Params: 2,706,001 (10.323 MB), Total: 10.40 MB, FLOPs: 189,798,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1724 finished in 0m09s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.077 MB, Params: 2,702,773 (10.310 MB), Total: 10.39 MB, FLOPs: 189,740,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1724 finished in 0m09s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 70)]\n",
      "Input: 0.077 MB, Params: 2,699,936 (10.299 MB), Total: 10.38 MB, FLOPs: 189,310,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1724 finished in 0m09s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.077 MB, Params: 2,694,642 (10.279 MB), Total: 10.36 MB, FLOPs: 189,214,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1724 finished in 0m09s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.077 MB, Params: 2,689,348 (10.259 MB), Total: 10.34 MB, FLOPs: 189,119,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1724 finished in 0m09s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.077 MB, Params: 2,684,297 (10.240 MB), Total: 10.32 MB, FLOPs: 188,928,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1724 finished in 0m09s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.077 MB, Params: 2,682,783 (10.234 MB), Total: 10.31 MB, FLOPs: 188,474,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1724 finished in 0m09s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 183)]\n",
      "Input: 0.077 MB, Params: 2,679,910 (10.223 MB), Total: 10.30 MB, FLOPs: 188,268,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1724 finished in 0m09s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.077 MB, Params: 2,676,700 (10.211 MB), Total: 10.29 MB, FLOPs: 188,210,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1724 finished in 0m09s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.077 MB, Params: 2,671,424 (10.191 MB), Total: 10.27 MB, FLOPs: 188,115,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1724 finished in 0m09s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.077 MB, Params: 2,666,391 (10.171 MB), Total: 10.25 MB, FLOPs: 187,925,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1724 finished in 0m09s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.077 MB, Params: 2,661,124 (10.151 MB), Total: 10.23 MB, FLOPs: 187,830,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1724 finished in 0m09s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.077 MB, Params: 2,655,857 (10.131 MB), Total: 10.21 MB, FLOPs: 187,736,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1724 finished in 0m09s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.077 MB, Params: 2,650,842 (10.112 MB), Total: 10.19 MB, FLOPs: 187,546,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1724 finished in 0m09s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.077 MB, Params: 2,645,584 (10.092 MB), Total: 10.17 MB, FLOPs: 187,451,910\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1724 finished in 0m09s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 170)]\n",
      "Input: 0.077 MB, Params: 2,640,326 (10.072 MB), Total: 10.15 MB, FLOPs: 187,357,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1724 finished in 0m09s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 64)]\n",
      "Input: 0.077 MB, Params: 2,635,329 (10.053 MB), Total: 10.13 MB, FLOPs: 187,168,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1724 finished in 0m09s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 246)]\n",
      "Input: 0.077 MB, Params: 2,632,164 (10.041 MB), Total: 10.12 MB, FLOPs: 187,111,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1724 finished in 0m09s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 135)]\n",
      "Input: 0.077 MB, Params: 2,627,167 (10.022 MB), Total: 10.10 MB, FLOPs: 186,921,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1724 finished in 0m09s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 2,622,170 (10.003 MB), Total: 10.08 MB, FLOPs: 186,732,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1724 finished in 0m09s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 314)]\n",
      "Input: 0.077 MB, Params: 2,619,005 (9.991 MB), Total: 10.07 MB, FLOPs: 186,675,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1724 finished in 0m09s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.077 MB, Params: 2,613,792 (9.971 MB), Total: 10.05 MB, FLOPs: 186,582,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1724 finished in 0m09s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.077 MB, Params: 2,610,636 (9.959 MB), Total: 10.04 MB, FLOPs: 186,525,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1724 finished in 0m09s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.077 MB, Params: 2,605,432 (9.939 MB), Total: 10.02 MB, FLOPs: 186,431,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1724 finished in 0m09s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.077 MB, Params: 2,602,604 (9.928 MB), Total: 10.01 MB, FLOPs: 186,228,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1724 finished in 0m09s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.077 MB, Params: 2,597,400 (9.908 MB), Total: 9.99 MB, FLOPs: 186,134,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1724 finished in 0m09s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 197)]\n",
      "Input: 0.077 MB, Params: 2,594,572 (9.898 MB), Total: 9.97 MB, FLOPs: 185,930,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1724 finished in 0m09s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.077 MB, Params: 2,589,368 (9.878 MB), Total: 9.95 MB, FLOPs: 185,837,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1724 finished in 0m09s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.077 MB, Params: 2,586,239 (9.866 MB), Total: 9.94 MB, FLOPs: 185,781,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1724 finished in 0m09s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.077 MB, Params: 2,583,411 (9.855 MB), Total: 9.93 MB, FLOPs: 185,577,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1724 finished in 0m09s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.077 MB, Params: 2,578,216 (9.835 MB), Total: 9.91 MB, FLOPs: 185,483,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1724 finished in 0m09s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 237)]\n",
      "Input: 0.077 MB, Params: 2,575,096 (9.823 MB), Total: 9.90 MB, FLOPs: 185,427,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1724 finished in 0m09s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 2,569,910 (9.803 MB), Total: 9.88 MB, FLOPs: 185,334,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1724 finished in 0m09s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.077 MB, Params: 2,564,724 (9.784 MB), Total: 9.86 MB, FLOPs: 185,241,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1724 finished in 0m09s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.077 MB, Params: 2,561,932 (9.773 MB), Total: 9.85 MB, FLOPs: 184,816,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1724 finished in 0m09s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 47)]\n",
      "Input: 0.077 MB, Params: 2,561,890 (9.773 MB), Total: 9.85 MB, FLOPs: 160,859,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1724 finished in 0m09s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 194)]\n",
      "Input: 0.077 MB, Params: 2,556,983 (9.754 MB), Total: 9.83 MB, FLOPs: 160,713,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1724 finished in 0m09s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 14)]\n",
      "Input: 0.077 MB, Params: 2,556,941 (9.754 MB), Total: 9.83 MB, FLOPs: 160,476,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1724 finished in 0m09s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.077 MB, Params: 2,553,839 (9.742 MB), Total: 9.82 MB, FLOPs: 160,439,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1724 finished in 0m09s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 99)]\n",
      "Input: 0.077 MB, Params: 2,551,047 (9.731 MB), Total: 9.81 MB, FLOPs: 160,060,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1724 finished in 0m09s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.077 MB, Params: 2,545,879 (9.712 MB), Total: 9.79 MB, FLOPs: 159,998,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1724 finished in 0m09s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.077 MB, Params: 2,542,786 (9.700 MB), Total: 9.78 MB, FLOPs: 159,961,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1724 finished in 0m09s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 92)]\n",
      "Input: 0.077 MB, Params: 2,539,985 (9.689 MB), Total: 9.77 MB, FLOPs: 159,793,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1724 finished in 0m09s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 118)]\n",
      "Input: 0.077 MB, Params: 2,535,096 (9.671 MB), Total: 9.75 MB, FLOPs: 159,648,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1724 finished in 0m09s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 2,532,313 (9.660 MB), Total: 9.74 MB, FLOPs: 159,269,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1724 finished in 0m09s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.077 MB, Params: 2,531,780 (9.658 MB), Total: 9.73 MB, FLOPs: 158,618,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1724 finished in 0m09s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.077 MB, Params: 2,526,891 (9.639 MB), Total: 9.72 MB, FLOPs: 158,473,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1724 finished in 0m09s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.077 MB, Params: 2,523,798 (9.628 MB), Total: 9.70 MB, FLOPs: 158,436,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1724 finished in 0m09s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 342)]\n",
      "Input: 0.077 MB, Params: 2,520,705 (9.616 MB), Total: 9.69 MB, FLOPs: 158,399,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1724 finished in 0m09s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.077 MB, Params: 2,517,612 (9.604 MB), Total: 9.68 MB, FLOPs: 158,362,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1724 finished in 0m09s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 166)]\n",
      "Input: 0.077 MB, Params: 2,512,498 (9.584 MB), Total: 9.66 MB, FLOPs: 158,301,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1724 finished in 0m09s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.077 MB, Params: 2,507,384 (9.565 MB), Total: 9.64 MB, FLOPs: 158,239,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1724 finished in 0m09s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.077 MB, Params: 2,502,270 (9.545 MB), Total: 9.62 MB, FLOPs: 158,178,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1724 finished in 0m09s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.077 MB, Params: 2,497,156 (9.526 MB), Total: 9.60 MB, FLOPs: 158,117,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1724 finished in 0m09s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 333)]\n",
      "Input: 0.077 MB, Params: 2,494,099 (9.514 MB), Total: 9.59 MB, FLOPs: 158,080,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1724 finished in 0m09s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 2,491,042 (9.503 MB), Total: 9.58 MB, FLOPs: 158,043,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1724 finished in 0m09s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 366)]\n",
      "Input: 0.077 MB, Params: 2,487,985 (9.491 MB), Total: 9.57 MB, FLOPs: 158,007,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1724 finished in 0m09s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 276)]\n",
      "Input: 0.077 MB, Params: 2,482,898 (9.472 MB), Total: 9.55 MB, FLOPs: 157,946,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1724 finished in 0m09s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.077 MB, Params: 2,478,054 (9.453 MB), Total: 9.53 MB, FLOPs: 157,801,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1724 finished in 0m09s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.077 MB, Params: 2,472,976 (9.434 MB), Total: 9.51 MB, FLOPs: 157,740,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1724 finished in 0m09s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 56)]\n",
      "Input: 0.077 MB, Params: 2,470,193 (9.423 MB), Total: 9.50 MB, FLOPs: 157,362,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1724 finished in 0m09s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 80)]\n",
      "Input: 0.077 MB, Params: 2,468,715 (9.417 MB), Total: 9.49 MB, FLOPs: 156,956,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1724 finished in 0m09s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.077 MB, Params: 2,463,637 (9.398 MB), Total: 9.47 MB, FLOPs: 156,895,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1724 finished in 0m09s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 269)]\n",
      "Input: 0.077 MB, Params: 2,460,607 (9.386 MB), Total: 9.46 MB, FLOPs: 156,858,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1724 finished in 0m09s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.077 MB, Params: 2,455,538 (9.367 MB), Total: 9.44 MB, FLOPs: 156,798,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1724 finished in 0m09s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 179)]\n",
      "Input: 0.077 MB, Params: 2,450,721 (9.349 MB), Total: 9.43 MB, FLOPs: 156,653,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1724 finished in 0m09s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.077 MB, Params: 2,447,974 (9.338 MB), Total: 9.42 MB, FLOPs: 156,488,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1724 finished in 0m09s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 247)]\n",
      "Input: 0.077 MB, Params: 2,442,914 (9.319 MB), Total: 9.40 MB, FLOPs: 156,428,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1724 finished in 0m09s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.077 MB, Params: 2,440,149 (9.308 MB), Total: 9.39 MB, FLOPs: 156,053,011\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1724 finished in 0m09s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 2,437,411 (9.298 MB), Total: 9.37 MB, FLOPs: 155,888,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1724 finished in 0m09s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.077 MB, Params: 2,432,351 (9.279 MB), Total: 9.36 MB, FLOPs: 155,828,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1724 finished in 0m09s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 105)]\n",
      "Input: 0.077 MB, Params: 2,430,882 (9.273 MB), Total: 9.35 MB, FLOPs: 155,424,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1724 finished in 0m09s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.077 MB, Params: 2,425,822 (9.254 MB), Total: 9.33 MB, FLOPs: 155,363,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1724 finished in 0m09s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 26)]\n",
      "Input: 0.077 MB, Params: 2,423,084 (9.243 MB), Total: 9.32 MB, FLOPs: 155,199,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1724 finished in 0m09s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 9)]\n",
      "Input: 0.077 MB, Params: 2,420,346 (9.233 MB), Total: 9.31 MB, FLOPs: 154,827,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1724 finished in 0m09s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 216)]\n",
      "Input: 0.077 MB, Params: 2,415,286 (9.214 MB), Total: 9.29 MB, FLOPs: 154,767,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1724 finished in 0m09s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 2,410,226 (9.194 MB), Total: 9.27 MB, FLOPs: 154,706,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1724 finished in 0m09s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 6)]\n",
      "Input: 0.077 MB, Params: 2,409,513 (9.192 MB), Total: 9.27 MB, FLOPs: 153,887,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1724 finished in 0m09s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.077 MB, Params: 2,404,453 (9.172 MB), Total: 9.25 MB, FLOPs: 153,826,811\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1724 finished in 0m09s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.077 MB, Params: 2,402,993 (9.167 MB), Total: 9.24 MB, FLOPs: 153,425,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1724 finished in 0m09s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.077 MB, Params: 2,400,026 (9.155 MB), Total: 9.23 MB, FLOPs: 153,390,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1724 finished in 0m09s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 199)]\n",
      "Input: 0.077 MB, Params: 2,397,059 (9.144 MB), Total: 9.22 MB, FLOPs: 153,354,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1724 finished in 0m09s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.077 MB, Params: 2,394,092 (9.133 MB), Total: 9.21 MB, FLOPs: 153,318,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1724 finished in 0m09s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.077 MB, Params: 2,391,125 (9.121 MB), Total: 9.20 MB, FLOPs: 153,283,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1724 finished in 0m09s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 288)]\n",
      "Input: 0.077 MB, Params: 2,386,101 (9.102 MB), Total: 9.18 MB, FLOPs: 153,223,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1724 finished in 0m09s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.077 MB, Params: 2,381,077 (9.083 MB), Total: 9.16 MB, FLOPs: 153,162,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1724 finished in 0m09s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 179)]\n",
      "Input: 0.077 MB, Params: 2,376,053 (9.064 MB), Total: 9.14 MB, FLOPs: 153,102,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1724 finished in 0m09s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 2,371,029 (9.045 MB), Total: 9.12 MB, FLOPs: 153,042,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1724 finished in 0m09s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.077 MB, Params: 2,366,005 (9.026 MB), Total: 9.10 MB, FLOPs: 152,981,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1724 finished in 0m09s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 0)]\n",
      "Input: 0.077 MB, Params: 2,363,276 (9.015 MB), Total: 9.09 MB, FLOPs: 152,612,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1724 finished in 0m09s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 289)]\n",
      "Input: 0.077 MB, Params: 2,358,252 (8.996 MB), Total: 9.07 MB, FLOPs: 152,552,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1724 finished in 0m09s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.077 MB, Params: 2,353,570 (8.978 MB), Total: 9.06 MB, FLOPs: 152,411,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1724 finished in 0m09s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.077 MB, Params: 2,348,555 (8.959 MB), Total: 9.04 MB, FLOPs: 152,350,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1724 finished in 0m09s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.077 MB, Params: 2,347,086 (8.953 MB), Total: 9.03 MB, FLOPs: 151,496,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1724 finished in 0m09s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 214)]\n",
      "Input: 0.077 MB, Params: 2,342,071 (8.934 MB), Total: 9.01 MB, FLOPs: 151,436,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1724 finished in 0m09s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.077 MB, Params: 2,339,176 (8.923 MB), Total: 9.00 MB, FLOPs: 151,401,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1724 finished in 0m09s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.077 MB, Params: 2,337,734 (8.918 MB), Total: 8.99 MB, FLOPs: 151,005,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1724 finished in 0m09s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.077 MB, Params: 2,332,728 (8.899 MB), Total: 8.98 MB, FLOPs: 150,945,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1724 finished in 0m09s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 168)]\n",
      "Input: 0.077 MB, Params: 2,330,017 (8.888 MB), Total: 8.97 MB, FLOPs: 150,782,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1724 finished in 0m09s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.077 MB, Params: 2,325,011 (8.869 MB), Total: 8.95 MB, FLOPs: 150,722,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1724 finished in 0m09s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 163)]\n",
      "Input: 0.077 MB, Params: 2,320,374 (8.852 MB), Total: 8.93 MB, FLOPs: 150,582,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1724 finished in 0m09s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.077 MB, Params: 2,317,497 (8.841 MB), Total: 8.92 MB, FLOPs: 150,547,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1724 finished in 0m09s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 141)]\n",
      "Input: 0.077 MB, Params: 2,314,795 (8.830 MB), Total: 8.91 MB, FLOPs: 150,385,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1724 finished in 0m09s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 114)]\n",
      "Input: 0.077 MB, Params: 2,310,167 (8.813 MB), Total: 8.89 MB, FLOPs: 150,245,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1724 finished in 0m09s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.077 MB, Params: 2,305,188 (8.794 MB), Total: 8.87 MB, FLOPs: 150,185,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1724 finished in 0m09s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 100)]\n",
      "Input: 0.077 MB, Params: 2,303,746 (8.788 MB), Total: 8.86 MB, FLOPs: 149,789,637\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1724 finished in 0m09s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.077 MB, Params: 2,298,767 (8.769 MB), Total: 8.85 MB, FLOPs: 149,729,901\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1724 finished in 0m09s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.077 MB, Params: 2,293,788 (8.750 MB), Total: 8.83 MB, FLOPs: 149,670,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1724 finished in 0m09s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.077 MB, Params: 2,288,809 (8.731 MB), Total: 8.81 MB, FLOPs: 149,610,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1724 finished in 0m09s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.077 MB, Params: 2,285,968 (8.720 MB), Total: 8.80 MB, FLOPs: 149,576,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1724 finished in 0m09s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.077 MB, Params: 2,280,998 (8.701 MB), Total: 8.78 MB, FLOPs: 149,516,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1724 finished in 0m09s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.077 MB, Params: 2,276,028 (8.682 MB), Total: 8.76 MB, FLOPs: 149,457,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1724 finished in 0m09s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 245)]\n",
      "Input: 0.077 MB, Params: 2,271,058 (8.663 MB), Total: 8.74 MB, FLOPs: 149,397,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1724 finished in 0m09s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.077 MB, Params: 2,266,088 (8.644 MB), Total: 8.72 MB, FLOPs: 149,337,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1724 finished in 0m09s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 191)]\n",
      "Input: 0.077 MB, Params: 2,263,283 (8.634 MB), Total: 8.71 MB, FLOPs: 149,304,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1724 finished in 0m09s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 91)]\n",
      "Input: 0.077 MB, Params: 2,258,727 (8.616 MB), Total: 8.69 MB, FLOPs: 149,165,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1724 finished in 0m09s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.077 MB, Params: 2,255,922 (8.606 MB), Total: 8.68 MB, FLOPs: 149,131,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1724 finished in 0m09s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 230)]\n",
      "Input: 0.077 MB, Params: 2,250,979 (8.587 MB), Total: 8.66 MB, FLOPs: 149,072,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1724 finished in 0m09s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 145)]\n",
      "Input: 0.077 MB, Params: 2,248,295 (8.577 MB), Total: 8.65 MB, FLOPs: 148,911,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1724 finished in 0m09s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.077 MB, Params: 2,246,853 (8.571 MB), Total: 8.65 MB, FLOPs: 148,515,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1724 finished in 0m09s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 129)]\n",
      "Input: 0.077 MB, Params: 2,244,057 (8.560 MB), Total: 8.64 MB, FLOPs: 148,481,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1724 finished in 0m09s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 2)]\n",
      "Input: 0.077 MB, Params: 2,241,373 (8.550 MB), Total: 8.63 MB, FLOPs: 148,320,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1724 finished in 0m09s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 86)]\n",
      "Input: 0.077 MB, Params: 2,236,844 (8.533 MB), Total: 8.61 MB, FLOPs: 148,182,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1724 finished in 0m09s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.077 MB, Params: 2,231,919 (8.514 MB), Total: 8.59 MB, FLOPs: 148,123,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1724 finished in 0m09s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 191)]\n",
      "Input: 0.077 MB, Params: 2,226,994 (8.495 MB), Total: 8.57 MB, FLOPs: 148,064,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1724 finished in 0m09s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.077 MB, Params: 2,224,319 (8.485 MB), Total: 8.56 MB, FLOPs: 147,904,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1724 finished in 0m09s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.077 MB, Params: 2,219,394 (8.466 MB), Total: 8.54 MB, FLOPs: 147,845,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1724 finished in 0m09s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 190)]\n",
      "Input: 0.077 MB, Params: 2,216,719 (8.456 MB), Total: 8.53 MB, FLOPs: 147,684,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1724 finished in 0m09s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.077 MB, Params: 2,211,794 (8.437 MB), Total: 8.51 MB, FLOPs: 147,625,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1724 finished in 0m09s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 214)]\n",
      "Input: 0.077 MB, Params: 2,206,869 (8.419 MB), Total: 8.50 MB, FLOPs: 147,566,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1724 finished in 0m09s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.077 MB, Params: 2,201,944 (8.400 MB), Total: 8.48 MB, FLOPs: 147,507,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1724 finished in 0m09s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 90)]\n",
      "Input: 0.077 MB, Params: 2,200,502 (8.394 MB), Total: 8.47 MB, FLOPs: 147,111,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1724 finished in 0m09s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 131)]\n",
      "Input: 0.077 MB, Params: 2,196,045 (8.377 MB), Total: 8.45 MB, FLOPs: 146,974,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1724 finished in 0m09s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.077 MB, Params: 2,193,303 (8.367 MB), Total: 8.44 MB, FLOPs: 146,942,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1724 finished in 0m09s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.077 MB, Params: 2,190,561 (8.356 MB), Total: 8.43 MB, FLOPs: 146,909,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1724 finished in 0m09s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 70)]\n",
      "Input: 0.077 MB, Params: 2,187,922 (8.346 MB), Total: 8.42 MB, FLOPs: 146,553,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1724 finished in 0m09s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.077 MB, Params: 2,183,465 (8.329 MB), Total: 8.41 MB, FLOPs: 146,417,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1724 finished in 0m09s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.077 MB, Params: 2,178,576 (8.311 MB), Total: 8.39 MB, FLOPs: 146,358,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1724 finished in 0m09s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.077 MB, Params: 2,175,937 (8.301 MB), Total: 8.38 MB, FLOPs: 146,002,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1724 finished in 0m09s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 140)]\n",
      "Input: 0.077 MB, Params: 2,171,489 (8.284 MB), Total: 8.36 MB, FLOPs: 145,866,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1724 finished in 0m09s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 101)]\n",
      "Input: 0.077 MB, Params: 2,167,041 (8.267 MB), Total: 8.34 MB, FLOPs: 145,730,365\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1724 finished in 0m09s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 66)]\n",
      "Input: 0.077 MB, Params: 2,165,617 (8.261 MB), Total: 8.34 MB, FLOPs: 145,339,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1724 finished in 0m09s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 145)]\n",
      "Input: 0.077 MB, Params: 2,162,996 (8.251 MB), Total: 8.33 MB, FLOPs: 145,181,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1724 finished in 0m09s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.077 MB, Params: 2,158,125 (8.233 MB), Total: 8.31 MB, FLOPs: 145,123,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1724 finished in 0m09s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.077 MB, Params: 2,153,695 (8.216 MB), Total: 8.29 MB, FLOPs: 144,988,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1724 finished in 0m09s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 2,148,833 (8.197 MB), Total: 8.27 MB, FLOPs: 144,929,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1724 finished in 0m09s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 349)]\n",
      "Input: 0.077 MB, Params: 2,146,118 (8.187 MB), Total: 8.26 MB, FLOPs: 144,897,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1724 finished in 0m09s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 233)]\n",
      "Input: 0.077 MB, Params: 2,141,265 (8.168 MB), Total: 8.25 MB, FLOPs: 144,838,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1724 finished in 0m09s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 258)]\n",
      "Input: 0.077 MB, Params: 2,136,412 (8.150 MB), Total: 8.23 MB, FLOPs: 144,780,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1724 finished in 0m09s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.077 MB, Params: 2,132,009 (8.133 MB), Total: 8.21 MB, FLOPs: 144,645,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1724 finished in 0m09s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 290)]\n",
      "Input: 0.077 MB, Params: 2,127,165 (8.114 MB), Total: 8.19 MB, FLOPs: 144,587,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1724 finished in 0m09s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.077 MB, Params: 2,122,771 (8.098 MB), Total: 8.17 MB, FLOPs: 144,452,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1724 finished in 0m09s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 2,120,177 (8.088 MB), Total: 8.16 MB, FLOPs: 144,297,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1724 finished in 0m09s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 157)]\n",
      "Input: 0.077 MB, Params: 2,115,342 (8.069 MB), Total: 8.15 MB, FLOPs: 144,239,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1724 finished in 0m09s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.077 MB, Params: 2,112,663 (8.059 MB), Total: 8.14 MB, FLOPs: 144,207,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1724 finished in 0m09s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.077 MB, Params: 2,107,837 (8.041 MB), Total: 8.12 MB, FLOPs: 144,149,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1724 finished in 0m09s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.077 MB, Params: 2,105,225 (8.031 MB), Total: 8.11 MB, FLOPs: 143,796,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1724 finished in 0m09s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 41)]\n",
      "Input: 0.077 MB, Params: 2,105,183 (8.031 MB), Total: 8.11 MB, FLOPs: 141,549,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1724 finished in 0m09s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.077 MB, Params: 2,103,768 (8.025 MB), Total: 8.10 MB, FLOPs: 141,160,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1724 finished in 0m09s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.077 MB, Params: 2,098,942 (8.007 MB), Total: 8.08 MB, FLOPs: 141,102,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1724 finished in 0m09s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 161)]\n",
      "Input: 0.077 MB, Params: 2,094,116 (7.988 MB), Total: 8.07 MB, FLOPs: 141,044,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1724 finished in 0m09s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 143)]\n",
      "Input: 0.077 MB, Params: 2,089,767 (7.972 MB), Total: 8.05 MB, FLOPs: 140,910,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1724 finished in 0m09s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.077 MB, Params: 2,087,115 (7.962 MB), Total: 8.04 MB, FLOPs: 140,878,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1724 finished in 0m09s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.077 MB, Params: 2,085,700 (7.956 MB), Total: 8.03 MB, FLOPs: 140,489,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1724 finished in 0m09s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 2,081,351 (7.940 MB), Total: 8.02 MB, FLOPs: 140,355,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1724 finished in 0m09s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.077 MB, Params: 2,076,552 (7.921 MB), Total: 8.00 MB, FLOPs: 140,298,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1724 finished in 0m09s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 240)]\n",
      "Input: 0.077 MB, Params: 2,071,753 (7.903 MB), Total: 7.98 MB, FLOPs: 140,240,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1724 finished in 0m09s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 226)]\n",
      "Input: 0.077 MB, Params: 2,069,119 (7.893 MB), Total: 7.97 MB, FLOPs: 140,209,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1724 finished in 0m09s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 2,067,704 (7.888 MB), Total: 7.96 MB, FLOPs: 139,820,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1724 finished in 0m09s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 114)]\n",
      "Input: 0.077 MB, Params: 2,063,373 (7.871 MB), Total: 7.95 MB, FLOPs: 139,686,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1724 finished in 0m09s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 152)]\n",
      "Input: 0.077 MB, Params: 2,060,815 (7.861 MB), Total: 7.94 MB, FLOPs: 139,533,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1724 finished in 0m09s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 283)]\n",
      "Input: 0.077 MB, Params: 2,058,181 (7.851 MB), Total: 7.93 MB, FLOPs: 139,501,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1724 finished in 0m09s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 187)]\n",
      "Input: 0.077 MB, Params: 2,055,623 (7.842 MB), Total: 7.92 MB, FLOPs: 139,348,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1724 finished in 0m09s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 26)]\n",
      "Input: 0.077 MB, Params: 2,051,310 (7.825 MB), Total: 7.90 MB, FLOPs: 139,215,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1724 finished in 0m09s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.077 MB, Params: 2,046,547 (7.807 MB), Total: 7.88 MB, FLOPs: 139,158,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1724 finished in 0m09s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 320)]\n",
      "Input: 0.077 MB, Params: 2,043,922 (7.797 MB), Total: 7.87 MB, FLOPs: 139,126,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1724 finished in 0m09s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.077 MB, Params: 2,039,168 (7.779 MB), Total: 7.86 MB, FLOPs: 139,069,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1724 finished in 0m09s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 81)]\n",
      "Input: 0.077 MB, Params: 2,037,753 (7.773 MB), Total: 7.85 MB, FLOPs: 138,681,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1724 finished in 0m09s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 238)]\n",
      "Input: 0.077 MB, Params: 2,035,137 (7.763 MB), Total: 7.84 MB, FLOPs: 138,649,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1724 finished in 0m09s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 71)]\n",
      "Input: 0.077 MB, Params: 2,032,579 (7.754 MB), Total: 7.83 MB, FLOPs: 138,308,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1724 finished in 0m09s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 115)]\n",
      "Input: 0.077 MB, Params: 2,030,039 (7.744 MB), Total: 7.82 MB, FLOPs: 138,155,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1724 finished in 0m09s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.077 MB, Params: 2,025,294 (7.726 MB), Total: 7.80 MB, FLOPs: 138,098,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1724 finished in 0m09s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.077 MB, Params: 2,020,549 (7.708 MB), Total: 7.78 MB, FLOPs: 138,041,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1724 finished in 0m09s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.077 MB, Params: 2,015,804 (7.690 MB), Total: 7.77 MB, FLOPs: 137,985,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1724 finished in 0m09s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.077 MB, Params: 2,011,059 (7.672 MB), Total: 7.75 MB, FLOPs: 137,928,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1724 finished in 0m09s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.077 MB, Params: 2,008,479 (7.662 MB), Total: 7.74 MB, FLOPs: 137,897,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1724 finished in 0m09s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.077 MB, Params: 2,005,939 (7.652 MB), Total: 7.73 MB, FLOPs: 137,744,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1724 finished in 0m09s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 280)]\n",
      "Input: 0.077 MB, Params: 2,001,203 (7.634 MB), Total: 7.71 MB, FLOPs: 137,688,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1724 finished in 0m09s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.077 MB, Params: 1,998,663 (7.624 MB), Total: 7.70 MB, FLOPs: 137,535,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1724 finished in 0m09s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.077 MB, Params: 1,996,092 (7.614 MB), Total: 7.69 MB, FLOPs: 137,504,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1724 finished in 0m09s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 70)]\n",
      "Input: 0.077 MB, Params: 1,993,552 (7.605 MB), Total: 7.68 MB, FLOPs: 137,352,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1724 finished in 0m09s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 177)]\n",
      "Input: 0.077 MB, Params: 1,989,338 (7.589 MB), Total: 7.67 MB, FLOPs: 137,222,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1724 finished in 0m09s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.077 MB, Params: 1,984,620 (7.571 MB), Total: 7.65 MB, FLOPs: 137,166,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1724 finished in 0m09s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.077 MB, Params: 1,982,089 (7.561 MB), Total: 7.64 MB, FLOPs: 137,014,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1724 finished in 0m09s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 52)]\n",
      "Input: 0.077 MB, Params: 1,981,385 (7.558 MB), Total: 7.64 MB, FLOPs: 136,241,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1724 finished in 0m09s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.077 MB, Params: 1,976,667 (7.540 MB), Total: 7.62 MB, FLOPs: 136,184,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1724 finished in 0m09s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.077 MB, Params: 1,971,949 (7.522 MB), Total: 7.60 MB, FLOPs: 136,127,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1724 finished in 0m09s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.077 MB, Params: 1,967,231 (7.504 MB), Total: 7.58 MB, FLOPs: 136,071,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1724 finished in 0m09s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 1,964,696 (7.495 MB), Total: 7.57 MB, FLOPs: 136,040,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1724 finished in 0m09s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 330)]\n",
      "Input: 0.077 MB, Params: 1,962,161 (7.485 MB), Total: 7.56 MB, FLOPs: 136,010,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1724 finished in 0m09s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.077 MB, Params: 1,959,626 (7.475 MB), Total: 7.55 MB, FLOPs: 135,980,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1724 finished in 0m09s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.077 MB, Params: 1,957,091 (7.466 MB), Total: 7.54 MB, FLOPs: 135,949,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1724 finished in 0m09s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.077 MB, Params: 1,954,556 (7.456 MB), Total: 7.53 MB, FLOPs: 135,919,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1724 finished in 0m09s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.077 MB, Params: 1,953,150 (7.451 MB), Total: 7.53 MB, FLOPs: 135,532,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1724 finished in 0m09s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 35)]\n",
      "Input: 0.077 MB, Params: 1,950,646 (7.441 MB), Total: 7.52 MB, FLOPs: 135,196,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1724 finished in 0m09s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.077 MB, Params: 1,946,477 (7.425 MB), Total: 7.50 MB, FLOPs: 135,067,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1724 finished in 0m09s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.077 MB, Params: 1,941,813 (7.407 MB), Total: 7.48 MB, FLOPs: 135,011,900\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1724 finished in 0m09s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 72)]\n",
      "Input: 0.077 MB, Params: 1,939,309 (7.398 MB), Total: 7.47 MB, FLOPs: 134,675,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1724 finished in 0m09s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.077 MB, Params: 1,934,645 (7.380 MB), Total: 7.46 MB, FLOPs: 134,619,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1724 finished in 0m09s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 18)]\n",
      "Input: 0.077 MB, Params: 1,934,603 (7.380 MB), Total: 7.46 MB, FLOPs: 134,383,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1724 finished in 0m09s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.077 MB, Params: 1,932,086 (7.370 MB), Total: 7.45 MB, FLOPs: 134,352,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1724 finished in 0m09s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 161)]\n",
      "Input: 0.077 MB, Params: 1,929,582 (7.361 MB), Total: 7.44 MB, FLOPs: 134,202,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1724 finished in 0m09s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 126)]\n",
      "Input: 0.077 MB, Params: 1,925,440 (7.345 MB), Total: 7.42 MB, FLOPs: 134,074,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1724 finished in 0m09s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.077 MB, Params: 1,922,923 (7.335 MB), Total: 7.41 MB, FLOPs: 134,044,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1724 finished in 0m09s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 168)]\n",
      "Input: 0.077 MB, Params: 1,918,781 (7.320 MB), Total: 7.40 MB, FLOPs: 133,916,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1724 finished in 0m09s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.077 MB, Params: 1,914,639 (7.304 MB), Total: 7.38 MB, FLOPs: 133,788,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1724 finished in 0m09s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.077 MB, Params: 1,913,251 (7.298 MB), Total: 7.38 MB, FLOPs: 133,407,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1724 finished in 0m09s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.077 MB, Params: 1,910,734 (7.289 MB), Total: 7.37 MB, FLOPs: 133,377,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1724 finished in 0m09s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.077 MB, Params: 1,906,592 (7.273 MB), Total: 7.35 MB, FLOPs: 133,249,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1724 finished in 0m09s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.077 MB, Params: 1,901,991 (7.256 MB), Total: 7.33 MB, FLOPs: 133,193,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1724 finished in 0m09s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 47)]\n",
      "Input: 0.077 MB, Params: 1,901,287 (7.253 MB), Total: 7.33 MB, FLOPs: 132,420,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1724 finished in 0m09s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.077 MB, Params: 1,898,779 (7.243 MB), Total: 7.32 MB, FLOPs: 132,390,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1724 finished in 0m09s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 1,894,187 (7.226 MB), Total: 7.30 MB, FLOPs: 132,335,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1724 finished in 0m09s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 1,889,595 (7.208 MB), Total: 7.29 MB, FLOPs: 132,280,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1724 finished in 0m09s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.077 MB, Params: 1,885,003 (7.191 MB), Total: 7.27 MB, FLOPs: 132,225,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1724 finished in 0m09s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.077 MB, Params: 1,880,411 (7.173 MB), Total: 7.25 MB, FLOPs: 132,170,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1724 finished in 0m09s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 86)]\n",
      "Input: 0.077 MB, Params: 1,877,925 (7.164 MB), Total: 7.24 MB, FLOPs: 131,836,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1724 finished in 0m09s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.077 MB, Params: 1,873,333 (7.146 MB), Total: 7.22 MB, FLOPs: 131,781,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1724 finished in 0m09s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 246)]\n",
      "Input: 0.077 MB, Params: 1,868,741 (7.129 MB), Total: 7.21 MB, FLOPs: 131,726,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1724 finished in 0m09s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.077 MB, Params: 1,866,287 (7.119 MB), Total: 7.20 MB, FLOPs: 131,697,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1724 finished in 0m09s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.077 MB, Params: 1,861,704 (7.102 MB), Total: 7.18 MB, FLOPs: 131,642,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1724 finished in 0m09s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.077 MB, Params: 1,859,259 (7.093 MB), Total: 7.17 MB, FLOPs: 131,612,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1724 finished in 0m09s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.077 MB, Params: 1,854,685 (7.075 MB), Total: 7.15 MB, FLOPs: 131,558,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1724 finished in 0m09s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.077 MB, Params: 1,850,624 (7.060 MB), Total: 7.14 MB, FLOPs: 131,431,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1724 finished in 0m09s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 159)]\n",
      "Input: 0.077 MB, Params: 1,848,174 (7.050 MB), Total: 7.13 MB, FLOPs: 131,284,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1724 finished in 0m09s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 129)]\n",
      "Input: 0.077 MB, Params: 1,845,724 (7.041 MB), Total: 7.12 MB, FLOPs: 131,137,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1724 finished in 0m09s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 255)]\n",
      "Input: 0.077 MB, Params: 1,843,288 (7.032 MB), Total: 7.11 MB, FLOPs: 131,107,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1724 finished in 0m09s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 174)]\n",
      "Input: 0.077 MB, Params: 1,840,838 (7.022 MB), Total: 7.10 MB, FLOPs: 130,961,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1724 finished in 0m09s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.077 MB, Params: 1,838,388 (7.013 MB), Total: 7.09 MB, FLOPs: 130,814,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1724 finished in 0m09s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.077 MB, Params: 1,835,938 (7.004 MB), Total: 7.08 MB, FLOPs: 130,667,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1724 finished in 0m09s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.077 MB, Params: 1,831,382 (6.986 MB), Total: 7.06 MB, FLOPs: 130,612,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1724 finished in 0m09s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.077 MB, Params: 1,827,375 (6.971 MB), Total: 7.05 MB, FLOPs: 130,488,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1724 finished in 0m09s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.077 MB, Params: 1,822,828 (6.954 MB), Total: 7.03 MB, FLOPs: 130,433,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1724 finished in 0m09s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.077 MB, Params: 1,820,410 (6.944 MB), Total: 7.02 MB, FLOPs: 130,404,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1724 finished in 0m09s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 86)]\n",
      "Input: 0.077 MB, Params: 1,817,969 (6.935 MB), Total: 7.01 MB, FLOPs: 130,074,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1724 finished in 0m09s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.077 MB, Params: 1,813,431 (6.918 MB), Total: 6.99 MB, FLOPs: 130,019,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1724 finished in 0m09s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.077 MB, Params: 1,810,990 (6.908 MB), Total: 6.99 MB, FLOPs: 129,688,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1724 finished in 0m09s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 34)]\n",
      "Input: 0.077 MB, Params: 1,809,629 (6.903 MB), Total: 6.98 MB, FLOPs: 129,314,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1724 finished in 0m09s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.077 MB, Params: 1,807,206 (6.894 MB), Total: 6.97 MB, FLOPs: 129,169,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1724 finished in 0m09s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.077 MB, Params: 1,804,797 (6.885 MB), Total: 6.96 MB, FLOPs: 129,140,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1724 finished in 0m09s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 234)]\n",
      "Input: 0.077 MB, Params: 1,800,268 (6.867 MB), Total: 6.94 MB, FLOPs: 129,086,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1724 finished in 0m09s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.077 MB, Params: 1,797,845 (6.858 MB), Total: 6.94 MB, FLOPs: 128,941,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1724 finished in 0m09s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.077 MB, Params: 1,795,445 (6.849 MB), Total: 6.93 MB, FLOPs: 128,912,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1724 finished in 0m09s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.077 MB, Params: 1,793,045 (6.840 MB), Total: 6.92 MB, FLOPs: 128,883,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1724 finished in 0m09s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 1,788,534 (6.823 MB), Total: 6.90 MB, FLOPs: 128,829,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1724 finished in 0m09s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 91)]\n",
      "Input: 0.077 MB, Params: 1,786,111 (6.813 MB), Total: 6.89 MB, FLOPs: 128,684,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1724 finished in 0m09s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.077 MB, Params: 1,783,688 (6.804 MB), Total: 6.88 MB, FLOPs: 128,538,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1724 finished in 0m09s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 1,779,177 (6.787 MB), Total: 6.86 MB, FLOPs: 128,484,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1724 finished in 0m09s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 118)]\n",
      "Input: 0.077 MB, Params: 1,775,251 (6.772 MB), Total: 6.85 MB, FLOPs: 128,363,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1724 finished in 0m09s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.077 MB, Params: 1,770,749 (6.755 MB), Total: 6.83 MB, FLOPs: 128,309,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1724 finished in 0m09s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.077 MB, Params: 1,766,247 (6.738 MB), Total: 6.81 MB, FLOPs: 128,255,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1724 finished in 0m09s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 22)]\n",
      "Input: 0.077 MB, Params: 1,765,543 (6.735 MB), Total: 6.81 MB, FLOPs: 127,481,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1724 finished in 0m09s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.077 MB, Params: 1,761,041 (6.718 MB), Total: 6.79 MB, FLOPs: 127,427,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1724 finished in 0m09s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.077 MB, Params: 1,757,142 (6.703 MB), Total: 6.78 MB, FLOPs: 127,306,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1724 finished in 0m09s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 99)]\n",
      "Input: 0.077 MB, Params: 1,752,649 (6.686 MB), Total: 6.76 MB, FLOPs: 127,252,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1724 finished in 0m09s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 79)]\n",
      "Input: 0.077 MB, Params: 1,751,288 (6.681 MB), Total: 6.76 MB, FLOPs: 126,878,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1724 finished in 0m09s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 37)]\n",
      "Input: 0.077 MB, Params: 1,750,584 (6.678 MB), Total: 6.75 MB, FLOPs: 126,105,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1724 finished in 0m09s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 134)]\n",
      "Input: 0.077 MB, Params: 1,748,179 (6.669 MB), Total: 6.75 MB, FLOPs: 125,961,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1724 finished in 0m09s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 243)]\n",
      "Input: 0.077 MB, Params: 1,745,833 (6.660 MB), Total: 6.74 MB, FLOPs: 125,933,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1724 finished in 0m09s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.077 MB, Params: 1,743,455 (6.651 MB), Total: 6.73 MB, FLOPs: 125,610,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1724 finished in 0m09s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 45)]\n",
      "Input: 0.077 MB, Params: 1,741,109 (6.642 MB), Total: 6.72 MB, FLOPs: 125,581,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1724 finished in 0m09s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 145)]\n",
      "Input: 0.077 MB, Params: 1,738,713 (6.633 MB), Total: 6.71 MB, FLOPs: 125,438,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1724 finished in 0m09s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 157)]\n",
      "Input: 0.077 MB, Params: 1,734,238 (6.616 MB), Total: 6.69 MB, FLOPs: 125,384,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1724 finished in 0m09s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 1,730,375 (6.601 MB), Total: 6.68 MB, FLOPs: 125,264,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1724 finished in 0m09s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.077 MB, Params: 1,726,512 (6.586 MB), Total: 6.66 MB, FLOPs: 125,144,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1724 finished in 0m09s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.077 MB, Params: 1,724,175 (6.577 MB), Total: 6.65 MB, FLOPs: 125,116,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1724 finished in 0m09s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 153)]\n",
      "Input: 0.077 MB, Params: 1,720,312 (6.562 MB), Total: 6.64 MB, FLOPs: 124,996,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1724 finished in 0m09s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.077 MB, Params: 1,715,873 (6.546 MB), Total: 6.62 MB, FLOPs: 124,943,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1724 finished in 0m09s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.077 MB, Params: 1,712,019 (6.531 MB), Total: 6.61 MB, FLOPs: 124,823,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1724 finished in 0m09s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 1,707,589 (6.514 MB), Total: 6.59 MB, FLOPs: 124,770,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1724 finished in 0m09s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 215)]\n",
      "Input: 0.077 MB, Params: 1,705,270 (6.505 MB), Total: 6.58 MB, FLOPs: 124,742,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1724 finished in 0m09s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 249)]\n",
      "Input: 0.077 MB, Params: 1,700,849 (6.488 MB), Total: 6.57 MB, FLOPs: 124,689,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1724 finished in 0m09s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.077 MB, Params: 1,698,539 (6.479 MB), Total: 6.56 MB, FLOPs: 124,662,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1724 finished in 0m09s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.077 MB, Params: 1,694,127 (6.463 MB), Total: 6.54 MB, FLOPs: 124,609,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1724 finished in 0m09s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.077 MB, Params: 1,691,826 (6.454 MB), Total: 6.53 MB, FLOPs: 124,581,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1724 finished in 0m09s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.077 MB, Params: 1,687,423 (6.437 MB), Total: 6.51 MB, FLOPs: 124,528,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1724 finished in 0m09s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 86)]\n",
      "Input: 0.077 MB, Params: 1,685,054 (6.428 MB), Total: 6.50 MB, FLOPs: 124,206,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1724 finished in 0m09s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.077 MB, Params: 1,680,651 (6.411 MB), Total: 6.49 MB, FLOPs: 124,153,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1724 finished in 0m09s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 117)]\n",
      "Input: 0.077 MB, Params: 1,678,300 (6.402 MB), Total: 6.48 MB, FLOPs: 124,012,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1724 finished in 0m09s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.077 MB, Params: 1,677,596 (6.400 MB), Total: 6.48 MB, FLOPs: 123,239,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1724 finished in 0m09s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.077 MB, Params: 1,673,193 (6.383 MB), Total: 6.46 MB, FLOPs: 123,186,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1724 finished in 0m09s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.077 MB, Params: 1,670,919 (6.374 MB), Total: 6.45 MB, FLOPs: 123,159,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1724 finished in 0m09s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.077 MB, Params: 1,668,645 (6.365 MB), Total: 6.44 MB, FLOPs: 123,131,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1724 finished in 0m09s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.077 MB, Params: 1,664,260 (6.349 MB), Total: 6.43 MB, FLOPs: 123,079,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1724 finished in 0m09s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.077 MB, Params: 1,661,995 (6.340 MB), Total: 6.42 MB, FLOPs: 123,052,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1724 finished in 0m09s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 1,657,619 (6.323 MB), Total: 6.40 MB, FLOPs: 122,999,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1724 finished in 0m09s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.077 MB, Params: 1,655,363 (6.315 MB), Total: 6.39 MB, FLOPs: 122,972,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1724 finished in 0m09s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 149)]\n",
      "Input: 0.077 MB, Params: 1,650,996 (6.298 MB), Total: 6.37 MB, FLOPs: 122,920,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1724 finished in 0m09s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.077 MB, Params: 1,646,629 (6.281 MB), Total: 6.36 MB, FLOPs: 122,867,910\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1724 finished in 0m09s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.077 MB, Params: 1,642,262 (6.265 MB), Total: 6.34 MB, FLOPs: 122,815,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1724 finished in 0m09s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.077 MB, Params: 1,640,919 (6.260 MB), Total: 6.34 MB, FLOPs: 122,446,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1724 finished in 0m09s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.077 MB, Params: 1,638,690 (6.251 MB), Total: 6.33 MB, FLOPs: 122,419,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1724 finished in 0m09s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 67)]\n",
      "Input: 0.077 MB, Params: 1,636,339 (6.242 MB), Total: 6.32 MB, FLOPs: 122,100,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1724 finished in 0m09s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.077 MB, Params: 1,634,110 (6.234 MB), Total: 6.31 MB, FLOPs: 122,073,569\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1724 finished in 0m09s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.077 MB, Params: 1,630,364 (6.219 MB), Total: 6.30 MB, FLOPs: 121,955,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1724 finished in 0m09s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.077 MB, Params: 1,626,024 (6.203 MB), Total: 6.28 MB, FLOPs: 121,903,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1724 finished in 0m09s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 119)]\n",
      "Input: 0.077 MB, Params: 1,623,691 (6.194 MB), Total: 6.27 MB, FLOPs: 121,763,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1724 finished in 0m09s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.077 MB, Params: 1,621,349 (6.185 MB), Total: 6.26 MB, FLOPs: 121,444,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1724 finished in 0m09s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 131)]\n",
      "Input: 0.077 MB, Params: 1,617,621 (6.171 MB), Total: 6.25 MB, FLOPs: 121,327,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1724 finished in 0m09s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 30)]\n",
      "Input: 0.077 MB, Params: 1,616,917 (6.168 MB), Total: 6.24 MB, FLOPs: 120,553,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1724 finished in 0m09s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 317)]\n",
      "Input: 0.077 MB, Params: 1,614,697 (6.160 MB), Total: 6.24 MB, FLOPs: 120,527,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1724 finished in 0m09s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.077 MB, Params: 1,612,477 (6.151 MB), Total: 6.23 MB, FLOPs: 120,500,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1724 finished in 0m09s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 192)]\n",
      "Input: 0.077 MB, Params: 1,610,257 (6.143 MB), Total: 6.22 MB, FLOPs: 120,474,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1724 finished in 0m09s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.077 MB, Params: 1,605,953 (6.126 MB), Total: 6.20 MB, FLOPs: 120,422,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1724 finished in 0m09s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.077 MB, Params: 1,602,234 (6.112 MB), Total: 6.19 MB, FLOPs: 120,305,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1724 finished in 0m09s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.077 MB, Params: 1,598,515 (6.098 MB), Total: 6.17 MB, FLOPs: 120,187,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1724 finished in 0m09s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 109)]\n",
      "Input: 0.077 MB, Params: 1,594,796 (6.084 MB), Total: 6.16 MB, FLOPs: 120,070,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1724 finished in 0m09s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 133)]\n",
      "Input: 0.077 MB, Params: 1,590,519 (6.067 MB), Total: 6.14 MB, FLOPs: 120,019,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1724 finished in 0m09s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.077 MB, Params: 1,586,242 (6.051 MB), Total: 6.13 MB, FLOPs: 119,967,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1724 finished in 0m09s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 160)]\n",
      "Input: 0.077 MB, Params: 1,583,954 (6.042 MB), Total: 6.12 MB, FLOPs: 119,830,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1724 finished in 0m09s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 66)]\n",
      "Input: 0.077 MB, Params: 1,581,666 (6.034 MB), Total: 6.11 MB, FLOPs: 119,693,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1724 finished in 0m09s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.077 MB, Params: 1,579,378 (6.025 MB), Total: 6.10 MB, FLOPs: 119,556,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1724 finished in 0m09s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.077 MB, Params: 1,577,185 (6.016 MB), Total: 6.09 MB, FLOPs: 119,530,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1724 finished in 0m09s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.077 MB, Params: 1,574,897 (6.008 MB), Total: 6.08 MB, FLOPs: 119,392,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1724 finished in 0m09s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.077 MB, Params: 1,572,704 (5.999 MB), Total: 6.08 MB, FLOPs: 119,366,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 777/1724 finished in 0m09s\n",
      "Total channels prunned so far: 777\n",
      "\n",
      "Iteration 778 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.077 MB, Params: 1,569,039 (5.985 MB), Total: 6.06 MB, FLOPs: 119,251,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 778/1724 finished in 0m09s\n",
      "Total channels prunned so far: 778\n",
      "\n",
      "Iteration 779 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 54)]\n",
      "Input: 0.077 MB, Params: 1,564,789 (5.969 MB), Total: 6.05 MB, FLOPs: 119,200,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 779/1724 finished in 0m09s\n",
      "Total channels prunned so far: 779\n",
      "\n",
      "Iteration 780 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 1,560,539 (5.953 MB), Total: 6.03 MB, FLOPs: 119,149,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 780/1724 finished in 0m09s\n",
      "Total channels prunned so far: 780\n",
      "\n",
      "Iteration 781 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.077 MB, Params: 1,556,289 (5.937 MB), Total: 6.01 MB, FLOPs: 119,098,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 781/1724 finished in 0m09s\n",
      "Total channels prunned so far: 781\n",
      "\n",
      "Iteration 782 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 66)]\n",
      "Input: 0.077 MB, Params: 1,553,983 (5.928 MB), Total: 6.00 MB, FLOPs: 118,781,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 782/1724 finished in 0m09s\n",
      "Total channels prunned so far: 782\n",
      "\n",
      "Iteration 783 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.077 MB, Params: 1,550,345 (5.914 MB), Total: 5.99 MB, FLOPs: 118,667,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 783/1724 finished in 0m09s\n",
      "Total channels prunned so far: 783\n",
      "\n",
      "Iteration 784 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 74)]\n",
      "Input: 0.077 MB, Params: 1,549,029 (5.909 MB), Total: 5.99 MB, FLOPs: 118,305,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 784/1724 finished in 0m09s\n",
      "Total channels prunned so far: 784\n",
      "\n",
      "Iteration 785 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 135)]\n",
      "Input: 0.077 MB, Params: 1,546,768 (5.900 MB), Total: 5.98 MB, FLOPs: 118,170,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 785/1724 finished in 0m09s\n",
      "Total channels prunned so far: 785\n",
      "\n",
      "Iteration 786 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 154)]\n",
      "Input: 0.077 MB, Params: 1,543,139 (5.887 MB), Total: 5.96 MB, FLOPs: 118,056,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 786/1724 finished in 0m09s\n",
      "Total channels prunned so far: 786\n",
      "\n",
      "Iteration 787 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.077 MB, Params: 1,540,973 (5.878 MB), Total: 5.96 MB, FLOPs: 118,030,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 787/1724 finished in 0m09s\n",
      "Total channels prunned so far: 787\n",
      "\n",
      "Iteration 788 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.077 MB, Params: 1,537,344 (5.865 MB), Total: 5.94 MB, FLOPs: 117,916,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 788/1724 finished in 0m09s\n",
      "Total channels prunned so far: 788\n",
      "\n",
      "Iteration 789 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.077 MB, Params: 1,533,715 (5.851 MB), Total: 5.93 MB, FLOPs: 117,801,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 789/1724 finished in 0m09s\n",
      "Total channels prunned so far: 789\n",
      "\n",
      "Iteration 790 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.077 MB, Params: 1,531,481 (5.842 MB), Total: 5.92 MB, FLOPs: 117,667,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 790/1724 finished in 0m09s\n",
      "Total channels prunned so far: 790\n",
      "\n",
      "Iteration 791 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 42)]\n",
      "Input: 0.077 MB, Params: 1,531,439 (5.842 MB), Total: 5.92 MB, FLOPs: 112,632,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 791/1724 finished in 0m09s\n",
      "Total channels prunned so far: 791\n",
      "\n",
      "Iteration 792 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 51)]\n",
      "Input: 0.077 MB, Params: 1,527,234 (5.826 MB), Total: 5.90 MB, FLOPs: 112,581,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 792/1724 finished in 0m09s\n",
      "Total channels prunned so far: 792\n",
      "\n",
      "Iteration 793 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 177)]\n",
      "Input: 0.077 MB, Params: 1,523,029 (5.810 MB), Total: 5.89 MB, FLOPs: 112,531,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 793/1724 finished in 0m09s\n",
      "Total channels prunned so far: 793\n",
      "\n",
      "Iteration 794 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 153)]\n",
      "Input: 0.077 MB, Params: 1,519,427 (5.796 MB), Total: 5.87 MB, FLOPs: 112,417,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 794/1724 finished in 0m09s\n",
      "Total channels prunned so far: 794\n",
      "\n",
      "Iteration 795 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 30)]\n",
      "Input: 0.077 MB, Params: 1,518,723 (5.793 MB), Total: 5.87 MB, FLOPs: 111,679,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 795/1724 finished in 0m09s\n",
      "Total channels prunned so far: 795\n",
      "\n",
      "Iteration 796 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.077 MB, Params: 1,514,527 (5.777 MB), Total: 5.85 MB, FLOPs: 111,629,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 796/1724 finished in 0m09s\n",
      "Total channels prunned so far: 796\n",
      "\n",
      "Iteration 797 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 1,510,331 (5.761 MB), Total: 5.84 MB, FLOPs: 111,579,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 797/1724 finished in 0m09s\n",
      "Total channels prunned so far: 797\n",
      "\n",
      "Iteration 798 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 127)]\n",
      "Input: 0.077 MB, Params: 1,508,201 (5.753 MB), Total: 5.83 MB, FLOPs: 111,553,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 798/1724 finished in 0m09s\n",
      "Total channels prunned so far: 798\n",
      "\n",
      "Iteration 799 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 234)]\n",
      "Input: 0.077 MB, Params: 1,504,014 (5.737 MB), Total: 5.81 MB, FLOPs: 111,503,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 799/1724 finished in 0m09s\n",
      "Total channels prunned so far: 799\n",
      "\n",
      "Iteration 800 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.077 MB, Params: 1,499,827 (5.721 MB), Total: 5.80 MB, FLOPs: 111,453,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 800/1724 finished in 0m09s\n",
      "Total channels prunned so far: 800\n",
      "\n",
      "Iteration 801 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 1,496,261 (5.708 MB), Total: 5.78 MB, FLOPs: 111,340,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 801/1724 finished in 0m09s\n",
      "Total channels prunned so far: 801\n",
      "\n",
      "Iteration 802 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 34)]\n",
      "Input: 0.077 MB, Params: 1,494,945 (5.703 MB), Total: 5.78 MB, FLOPs: 111,011,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 802/1724 finished in 0m09s\n",
      "Total channels prunned so far: 802\n",
      "\n",
      "Iteration 803 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 44)]\n",
      "Input: 0.077 MB, Params: 1,493,683 (5.698 MB), Total: 5.77 MB, FLOPs: 110,334,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 803/1724 finished in 0m09s\n",
      "Total channels prunned so far: 803\n",
      "\n",
      "Iteration 804 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.077 MB, Params: 1,492,376 (5.693 MB), Total: 5.77 MB, FLOPs: 110,007,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 804/1724 finished in 0m09s\n",
      "Total channels prunned so far: 804\n",
      "\n",
      "Iteration 805 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 117)]\n",
      "Input: 0.077 MB, Params: 1,490,160 (5.685 MB), Total: 5.76 MB, FLOPs: 109,874,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 805/1724 finished in 0m09s\n",
      "Total channels prunned so far: 805\n",
      "\n",
      "Iteration 806 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.077 MB, Params: 1,487,908 (5.676 MB), Total: 5.75 MB, FLOPs: 109,587,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 806/1724 finished in 0m09s\n",
      "Total channels prunned so far: 806\n",
      "\n",
      "Iteration 807 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.077 MB, Params: 1,485,701 (5.667 MB), Total: 5.74 MB, FLOPs: 109,454,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 807/1724 finished in 0m09s\n",
      "Total channels prunned so far: 807\n",
      "\n",
      "Iteration 808 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.077 MB, Params: 1,483,589 (5.659 MB), Total: 5.74 MB, FLOPs: 109,429,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 808/1724 finished in 0m09s\n",
      "Total channels prunned so far: 808\n",
      "\n",
      "Iteration 809 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.077 MB, Params: 1,479,420 (5.644 MB), Total: 5.72 MB, FLOPs: 109,379,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 809/1724 finished in 0m09s\n",
      "Total channels prunned so far: 809\n",
      "\n",
      "Iteration 810 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.077 MB, Params: 1,477,317 (5.636 MB), Total: 5.71 MB, FLOPs: 109,354,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 810/1724 finished in 0m09s\n",
      "Total channels prunned so far: 810\n",
      "\n",
      "Iteration 811 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.077 MB, Params: 1,475,110 (5.627 MB), Total: 5.70 MB, FLOPs: 109,222,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 811/1724 finished in 0m09s\n",
      "Total channels prunned so far: 811\n",
      "\n",
      "Iteration 812 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.077 MB, Params: 1,473,812 (5.622 MB), Total: 5.70 MB, FLOPs: 108,897,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 812/1724 finished in 0m09s\n",
      "Total channels prunned so far: 812\n",
      "\n",
      "Iteration 813 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.077 MB, Params: 1,469,652 (5.606 MB), Total: 5.68 MB, FLOPs: 108,847,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 813/1724 finished in 0m09s\n",
      "Total channels prunned so far: 813\n",
      "\n",
      "Iteration 814 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.077 MB, Params: 1,467,427 (5.598 MB), Total: 5.67 MB, FLOPs: 108,563,544\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 814/1724 finished in 0m09s\n",
      "Total channels prunned so far: 814\n",
      "\n",
      "Iteration 815 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.077 MB, Params: 1,463,267 (5.582 MB), Total: 5.66 MB, FLOPs: 108,513,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 815/1724 finished in 0m09s\n",
      "Total channels prunned so far: 815\n",
      "\n",
      "Iteration 816 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.077 MB, Params: 1,461,182 (5.574 MB), Total: 5.65 MB, FLOPs: 108,488,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 816/1724 finished in 0m09s\n",
      "Total channels prunned so far: 816\n",
      "\n",
      "Iteration 817 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.077 MB, Params: 1,458,984 (5.566 MB), Total: 5.64 MB, FLOPs: 108,356,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 817/1724 finished in 0m09s\n",
      "Total channels prunned so far: 817\n",
      "\n",
      "Iteration 818 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 216)]\n",
      "Input: 0.077 MB, Params: 1,454,833 (5.550 MB), Total: 5.63 MB, FLOPs: 108,307,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 818/1724 finished in 0m09s\n",
      "Total channels prunned so far: 818\n",
      "\n",
      "Iteration 819 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.077 MB, Params: 1,451,339 (5.536 MB), Total: 5.61 MB, FLOPs: 108,196,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 819/1724 finished in 0m09s\n",
      "Total channels prunned so far: 819\n",
      "\n",
      "Iteration 820 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.077 MB, Params: 1,449,263 (5.528 MB), Total: 5.61 MB, FLOPs: 108,171,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 820/1724 finished in 0m09s\n",
      "Total channels prunned so far: 820\n",
      "\n",
      "Iteration 821 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 288)]\n",
      "Input: 0.077 MB, Params: 1,447,187 (5.521 MB), Total: 5.60 MB, FLOPs: 108,147,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 821/1724 finished in 0m09s\n",
      "Total channels prunned so far: 821\n",
      "\n",
      "Iteration 822 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.077 MB, Params: 1,444,998 (5.512 MB), Total: 5.59 MB, FLOPs: 108,015,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 822/1724 finished in 0m09s\n",
      "Total channels prunned so far: 822\n",
      "\n",
      "Iteration 823 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.077 MB, Params: 1,441,513 (5.499 MB), Total: 5.58 MB, FLOPs: 107,906,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 823/1724 finished in 0m09s\n",
      "Total channels prunned so far: 823\n",
      "\n",
      "Iteration 824 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.077 MB, Params: 1,438,028 (5.486 MB), Total: 5.56 MB, FLOPs: 107,796,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 824/1724 finished in 0m09s\n",
      "Total channels prunned so far: 824\n",
      "\n",
      "Iteration 825 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.077 MB, Params: 1,433,922 (5.470 MB), Total: 5.55 MB, FLOPs: 107,747,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 825/1724 finished in 0m09s\n",
      "Total channels prunned so far: 825\n",
      "\n",
      "Iteration 826 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 44)]\n",
      "Input: 0.077 MB, Params: 1,432,678 (5.465 MB), Total: 5.54 MB, FLOPs: 107,074,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 826/1724 finished in 0m09s\n",
      "Total channels prunned so far: 826\n",
      "\n",
      "Iteration 827 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 44)]\n",
      "Input: 0.077 MB, Params: 1,431,398 (5.460 MB), Total: 5.54 MB, FLOPs: 106,754,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 827/1724 finished in 0m09s\n",
      "Total channels prunned so far: 827\n",
      "\n",
      "Iteration 828 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.077 MB, Params: 1,427,292 (5.445 MB), Total: 5.52 MB, FLOPs: 106,705,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 828/1724 finished in 0m09s\n",
      "Total channels prunned so far: 828\n",
      "\n",
      "Iteration 829 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 127)]\n",
      "Input: 0.077 MB, Params: 1,423,825 (5.431 MB), Total: 5.51 MB, FLOPs: 106,595,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 829/1724 finished in 0m09s\n",
      "Total channels prunned so far: 829\n",
      "\n",
      "Iteration 830 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.077 MB, Params: 1,420,358 (5.418 MB), Total: 5.50 MB, FLOPs: 106,486,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 830/1724 finished in 0m09s\n",
      "Total channels prunned so far: 830\n",
      "\n",
      "Iteration 831 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 1)]\n",
      "Input: 0.077 MB, Params: 1,420,316 (5.418 MB), Total: 5.49 MB, FLOPs: 106,250,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 831/1724 finished in 0m09s\n",
      "Total channels prunned so far: 831\n",
      "\n",
      "Iteration 832 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.077 MB, Params: 1,416,228 (5.402 MB), Total: 5.48 MB, FLOPs: 106,200,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 832/1724 finished in 0m09s\n",
      "Total channels prunned so far: 832\n",
      "\n",
      "Iteration 833 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.077 MB, Params: 1,414,948 (5.398 MB), Total: 5.47 MB, FLOPs: 105,881,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 833/1724 finished in 0m09s\n",
      "Total channels prunned so far: 833\n",
      "\n",
      "Iteration 834 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 5)]\n",
      "Input: 0.077 MB, Params: 1,414,727 (5.397 MB), Total: 5.47 MB, FLOPs: 104,723,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 834/1724 finished in 0m09s\n",
      "Total channels prunned so far: 834\n",
      "\n",
      "Iteration 835 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.077 MB, Params: 1,410,639 (5.381 MB), Total: 5.46 MB, FLOPs: 104,674,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 835/1724 finished in 0m09s\n",
      "Total channels prunned so far: 835\n",
      "\n",
      "Iteration 836 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 72)]\n",
      "Input: 0.077 MB, Params: 1,408,450 (5.373 MB), Total: 5.45 MB, FLOPs: 104,395,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 836/1724 finished in 0m09s\n",
      "Total channels prunned so far: 836\n",
      "\n",
      "Iteration 837 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 287)]\n",
      "Input: 0.077 MB, Params: 1,406,410 (5.365 MB), Total: 5.44 MB, FLOPs: 104,371,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 837/1724 finished in 0m09s\n",
      "Total channels prunned so far: 837\n",
      "\n",
      "Iteration 838 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.077 MB, Params: 1,405,184 (5.360 MB), Total: 5.44 MB, FLOPs: 103,703,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 838/1724 finished in 0m09s\n",
      "Total channels prunned so far: 838\n",
      "\n",
      "Iteration 839 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.077 MB, Params: 1,403,040 (5.352 MB), Total: 5.43 MB, FLOPs: 103,574,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 839/1724 finished in 0m09s\n",
      "Total channels prunned so far: 839\n",
      "\n",
      "Iteration 840 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.077 MB, Params: 1,399,600 (5.339 MB), Total: 5.42 MB, FLOPs: 103,465,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 840/1724 finished in 0m09s\n",
      "Total channels prunned so far: 840\n",
      "\n",
      "Iteration 841 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.077 MB, Params: 1,397,420 (5.331 MB), Total: 5.41 MB, FLOPs: 103,187,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 841/1724 finished in 0m09s\n",
      "Total channels prunned so far: 841\n",
      "\n",
      "Iteration 842 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.077 MB, Params: 1,395,294 (5.323 MB), Total: 5.40 MB, FLOPs: 103,060,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 842/1724 finished in 0m09s\n",
      "Total channels prunned so far: 842\n",
      "\n",
      "Iteration 843 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.077 MB, Params: 1,393,168 (5.315 MB), Total: 5.39 MB, FLOPs: 102,932,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 843/1724 finished in 0m09s\n",
      "Total channels prunned so far: 843\n",
      "\n",
      "Iteration 844 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 1,389,746 (5.301 MB), Total: 5.38 MB, FLOPs: 102,824,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 844/1724 finished in 0m09s\n",
      "Total channels prunned so far: 844\n",
      "\n",
      "Iteration 845 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.077 MB, Params: 1,385,685 (5.286 MB), Total: 5.36 MB, FLOPs: 102,776,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 845/1724 finished in 0m09s\n",
      "Total channels prunned so far: 845\n",
      "\n",
      "Iteration 846 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.077 MB, Params: 1,381,624 (5.270 MB), Total: 5.35 MB, FLOPs: 102,727,404\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 846/1724 finished in 0m09s\n",
      "Total channels prunned so far: 846\n",
      "\n",
      "Iteration 847 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.077 MB, Params: 1,377,563 (5.255 MB), Total: 5.33 MB, FLOPs: 102,678,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 847/1724 finished in 0m09s\n",
      "Total channels prunned so far: 847\n",
      "\n",
      "Iteration 848 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.077 MB, Params: 1,373,502 (5.239 MB), Total: 5.32 MB, FLOPs: 102,629,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 848/1724 finished in 0m09s\n",
      "Total channels prunned so far: 848\n",
      "\n",
      "Iteration 849 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 1,371,385 (5.231 MB), Total: 5.31 MB, FLOPs: 102,503,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 849/1724 finished in 0m09s\n",
      "Total channels prunned so far: 849\n",
      "\n",
      "Iteration 850 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.077 MB, Params: 1,369,268 (5.223 MB), Total: 5.30 MB, FLOPs: 102,376,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 850/1724 finished in 0m09s\n",
      "Total channels prunned so far: 850\n",
      "\n",
      "Iteration 851 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.077 MB, Params: 1,365,207 (5.208 MB), Total: 5.28 MB, FLOPs: 102,327,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 851/1724 finished in 0m09s\n",
      "Total channels prunned so far: 851\n",
      "\n",
      "Iteration 852 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 79)]\n",
      "Input: 0.077 MB, Params: 1,363,090 (5.200 MB), Total: 5.28 MB, FLOPs: 102,200,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 852/1724 finished in 0m09s\n",
      "Total channels prunned so far: 852\n",
      "\n",
      "Iteration 853 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 226)]\n",
      "Input: 0.077 MB, Params: 1,361,095 (5.192 MB), Total: 5.27 MB, FLOPs: 102,176,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 853/1724 finished in 0m09s\n",
      "Total channels prunned so far: 853\n",
      "\n",
      "Iteration 854 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 177)]\n",
      "Input: 0.077 MB, Params: 1,357,043 (5.177 MB), Total: 5.25 MB, FLOPs: 102,127,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 854/1724 finished in 0m09s\n",
      "Total channels prunned so far: 854\n",
      "\n",
      "Iteration 855 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 58)]\n",
      "Input: 0.077 MB, Params: 1,355,790 (5.172 MB), Total: 5.25 MB, FLOPs: 101,814,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 855/1724 finished in 0m09s\n",
      "Total channels prunned so far: 855\n",
      "\n",
      "Iteration 856 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 82)]\n",
      "Input: 0.077 MB, Params: 1,353,664 (5.164 MB), Total: 5.24 MB, FLOPs: 101,541,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 856/1724 finished in 0m09s\n",
      "Total channels prunned so far: 856\n",
      "\n",
      "Iteration 857 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 1,352,420 (5.159 MB), Total: 5.24 MB, FLOPs: 101,230,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 857/1724 finished in 0m09s\n",
      "Total channels prunned so far: 857\n",
      "\n",
      "Iteration 858 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.077 MB, Params: 1,350,303 (5.151 MB), Total: 5.23 MB, FLOPs: 100,959,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 858/1724 finished in 0m09s\n",
      "Total channels prunned so far: 858\n",
      "\n",
      "Iteration 859 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.077 MB, Params: 1,346,962 (5.138 MB), Total: 5.22 MB, FLOPs: 100,854,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 859/1724 finished in 0m09s\n",
      "Total channels prunned so far: 859\n",
      "\n",
      "Iteration 860 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 85)]\n",
      "Input: 0.077 MB, Params: 1,344,872 (5.130 MB), Total: 5.21 MB, FLOPs: 100,729,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 860/1724 finished in 0m09s\n",
      "Total channels prunned so far: 860\n",
      "\n",
      "Iteration 861 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 37)]\n",
      "Input: 0.077 MB, Params: 1,344,195 (5.128 MB), Total: 5.20 MB, FLOPs: 100,019,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 861/1724 finished in 0m09s\n",
      "Total channels prunned so far: 861\n",
      "\n",
      "Iteration 862 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.077 MB, Params: 1,340,152 (5.112 MB), Total: 5.19 MB, FLOPs: 99,970,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 862/1724 finished in 0m09s\n",
      "Total channels prunned so far: 862\n",
      "\n",
      "Iteration 863 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 36)]\n",
      "Input: 0.077 MB, Params: 1,339,475 (5.110 MB), Total: 5.19 MB, FLOPs: 99,260,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 863/1724 finished in 0m09s\n",
      "Total channels prunned so far: 863\n",
      "\n",
      "Iteration 864 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.077 MB, Params: 1,336,152 (5.097 MB), Total: 5.17 MB, FLOPs: 99,156,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 864/1724 finished in 0m09s\n",
      "Total channels prunned so far: 864\n",
      "\n",
      "Iteration 865 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 249)]\n",
      "Input: 0.077 MB, Params: 1,334,175 (5.089 MB), Total: 5.17 MB, FLOPs: 99,132,488\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 865/1724 finished in 0m09s\n",
      "Total channels prunned so far: 865\n",
      "\n",
      "Iteration 866 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 213)]\n",
      "Input: 0.077 MB, Params: 1,332,198 (5.082 MB), Total: 5.16 MB, FLOPs: 99,108,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 866/1724 finished in 0m09s\n",
      "Total channels prunned so far: 866\n",
      "\n",
      "Iteration 867 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.077 MB, Params: 1,330,221 (5.074 MB), Total: 5.15 MB, FLOPs: 99,085,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 867/1724 finished in 0m09s\n",
      "Total channels prunned so far: 867\n",
      "\n",
      "Iteration 868 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.077 MB, Params: 1,328,244 (5.067 MB), Total: 5.14 MB, FLOPs: 99,061,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 868/1724 finished in 0m09s\n",
      "Total channels prunned so far: 868\n",
      "\n",
      "Iteration 869 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.077 MB, Params: 1,326,267 (5.059 MB), Total: 5.14 MB, FLOPs: 99,037,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 869/1724 finished in 0m09s\n",
      "Total channels prunned so far: 869\n",
      "\n",
      "Iteration 870 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.077 MB, Params: 1,324,290 (5.052 MB), Total: 5.13 MB, FLOPs: 99,014,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 870/1724 finished in 0m09s\n",
      "Total channels prunned so far: 870\n",
      "\n",
      "Iteration 871 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.077 MB, Params: 1,322,313 (5.044 MB), Total: 5.12 MB, FLOPs: 98,990,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 871/1724 finished in 0m09s\n",
      "Total channels prunned so far: 871\n",
      "\n",
      "Iteration 872 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.077 MB, Params: 1,318,342 (5.029 MB), Total: 5.11 MB, FLOPs: 98,942,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 872/1724 finished in 0m09s\n",
      "Total channels prunned so far: 872\n",
      "\n",
      "Iteration 873 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 48)]\n",
      "Input: 0.077 MB, Params: 1,317,152 (5.025 MB), Total: 5.10 MB, FLOPs: 98,298,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 873/1724 finished in 0m09s\n",
      "Total channels prunned so far: 873\n",
      "\n",
      "Iteration 874 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.077 MB, Params: 1,313,838 (5.012 MB), Total: 5.09 MB, FLOPs: 98,193,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 874/1724 finished in 0m09s\n",
      "Total channels prunned so far: 874\n",
      "\n",
      "Iteration 875 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.077 MB, Params: 1,310,524 (4.999 MB), Total: 5.08 MB, FLOPs: 98,088,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 875/1724 finished in 0m09s\n",
      "Total channels prunned so far: 875\n",
      "\n",
      "Iteration 876 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 135)]\n",
      "Input: 0.077 MB, Params: 1,308,461 (4.991 MB), Total: 5.07 MB, FLOPs: 97,965,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 876/1724 finished in 0m09s\n",
      "Total channels prunned so far: 876\n",
      "\n",
      "Iteration 877 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 61)]\n",
      "Input: 0.077 MB, Params: 1,305,156 (4.979 MB), Total: 5.06 MB, FLOPs: 97,860,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 877/1724 finished in 0m09s\n",
      "Total channels prunned so far: 877\n",
      "\n",
      "Iteration 878 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.077 MB, Params: 1,301,212 (4.964 MB), Total: 5.04 MB, FLOPs: 97,813,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 878/1724 finished in 0m09s\n",
      "Total channels prunned so far: 878\n",
      "\n",
      "Iteration 879 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.077 MB, Params: 1,299,253 (4.956 MB), Total: 5.03 MB, FLOPs: 97,790,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 879/1724 finished in 0m09s\n",
      "Total channels prunned so far: 879\n",
      "\n",
      "Iteration 880 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 27)]\n",
      "Input: 0.077 MB, Params: 1,298,027 (4.952 MB), Total: 5.03 MB, FLOPs: 97,483,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 880/1724 finished in 0m09s\n",
      "Total channels prunned so far: 880\n",
      "\n",
      "Iteration 881 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 48)]\n",
      "Input: 0.077 MB, Params: 1,295,937 (4.944 MB), Total: 5.02 MB, FLOPs: 97,216,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 881/1724 finished in 0m09s\n",
      "Total channels prunned so far: 881\n",
      "\n",
      "Iteration 882 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 47)]\n",
      "Input: 0.077 MB, Params: 1,293,847 (4.936 MB), Total: 5.01 MB, FLOPs: 96,948,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 882/1724 finished in 0m09s\n",
      "Total channels prunned so far: 882\n",
      "\n",
      "Iteration 883 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.077 MB, Params: 1,291,888 (4.928 MB), Total: 5.01 MB, FLOPs: 96,925,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 883/1724 finished in 0m09s\n",
      "Total channels prunned so far: 883\n",
      "\n",
      "Iteration 884 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.077 MB, Params: 1,289,929 (4.921 MB), Total: 5.00 MB, FLOPs: 96,901,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 884/1724 finished in 0m09s\n",
      "Total channels prunned so far: 884\n",
      "\n",
      "Iteration 885 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.077 MB, Params: 1,286,012 (4.906 MB), Total: 4.98 MB, FLOPs: 96,854,560\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 885/1724 finished in 0m09s\n",
      "Total channels prunned so far: 885\n",
      "\n",
      "Iteration 886 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.077 MB, Params: 1,284,804 (4.901 MB), Total: 4.98 MB, FLOPs: 96,552,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 886/1724 finished in 0m09s\n",
      "Total channels prunned so far: 886\n",
      "\n",
      "Iteration 887 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 232)]\n",
      "Input: 0.077 MB, Params: 1,282,854 (4.894 MB), Total: 4.97 MB, FLOPs: 96,529,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 887/1724 finished in 0m09s\n",
      "Total channels prunned so far: 887\n",
      "\n",
      "Iteration 888 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.077 MB, Params: 1,280,904 (4.886 MB), Total: 4.96 MB, FLOPs: 96,506,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 888/1724 finished in 0m09s\n",
      "Total channels prunned so far: 888\n",
      "\n",
      "Iteration 889 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.077 MB, Params: 1,277,005 (4.871 MB), Total: 4.95 MB, FLOPs: 96,459,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 889/1724 finished in 0m09s\n",
      "Total channels prunned so far: 889\n",
      "\n",
      "Iteration 890 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 127)]\n",
      "Input: 0.077 MB, Params: 1,273,727 (4.859 MB), Total: 4.94 MB, FLOPs: 96,355,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 890/1724 finished in 0m09s\n",
      "Total channels prunned so far: 890\n",
      "\n",
      "Iteration 891 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 205)]\n",
      "Input: 0.077 MB, Params: 1,269,837 (4.844 MB), Total: 4.92 MB, FLOPs: 96,308,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 891/1724 finished in 0m09s\n",
      "Total channels prunned so far: 891\n",
      "\n",
      "Iteration 892 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.077 MB, Params: 1,267,810 (4.836 MB), Total: 4.91 MB, FLOPs: 96,187,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 892/1724 finished in 0m09s\n",
      "Total channels prunned so far: 892\n",
      "\n",
      "Iteration 893 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 45)]\n",
      "Input: 0.077 MB, Params: 1,265,738 (4.828 MB), Total: 4.91 MB, FLOPs: 95,922,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 893/1724 finished in 0m09s\n",
      "Total channels prunned so far: 893\n",
      "\n",
      "Iteration 894 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 6)]\n",
      "Input: 0.077 MB, Params: 1,265,295 (4.827 MB), Total: 4.90 MB, FLOPs: 95,422,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 894/1724 finished in 0m09s\n",
      "Total channels prunned so far: 894\n",
      "\n",
      "Iteration 895 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 144)]\n",
      "Input: 0.077 MB, Params: 1,263,277 (4.819 MB), Total: 4.90 MB, FLOPs: 95,301,560\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 895/1724 finished in 0m09s\n",
      "Total channels prunned so far: 895\n",
      "\n",
      "Iteration 896 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.077 MB, Params: 1,261,345 (4.812 MB), Total: 4.89 MB, FLOPs: 95,278,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 896/1724 finished in 0m09s\n",
      "Total channels prunned so far: 896\n",
      "\n",
      "Iteration 897 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.077 MB, Params: 1,260,146 (4.807 MB), Total: 4.88 MB, FLOPs: 94,978,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 897/1724 finished in 0m09s\n",
      "Total channels prunned so far: 897\n",
      "\n",
      "Iteration 898 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.077 MB, Params: 1,259,487 (4.805 MB), Total: 4.88 MB, FLOPs: 94,288,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 898/1724 finished in 0m09s\n",
      "Total channels prunned so far: 898\n",
      "\n",
      "Iteration 899 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 250)]\n",
      "Input: 0.077 MB, Params: 1,257,555 (4.797 MB), Total: 4.87 MB, FLOPs: 94,264,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 899/1724 finished in 0m09s\n",
      "Total channels prunned so far: 899\n",
      "\n",
      "Iteration 900 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.077 MB, Params: 1,254,304 (4.785 MB), Total: 4.86 MB, FLOPs: 94,162,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 900/1724 finished in 0m09s\n",
      "Total channels prunned so far: 900\n",
      "\n",
      "Iteration 901 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.077 MB, Params: 1,250,441 (4.770 MB), Total: 4.85 MB, FLOPs: 94,115,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 901/1724 finished in 0m09s\n",
      "Total channels prunned so far: 901\n",
      "\n",
      "Iteration 902 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.077 MB, Params: 1,246,578 (4.755 MB), Total: 4.83 MB, FLOPs: 94,069,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 902/1724 finished in 0m09s\n",
      "Total channels prunned so far: 902\n",
      "\n",
      "Iteration 903 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.077 MB, Params: 1,242,715 (4.741 MB), Total: 4.82 MB, FLOPs: 94,023,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 903/1724 finished in 0m09s\n",
      "Total channels prunned so far: 903\n",
      "\n",
      "Iteration 904 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 38)]\n",
      "Input: 0.077 MB, Params: 1,240,661 (4.733 MB), Total: 4.81 MB, FLOPs: 93,761,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 904/1724 finished in 0m09s\n",
      "Total channels prunned so far: 904\n",
      "\n",
      "Iteration 905 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 38)]\n",
      "Input: 0.077 MB, Params: 1,238,661 (4.725 MB), Total: 4.80 MB, FLOPs: 93,641,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 905/1724 finished in 0m09s\n",
      "Total channels prunned so far: 905\n",
      "\n",
      "Iteration 906 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.077 MB, Params: 1,236,661 (4.717 MB), Total: 4.79 MB, FLOPs: 93,521,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 906/1724 finished in 0m09s\n",
      "Total channels prunned so far: 906\n",
      "\n",
      "Iteration 907 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 1,233,455 (4.705 MB), Total: 4.78 MB, FLOPs: 93,420,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 907/1724 finished in 0m09s\n",
      "Total channels prunned so far: 907\n",
      "\n",
      "Iteration 908 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 203)]\n",
      "Input: 0.077 MB, Params: 1,231,550 (4.698 MB), Total: 4.77 MB, FLOPs: 93,397,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 908/1724 finished in 0m09s\n",
      "Total channels prunned so far: 908\n",
      "\n",
      "Iteration 909 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.077 MB, Params: 1,227,705 (4.683 MB), Total: 4.76 MB, FLOPs: 93,351,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 909/1724 finished in 0m09s\n",
      "Total channels prunned so far: 909\n",
      "\n",
      "Iteration 910 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.077 MB, Params: 1,225,809 (4.676 MB), Total: 4.75 MB, FLOPs: 93,328,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 910/1724 finished in 0m09s\n",
      "Total channels prunned so far: 910\n",
      "\n",
      "Iteration 911 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.077 MB, Params: 1,224,619 (4.672 MB), Total: 4.75 MB, FLOPs: 93,031,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 911/1724 finished in 0m09s\n",
      "Total channels prunned so far: 911\n",
      "\n",
      "Iteration 912 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 1,222,628 (4.664 MB), Total: 4.74 MB, FLOPs: 92,911,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 912/1724 finished in 0m09s\n",
      "Total channels prunned so far: 912\n",
      "\n",
      "Iteration 913 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.077 MB, Params: 1,220,732 (4.657 MB), Total: 4.73 MB, FLOPs: 92,889,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 913/1724 finished in 0m09s\n",
      "Total channels prunned so far: 913\n",
      "\n",
      "Iteration 914 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.077 MB, Params: 1,218,836 (4.649 MB), Total: 4.73 MB, FLOPs: 92,866,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 914/1724 finished in 0m09s\n",
      "Total channels prunned so far: 914\n",
      "\n",
      "Iteration 915 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 9)]\n",
      "Input: 0.077 MB, Params: 1,218,177 (4.647 MB), Total: 4.72 MB, FLOPs: 92,175,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 915/1724 finished in 0m09s\n",
      "Total channels prunned so far: 915\n",
      "\n",
      "Iteration 916 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.077 MB, Params: 1,216,186 (4.639 MB), Total: 4.72 MB, FLOPs: 92,055,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 916/1724 finished in 0m09s\n",
      "Total channels prunned so far: 916\n",
      "\n",
      "Iteration 917 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.077 MB, Params: 1,214,290 (4.632 MB), Total: 4.71 MB, FLOPs: 92,033,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 917/1724 finished in 0m09s\n",
      "Total channels prunned so far: 917\n",
      "\n",
      "Iteration 918 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.077 MB, Params: 1,210,481 (4.618 MB), Total: 4.69 MB, FLOPs: 91,987,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 918/1724 finished in 0m09s\n",
      "Total channels prunned so far: 918\n",
      "\n",
      "Iteration 919 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.077 MB, Params: 1,208,594 (4.610 MB), Total: 4.69 MB, FLOPs: 91,964,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 919/1724 finished in 0m09s\n",
      "Total channels prunned so far: 919\n",
      "\n",
      "Iteration 920 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 183)]\n",
      "Input: 0.077 MB, Params: 1,204,794 (4.596 MB), Total: 4.67 MB, FLOPs: 91,919,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 920/1724 finished in 0m09s\n",
      "Total channels prunned so far: 920\n",
      "\n",
      "Iteration 921 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 68)]\n",
      "Input: 0.077 MB, Params: 1,201,633 (4.584 MB), Total: 4.66 MB, FLOPs: 91,819,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 921/1724 finished in 0m09s\n",
      "Total channels prunned so far: 921\n",
      "\n",
      "Iteration 922 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 98)]\n",
      "Input: 0.077 MB, Params: 1,197,842 (4.569 MB), Total: 4.65 MB, FLOPs: 91,774,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 922/1724 finished in 0m09s\n",
      "Total channels prunned so far: 922\n",
      "\n",
      "Iteration 923 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.077 MB, Params: 1,195,860 (4.562 MB), Total: 4.64 MB, FLOPs: 91,655,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 923/1724 finished in 0m09s\n",
      "Total channels prunned so far: 923\n",
      "\n",
      "Iteration 924 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 232)]\n",
      "Input: 0.077 MB, Params: 1,193,991 (4.555 MB), Total: 4.63 MB, FLOPs: 91,632,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 924/1724 finished in 0m09s\n",
      "Total channels prunned so far: 924\n",
      "\n",
      "Iteration 925 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.077 MB, Params: 1,193,954 (4.555 MB), Total: 4.63 MB, FLOPs: 89,901,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 925/1724 finished in 0m09s\n",
      "Total channels prunned so far: 925\n",
      "\n",
      "Iteration 926 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.077 MB, Params: 1,192,085 (4.547 MB), Total: 4.62 MB, FLOPs: 89,879,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 926/1724 finished in 0m09s\n",
      "Total channels prunned so far: 926\n",
      "\n",
      "Iteration 927 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.077 MB, Params: 1,192,048 (4.547 MB), Total: 4.62 MB, FLOPs: 89,669,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 927/1724 finished in 0m09s\n",
      "Total channels prunned so far: 927\n",
      "\n",
      "Iteration 928 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.077 MB, Params: 1,188,905 (4.535 MB), Total: 4.61 MB, FLOPs: 89,570,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 928/1724 finished in 0m09s\n",
      "Total channels prunned so far: 928\n",
      "\n",
      "Iteration 929 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 204)]\n",
      "Input: 0.077 MB, Params: 1,185,141 (4.521 MB), Total: 4.60 MB, FLOPs: 89,525,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 929/1724 finished in 0m09s\n",
      "Total channels prunned so far: 929\n",
      "\n",
      "Iteration 930 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 1,182,007 (4.509 MB), Total: 4.59 MB, FLOPs: 89,426,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 930/1724 finished in 0m09s\n",
      "Total channels prunned so far: 930\n",
      "\n",
      "Iteration 931 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.077 MB, Params: 1,180,147 (4.502 MB), Total: 4.58 MB, FLOPs: 89,403,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 931/1724 finished in 0m09s\n",
      "Total channels prunned so far: 931\n",
      "\n",
      "Iteration 932 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 1,178,957 (4.497 MB), Total: 4.57 MB, FLOPs: 89,106,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 932/1724 finished in 0m09s\n",
      "Total channels prunned so far: 932\n",
      "\n",
      "Iteration 933 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.077 MB, Params: 1,177,097 (4.490 MB), Total: 4.57 MB, FLOPs: 89,084,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 933/1724 finished in 0m09s\n",
      "Total channels prunned so far: 933\n",
      "\n",
      "Iteration 934 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.077 MB, Params: 1,175,133 (4.483 MB), Total: 4.56 MB, FLOPs: 88,966,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 934/1724 finished in 0m09s\n",
      "Total channels prunned so far: 934\n",
      "\n",
      "Iteration 935 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.077 MB, Params: 1,173,169 (4.475 MB), Total: 4.55 MB, FLOPs: 88,848,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 935/1724 finished in 0m09s\n",
      "Total channels prunned so far: 935\n",
      "\n",
      "Iteration 936 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.077 MB, Params: 1,169,432 (4.461 MB), Total: 4.54 MB, FLOPs: 88,803,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 936/1724 finished in 0m09s\n",
      "Total channels prunned so far: 936\n",
      "\n",
      "Iteration 937 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.077 MB, Params: 1,168,242 (4.456 MB), Total: 4.53 MB, FLOPs: 88,506,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 937/1724 finished in 0m09s\n",
      "Total channels prunned so far: 937\n",
      "\n",
      "Iteration 938 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 1,165,135 (4.445 MB), Total: 4.52 MB, FLOPs: 88,408,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 938/1724 finished in 0m09s\n",
      "Total channels prunned so far: 938\n",
      "\n",
      "Iteration 939 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.077 MB, Params: 1,163,945 (4.440 MB), Total: 4.52 MB, FLOPs: 88,111,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 939/1724 finished in 0m09s\n",
      "Total channels prunned so far: 939\n",
      "\n",
      "Iteration 940 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 67)]\n",
      "Input: 0.077 MB, Params: 1,161,990 (4.433 MB), Total: 4.51 MB, FLOPs: 87,994,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 940/1724 finished in 0m09s\n",
      "Total channels prunned so far: 940\n",
      "\n",
      "Iteration 941 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 61)]\n",
      "Input: 0.077 MB, Params: 1,160,139 (4.426 MB), Total: 4.50 MB, FLOPs: 87,972,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 941/1724 finished in 0m09s\n",
      "Total channels prunned so far: 941\n",
      "\n",
      "Iteration 942 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.077 MB, Params: 1,156,420 (4.411 MB), Total: 4.49 MB, FLOPs: 87,927,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 942/1724 finished in 0m09s\n",
      "Total channels prunned so far: 942\n",
      "\n",
      "Iteration 943 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 1,152,701 (4.397 MB), Total: 4.47 MB, FLOPs: 87,882,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 943/1724 finished in 0m09s\n",
      "Total channels prunned so far: 943\n",
      "\n",
      "Iteration 944 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.077 MB, Params: 1,148,982 (4.383 MB), Total: 4.46 MB, FLOPs: 87,838,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 944/1724 finished in 0m09s\n",
      "Total channels prunned so far: 944\n",
      "\n",
      "Iteration 945 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.077 MB, Params: 1,147,036 (4.376 MB), Total: 4.45 MB, FLOPs: 87,589,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 945/1724 finished in 0m09s\n",
      "Total channels prunned so far: 945\n",
      "\n",
      "Iteration 946 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.077 MB, Params: 1,145,090 (4.368 MB), Total: 4.45 MB, FLOPs: 87,472,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 946/1724 finished in 0m09s\n",
      "Total channels prunned so far: 946\n",
      "\n",
      "Iteration 947 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 277)]\n",
      "Input: 0.077 MB, Params: 1,143,266 (4.361 MB), Total: 4.44 MB, FLOPs: 87,450,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 947/1724 finished in 0m09s\n",
      "Total channels prunned so far: 947\n",
      "\n",
      "Iteration 948 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.077 MB, Params: 1,141,442 (4.354 MB), Total: 4.43 MB, FLOPs: 87,429,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 948/1724 finished in 0m09s\n",
      "Total channels prunned so far: 948\n",
      "\n",
      "Iteration 949 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 239)]\n",
      "Input: 0.077 MB, Params: 1,139,618 (4.347 MB), Total: 4.42 MB, FLOPs: 87,407,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 949/1724 finished in 0m09s\n",
      "Total channels prunned so far: 949\n",
      "\n",
      "Iteration 950 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 23)]\n",
      "Input: 0.077 MB, Params: 1,138,959 (4.345 MB), Total: 4.42 MB, FLOPs: 86,749,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 950/1724 finished in 0m09s\n",
      "Total channels prunned so far: 950\n",
      "\n",
      "Iteration 951 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 179)]\n",
      "Input: 0.077 MB, Params: 1,135,267 (4.331 MB), Total: 4.41 MB, FLOPs: 86,704,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 951/1724 finished in 0m09s\n",
      "Total channels prunned so far: 951\n",
      "\n",
      "Iteration 952 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.077 MB, Params: 1,133,321 (4.323 MB), Total: 4.40 MB, FLOPs: 86,588,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 952/1724 finished in 0m09s\n",
      "Total channels prunned so far: 952\n",
      "\n",
      "Iteration 953 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.077 MB, Params: 1,131,506 (4.316 MB), Total: 4.39 MB, FLOPs: 86,566,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 953/1724 finished in 0m09s\n",
      "Total channels prunned so far: 953\n",
      "\n",
      "Iteration 954 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 38)]\n",
      "Input: 0.077 MB, Params: 1,130,847 (4.314 MB), Total: 4.39 MB, FLOPs: 85,908,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 954/1724 finished in 0m09s\n",
      "Total channels prunned so far: 954\n",
      "\n",
      "Iteration 955 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.077 MB, Params: 1,129,032 (4.307 MB), Total: 4.38 MB, FLOPs: 85,886,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 955/1724 finished in 0m09s\n",
      "Total channels prunned so far: 955\n",
      "\n",
      "Iteration 956 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.077 MB, Params: 1,125,358 (4.293 MB), Total: 4.37 MB, FLOPs: 85,842,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 956/1724 finished in 0m09s\n",
      "Total channels prunned so far: 956\n",
      "\n",
      "Iteration 957 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.077 MB, Params: 1,121,684 (4.279 MB), Total: 4.36 MB, FLOPs: 85,798,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 957/1724 finished in 0m09s\n",
      "Total channels prunned so far: 957\n",
      "\n",
      "Iteration 958 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.077 MB, Params: 1,119,738 (4.271 MB), Total: 4.35 MB, FLOPs: 85,681,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 958/1724 finished in 0m09s\n",
      "Total channels prunned so far: 958\n",
      "\n",
      "Iteration 959 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.077 MB, Params: 1,116,721 (4.260 MB), Total: 4.34 MB, FLOPs: 85,586,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 959/1724 finished in 0m09s\n",
      "Total channels prunned so far: 959\n",
      "\n",
      "Iteration 960 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.077 MB, Params: 1,115,630 (4.256 MB), Total: 4.33 MB, FLOPs: 85,015,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 960/1724 finished in 0m09s\n",
      "Total channels prunned so far: 960\n",
      "\n",
      "Iteration 961 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 213)]\n",
      "Input: 0.077 MB, Params: 1,113,833 (4.249 MB), Total: 4.33 MB, FLOPs: 84,994,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 961/1724 finished in 0m09s\n",
      "Total channels prunned so far: 961\n",
      "\n",
      "Iteration 962 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 130)]\n",
      "Input: 0.077 MB, Params: 1,111,896 (4.242 MB), Total: 4.32 MB, FLOPs: 84,877,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 962/1724 finished in 0m09s\n",
      "Total channels prunned so far: 962\n",
      "\n",
      "Iteration 963 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 1,109,959 (4.234 MB), Total: 4.31 MB, FLOPs: 84,761,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 963/1724 finished in 0m09s\n",
      "Total channels prunned so far: 963\n",
      "\n",
      "Iteration 964 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 34)]\n",
      "Input: 0.077 MB, Params: 1,108,058 (4.227 MB), Total: 4.30 MB, FLOPs: 84,515,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 964/1724 finished in 0m09s\n",
      "Total channels prunned so far: 964\n",
      "\n",
      "Iteration 965 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 40)]\n",
      "Input: 0.077 MB, Params: 1,106,967 (4.223 MB), Total: 4.30 MB, FLOPs: 83,944,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 965/1724 finished in 0m09s\n",
      "Total channels prunned so far: 965\n",
      "\n",
      "Iteration 966 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 1,103,311 (4.209 MB), Total: 4.29 MB, FLOPs: 83,900,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 966/1724 finished in 0m09s\n",
      "Total channels prunned so far: 966\n",
      "\n",
      "Iteration 967 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 1,099,655 (4.195 MB), Total: 4.27 MB, FLOPs: 83,856,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 967/1724 finished in 0m09s\n",
      "Total channels prunned so far: 967\n",
      "\n",
      "Iteration 968 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 1,097,727 (4.187 MB), Total: 4.26 MB, FLOPs: 83,740,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 968/1724 finished in 0m09s\n",
      "Total channels prunned so far: 968\n",
      "\n",
      "Iteration 969 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.077 MB, Params: 1,095,948 (4.181 MB), Total: 4.26 MB, FLOPs: 83,719,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 969/1724 finished in 0m09s\n",
      "Total channels prunned so far: 969\n",
      "\n",
      "Iteration 970 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.077 MB, Params: 1,094,020 (4.173 MB), Total: 4.25 MB, FLOPs: 83,604,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 970/1724 finished in 0m09s\n",
      "Total channels prunned so far: 970\n",
      "\n",
      "Iteration 971 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 73)]\n",
      "Input: 0.077 MB, Params: 1,092,866 (4.169 MB), Total: 4.25 MB, FLOPs: 83,315,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 971/1724 finished in 0m09s\n",
      "Total channels prunned so far: 971\n",
      "\n",
      "Iteration 972 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.077 MB, Params: 1,092,225 (4.167 MB), Total: 4.24 MB, FLOPs: 82,675,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 972/1724 finished in 0m09s\n",
      "Total channels prunned so far: 972\n",
      "\n",
      "Iteration 973 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 1,089,262 (4.155 MB), Total: 4.23 MB, FLOPs: 82,583,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 973/1724 finished in 0m09s\n",
      "Total channels prunned so far: 973\n",
      "\n",
      "Iteration 974 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.077 MB, Params: 1,087,483 (4.148 MB), Total: 4.23 MB, FLOPs: 82,561,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 974/1724 finished in 0m09s\n",
      "Total channels prunned so far: 974\n",
      "\n",
      "Iteration 975 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.077 MB, Params: 1,084,520 (4.137 MB), Total: 4.21 MB, FLOPs: 82,469,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 975/1724 finished in 0m09s\n",
      "Total channels prunned so far: 975\n",
      "\n",
      "Iteration 976 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 28)]\n",
      "Input: 0.077 MB, Params: 1,083,879 (4.135 MB), Total: 4.21 MB, FLOPs: 81,829,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 976/1724 finished in 0m09s\n",
      "Total channels prunned so far: 976\n",
      "\n",
      "Iteration 977 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.077 MB, Params: 1,082,815 (4.131 MB), Total: 4.21 MB, FLOPs: 81,278,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 977/1724 finished in 0m09s\n",
      "Total channels prunned so far: 977\n",
      "\n",
      "Iteration 978 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.077 MB, Params: 1,080,905 (4.123 MB), Total: 4.20 MB, FLOPs: 81,163,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 978/1724 finished in 0m09s\n",
      "Total channels prunned so far: 978\n",
      "\n",
      "Iteration 979 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.077 MB, Params: 1,077,285 (4.110 MB), Total: 4.19 MB, FLOPs: 81,120,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 979/1724 finished in 0m09s\n",
      "Total channels prunned so far: 979\n",
      "\n",
      "Iteration 980 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 72)]\n",
      "Input: 0.077 MB, Params: 1,075,375 (4.102 MB), Total: 4.18 MB, FLOPs: 81,005,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 980/1724 finished in 0m09s\n",
      "Total channels prunned so far: 980\n",
      "\n",
      "Iteration 981 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.077 MB, Params: 1,071,755 (4.088 MB), Total: 4.17 MB, FLOPs: 80,962,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 981/1724 finished in 0m09s\n",
      "Total channels prunned so far: 981\n",
      "\n",
      "Iteration 982 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.077 MB, Params: 1,069,845 (4.081 MB), Total: 4.16 MB, FLOPs: 80,847,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 982/1724 finished in 0m09s\n",
      "Total channels prunned so far: 982\n",
      "\n",
      "Iteration 983 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.077 MB, Params: 1,066,927 (4.070 MB), Total: 4.15 MB, FLOPs: 80,756,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 983/1724 finished in 0m09s\n",
      "Total channels prunned so far: 983\n",
      "\n",
      "Iteration 984 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.077 MB, Params: 1,066,890 (4.070 MB), Total: 4.15 MB, FLOPs: 74,087,567\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 984/1724 finished in 0m09s\n",
      "Total channels prunned so far: 984\n",
      "\n",
      "Iteration 985 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 1,064,989 (4.063 MB), Total: 4.14 MB, FLOPs: 73,996,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 985/1724 finished in 0m09s\n",
      "Total channels prunned so far: 985\n",
      "\n",
      "Iteration 986 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.077 MB, Params: 1,063,228 (4.056 MB), Total: 4.13 MB, FLOPs: 73,975,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 986/1724 finished in 0m09s\n",
      "Total channels prunned so far: 986\n",
      "\n",
      "Iteration 987 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.077 MB, Params: 1,061,467 (4.049 MB), Total: 4.13 MB, FLOPs: 73,954,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 987/1724 finished in 0m09s\n",
      "Total channels prunned so far: 987\n",
      "\n",
      "Iteration 988 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 109)]\n",
      "Input: 0.077 MB, Params: 1,058,558 (4.038 MB), Total: 4.11 MB, FLOPs: 73,877,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 988/1724 finished in 0m09s\n",
      "Total channels prunned so far: 988\n",
      "\n",
      "Iteration 989 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 61)]\n",
      "Input: 0.077 MB, Params: 1,056,720 (4.031 MB), Total: 4.11 MB, FLOPs: 73,668,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 989/1724 finished in 0m09s\n",
      "Total channels prunned so far: 989\n",
      "\n",
      "Iteration 990 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.077 MB, Params: 1,053,811 (4.020 MB), Total: 4.10 MB, FLOPs: 73,591,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 990/1724 finished in 0m09s\n",
      "Total channels prunned so far: 990\n",
      "\n",
      "Iteration 991 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.077 MB, Params: 1,052,050 (4.013 MB), Total: 4.09 MB, FLOPs: 73,570,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 991/1724 finished in 0m09s\n",
      "Total channels prunned so far: 991\n",
      "\n",
      "Iteration 992 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.077 MB, Params: 1,048,484 (4.000 MB), Total: 4.08 MB, FLOPs: 73,527,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 992/1724 finished in 0m09s\n",
      "Total channels prunned so far: 992\n",
      "\n",
      "Iteration 993 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.077 MB, Params: 1,045,584 (3.989 MB), Total: 4.07 MB, FLOPs: 73,451,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 993/1724 finished in 0m09s\n",
      "Total channels prunned so far: 993\n",
      "\n",
      "Iteration 994 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.077 MB, Params: 1,043,832 (3.982 MB), Total: 4.06 MB, FLOPs: 73,430,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 994/1724 finished in 0m09s\n",
      "Total channels prunned so far: 994\n",
      "\n",
      "Iteration 995 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 97)]\n",
      "Input: 0.077 MB, Params: 1,040,932 (3.971 MB), Total: 4.05 MB, FLOPs: 73,354,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 995/1724 finished in 0m09s\n",
      "Total channels prunned so far: 995\n",
      "\n",
      "Iteration 996 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.077 MB, Params: 1,039,076 (3.964 MB), Total: 4.04 MB, FLOPs: 73,265,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 996/1724 finished in 0m09s\n",
      "Total channels prunned so far: 996\n",
      "\n",
      "Iteration 997 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 1,035,537 (3.950 MB), Total: 4.03 MB, FLOPs: 73,222,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 997/1724 finished in 0m09s\n",
      "Total channels prunned so far: 997\n",
      "\n",
      "Iteration 998 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.077 MB, Params: 1,033,681 (3.943 MB), Total: 4.02 MB, FLOPs: 73,133,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 998/1724 finished in 0m09s\n",
      "Total channels prunned so far: 998\n",
      "\n",
      "Iteration 999 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 1,031,938 (3.937 MB), Total: 4.01 MB, FLOPs: 73,112,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 999/1724 finished in 0m09s\n",
      "Total channels prunned so far: 999\n",
      "\n",
      "Iteration 1000 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.077 MB, Params: 1,028,408 (3.923 MB), Total: 4.00 MB, FLOPs: 73,070,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1000/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1000\n",
      "\n",
      "Iteration 1001 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 149)]\n",
      "Input: 0.077 MB, Params: 1,024,878 (3.910 MB), Total: 3.99 MB, FLOPs: 73,027,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1001/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1001\n",
      "\n",
      "Iteration 1002 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.077 MB, Params: 1,022,023 (3.899 MB), Total: 3.98 MB, FLOPs: 72,952,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1002/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1002\n",
      "\n",
      "Iteration 1003 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 1,018,502 (3.885 MB), Total: 3.96 MB, FLOPs: 72,910,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1003/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1003\n",
      "\n",
      "Iteration 1004 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.077 MB, Params: 1,016,682 (3.878 MB), Total: 3.96 MB, FLOPs: 72,701,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1004/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1004\n",
      "\n",
      "Iteration 1005 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.077 MB, Params: 1,014,844 (3.871 MB), Total: 3.95 MB, FLOPs: 72,613,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1005/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1005\n",
      "\n",
      "Iteration 1006 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 23)]\n",
      "Input: 0.077 MB, Params: 1,014,212 (3.869 MB), Total: 3.95 MB, FLOPs: 72,014,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1006/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1006\n",
      "\n",
      "Iteration 1007 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.077 MB, Params: 1,012,496 (3.862 MB), Total: 3.94 MB, FLOPs: 71,993,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1007/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1007\n",
      "\n",
      "Iteration 1008 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 34)]\n",
      "Input: 0.077 MB, Params: 1,011,864 (3.860 MB), Total: 3.94 MB, FLOPs: 71,394,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1008/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1008\n",
      "\n",
      "Iteration 1009 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.077 MB, Params: 1,008,352 (3.847 MB), Total: 3.92 MB, FLOPs: 71,352,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1009/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1009\n",
      "\n",
      "Iteration 1010 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.077 MB, Params: 1,004,840 (3.833 MB), Total: 3.91 MB, FLOPs: 71,309,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1010/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1010\n",
      "\n",
      "Iteration 1011 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 1,003,002 (3.826 MB), Total: 3.90 MB, FLOPs: 71,221,777\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1011/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1011\n",
      "\n",
      "Iteration 1012 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.077 MB, Params: 1,001,875 (3.822 MB), Total: 3.90 MB, FLOPs: 70,968,427\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1012/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1012\n",
      "\n",
      "Iteration 1013 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.077 MB, Params: 1,000,177 (3.815 MB), Total: 3.89 MB, FLOPs: 70,948,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1013/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1013\n",
      "\n",
      "Iteration 1014 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.077 MB, Params: 997,367 (3.805 MB), Total: 3.88 MB, FLOPs: 70,874,119\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1014/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1014\n",
      "\n",
      "Iteration 1015 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.077 MB, Params: 993,873 (3.791 MB), Total: 3.87 MB, FLOPs: 70,832,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1015/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1015\n",
      "\n",
      "Iteration 1016 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 230)]\n",
      "Input: 0.077 MB, Params: 992,184 (3.785 MB), Total: 3.86 MB, FLOPs: 70,811,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1016/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1016\n",
      "\n",
      "Iteration 1017 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 988,699 (3.772 MB), Total: 3.85 MB, FLOPs: 70,770,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1017/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1017\n",
      "\n",
      "Iteration 1018 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.077 MB, Params: 986,870 (3.765 MB), Total: 3.84 MB, FLOPs: 70,682,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1018/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1018\n",
      "\n",
      "Iteration 1019 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 983,385 (3.751 MB), Total: 3.83 MB, FLOPs: 70,640,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1019/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1019\n",
      "\n",
      "Iteration 1020 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.077 MB, Params: 980,611 (3.741 MB), Total: 3.82 MB, FLOPs: 70,567,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1020/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1020\n",
      "\n",
      "Iteration 1021 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.077 MB, Params: 979,484 (3.736 MB), Total: 3.81 MB, FLOPs: 70,314,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1021/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1021\n",
      "\n",
      "Iteration 1022 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.077 MB, Params: 976,710 (3.726 MB), Total: 3.80 MB, FLOPs: 70,240,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1022/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1022\n",
      "\n",
      "Iteration 1023 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.077 MB, Params: 976,078 (3.723 MB), Total: 3.80 MB, FLOPs: 69,641,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1023/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1023\n",
      "\n",
      "Iteration 1024 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 68)]\n",
      "Input: 0.077 MB, Params: 972,611 (3.710 MB), Total: 3.79 MB, FLOPs: 69,599,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1024/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1024\n",
      "\n",
      "Iteration 1025 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 969,144 (3.697 MB), Total: 3.77 MB, FLOPs: 69,558,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1025/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1025\n",
      "\n",
      "Iteration 1026 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 31)]\n",
      "Input: 0.077 MB, Params: 967,369 (3.690 MB), Total: 3.77 MB, FLOPs: 69,354,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1026/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1026\n",
      "\n",
      "Iteration 1027 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.077 MB, Params: 965,716 (3.684 MB), Total: 3.76 MB, FLOPs: 69,335,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1027/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1027\n",
      "\n",
      "Iteration 1028 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.077 MB, Params: 962,960 (3.673 MB), Total: 3.75 MB, FLOPs: 69,262,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1028/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1028\n",
      "\n",
      "Iteration 1029 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 961,842 (3.669 MB), Total: 3.75 MB, FLOPs: 69,010,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1029/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1029\n",
      "\n",
      "Iteration 1030 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.077 MB, Params: 959,086 (3.659 MB), Total: 3.74 MB, FLOPs: 68,937,683\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1030/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1030\n",
      "\n",
      "Iteration 1031 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 956,330 (3.648 MB), Total: 3.72 MB, FLOPs: 68,864,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1031/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1031\n",
      "\n",
      "Iteration 1032 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.077 MB, Params: 954,555 (3.641 MB), Total: 3.72 MB, FLOPs: 68,779,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1032/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1032\n",
      "\n",
      "Iteration 1033 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.077 MB, Params: 951,124 (3.628 MB), Total: 3.71 MB, FLOPs: 68,738,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1033/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1033\n",
      "\n",
      "Iteration 1034 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 89)]\n",
      "Input: 0.077 MB, Params: 947,693 (3.615 MB), Total: 3.69 MB, FLOPs: 68,697,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1034/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1034\n",
      "\n",
      "Iteration 1035 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.077 MB, Params: 944,964 (3.605 MB), Total: 3.68 MB, FLOPs: 68,624,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1035/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1035\n",
      "\n",
      "Iteration 1036 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.077 MB, Params: 941,542 (3.592 MB), Total: 3.67 MB, FLOPs: 68,583,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1036/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1036\n",
      "\n",
      "Iteration 1037 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 133)]\n",
      "Input: 0.077 MB, Params: 938,120 (3.579 MB), Total: 3.66 MB, FLOPs: 68,542,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1037/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1037\n",
      "\n",
      "Iteration 1038 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.077 MB, Params: 937,002 (3.574 MB), Total: 3.65 MB, FLOPs: 68,291,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1038/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1038\n",
      "\n",
      "Iteration 1039 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.077 MB, Params: 934,291 (3.564 MB), Total: 3.64 MB, FLOPs: 68,219,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1039/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1039\n",
      "\n",
      "Iteration 1040 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.077 MB, Params: 930,878 (3.551 MB), Total: 3.63 MB, FLOPs: 68,178,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1040/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1040\n",
      "\n",
      "Iteration 1041 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.077 MB, Params: 929,270 (3.545 MB), Total: 3.62 MB, FLOPs: 68,159,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 1041/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1041\n",
      "\n",
      "Iteration 1042 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 114)]\n",
      "Input: 0.077 MB, Params: 927,662 (3.539 MB), Total: 3.62 MB, FLOPs: 68,139,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1042/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1042\n",
      "\n",
      "Iteration 1043 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.077 MB, Params: 926,054 (3.533 MB), Total: 3.61 MB, FLOPs: 68,120,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1043/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1043\n",
      "\n",
      "Iteration 1044 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 237)]\n",
      "Input: 0.077 MB, Params: 924,446 (3.526 MB), Total: 3.60 MB, FLOPs: 68,101,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1044/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1044\n",
      "\n",
      "Iteration 1045 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.077 MB, Params: 922,838 (3.520 MB), Total: 3.60 MB, FLOPs: 68,082,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1045/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1045\n",
      "\n",
      "Iteration 1046 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.077 MB, Params: 921,090 (3.514 MB), Total: 3.59 MB, FLOPs: 67,883,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1046/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1046\n",
      "\n",
      "Iteration 1047 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.077 MB, Params: 919,342 (3.507 MB), Total: 3.58 MB, FLOPs: 67,799,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1047/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1047\n",
      "\n",
      "Iteration 1048 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 113)]\n",
      "Input: 0.077 MB, Params: 917,594 (3.500 MB), Total: 3.58 MB, FLOPs: 67,715,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1048/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1048\n",
      "\n",
      "Iteration 1049 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.077 MB, Params: 914,226 (3.487 MB), Total: 3.56 MB, FLOPs: 67,675,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1049/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1049\n",
      "\n",
      "Iteration 1050 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.077 MB, Params: 910,858 (3.475 MB), Total: 3.55 MB, FLOPs: 67,634,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1050/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1050\n",
      "\n",
      "Iteration 1051 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 21)]\n",
      "Input: 0.077 MB, Params: 910,496 (3.473 MB), Total: 3.55 MB, FLOPs: 67,258,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1051/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1051\n",
      "\n",
      "Iteration 1052 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.077 MB, Params: 907,128 (3.460 MB), Total: 3.54 MB, FLOPs: 67,217,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1052/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1052\n",
      "\n",
      "Iteration 1053 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.077 MB, Params: 905,380 (3.454 MB), Total: 3.53 MB, FLOPs: 67,134,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1053/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1053\n",
      "\n",
      "Iteration 1054 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 2)]\n",
      "Input: 0.077 MB, Params: 903,632 (3.447 MB), Total: 3.52 MB, FLOPs: 67,050,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1054/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1054\n",
      "\n",
      "Iteration 1055 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.077 MB, Params: 902,051 (3.441 MB), Total: 3.52 MB, FLOPs: 67,031,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1055/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1055\n",
      "\n",
      "Iteration 1056 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.077 MB, Params: 899,412 (3.431 MB), Total: 3.51 MB, FLOPs: 66,961,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 1056/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1056\n",
      "\n",
      "Iteration 1057 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 33)]\n",
      "Input: 0.077 MB, Params: 896,062 (3.418 MB), Total: 3.50 MB, FLOPs: 66,921,159\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1057/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1057\n",
      "\n",
      "Iteration 1058 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 223)]\n",
      "Input: 0.077 MB, Params: 894,490 (3.412 MB), Total: 3.49 MB, FLOPs: 66,902,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1058/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1058\n",
      "\n",
      "Iteration 1059 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.077 MB, Params: 892,918 (3.406 MB), Total: 3.48 MB, FLOPs: 66,883,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1059/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1059\n",
      "\n",
      "Iteration 1060 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.077 MB, Params: 891,809 (3.402 MB), Total: 3.48 MB, FLOPs: 66,634,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1060/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1060\n",
      "\n",
      "Iteration 1061 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 72)]\n",
      "Input: 0.077 MB, Params: 890,106 (3.395 MB), Total: 3.47 MB, FLOPs: 66,439,035\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1061/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1061\n",
      "\n",
      "Iteration 1062 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.077 MB, Params: 888,534 (3.389 MB), Total: 3.47 MB, FLOPs: 66,420,207\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1062/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1062\n",
      "\n",
      "Iteration 1063 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 2)]\n",
      "Input: 0.077 MB, Params: 887,542 (3.386 MB), Total: 3.46 MB, FLOPs: 65,941,132\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1063/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1063\n",
      "\n",
      "Iteration 1064 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.077 MB, Params: 885,812 (3.379 MB), Total: 3.46 MB, FLOPs: 65,858,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1064/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1064\n",
      "\n",
      "Iteration 1065 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.077 MB, Params: 884,082 (3.373 MB), Total: 3.45 MB, FLOPs: 65,775,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1065/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1065\n",
      "\n",
      "Iteration 1066 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.077 MB, Params: 880,759 (3.360 MB), Total: 3.44 MB, FLOPs: 65,735,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1066/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1066\n",
      "\n",
      "Iteration 1067 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 234)]\n",
      "Input: 0.077 MB, Params: 879,196 (3.354 MB), Total: 3.43 MB, FLOPs: 65,716,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1067/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1067\n",
      "\n",
      "Iteration 1068 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.077 MB, Params: 876,593 (3.344 MB), Total: 3.42 MB, FLOPs: 65,647,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1068/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1068\n",
      "\n",
      "Iteration 1069 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.077 MB, Params: 874,872 (3.337 MB), Total: 3.41 MB, FLOPs: 65,565,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1069/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1069\n",
      "\n",
      "Iteration 1070 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 872,278 (3.327 MB), Total: 3.40 MB, FLOPs: 65,496,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1070/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1070\n",
      "\n",
      "Iteration 1071 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.077 MB, Params: 868,982 (3.315 MB), Total: 3.39 MB, FLOPs: 65,457,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1071/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1071\n",
      "\n",
      "Iteration 1072 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 865,686 (3.302 MB), Total: 3.38 MB, FLOPs: 65,417,572\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1072/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1072\n",
      "\n",
      "Iteration 1073 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.077 MB, Params: 862,390 (3.290 MB), Total: 3.37 MB, FLOPs: 65,378,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1073/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1073\n",
      "\n",
      "Iteration 1074 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 35)]\n",
      "Input: 0.077 MB, Params: 862,353 (3.290 MB), Total: 3.37 MB, FLOPs: 65,168,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 1074/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1074\n",
      "\n",
      "Iteration 1075 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.077 MB, Params: 861,361 (3.286 MB), Total: 3.36 MB, FLOPs: 64,689,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 1075/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1075\n",
      "\n",
      "Iteration 1076 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.077 MB, Params: 859,649 (3.279 MB), Total: 3.36 MB, FLOPs: 64,607,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1076/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1076\n",
      "\n",
      "Iteration 1077 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.077 MB, Params: 856,353 (3.267 MB), Total: 3.34 MB, FLOPs: 64,568,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1077/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1077\n",
      "\n",
      "Iteration 1078 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 110)]\n",
      "Input: 0.077 MB, Params: 854,641 (3.260 MB), Total: 3.34 MB, FLOPs: 64,485,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1078/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1078\n",
      "\n",
      "Iteration 1079 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.077 MB, Params: 853,114 (3.254 MB), Total: 3.33 MB, FLOPs: 64,467,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1079/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1079\n",
      "\n",
      "Iteration 1080 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.077 MB, Params: 850,574 (3.245 MB), Total: 3.32 MB, FLOPs: 64,400,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1080/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1080\n",
      "\n",
      "Iteration 1081 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 68)]\n",
      "Input: 0.077 MB, Params: 848,871 (3.238 MB), Total: 3.32 MB, FLOPs: 64,318,789\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1081/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1081\n",
      "\n",
      "Iteration 1082 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 846,340 (3.229 MB), Total: 3.31 MB, FLOPs: 64,252,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1082/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1082\n",
      "\n",
      "Iteration 1083 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.077 MB, Params: 843,071 (3.216 MB), Total: 3.29 MB, FLOPs: 64,212,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 1083/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1083\n",
      "\n",
      "Iteration 1084 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.077 MB, Params: 839,802 (3.204 MB), Total: 3.28 MB, FLOPs: 64,173,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1084/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1084\n",
      "\n",
      "Iteration 1085 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.077 MB, Params: 838,108 (3.197 MB), Total: 3.27 MB, FLOPs: 64,092,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1085/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1085\n",
      "\n",
      "Iteration 1086 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.077 MB, Params: 836,414 (3.191 MB), Total: 3.27 MB, FLOPs: 64,011,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1086/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1086\n",
      "\n",
      "Iteration 1087 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 65)]\n",
      "Input: 0.077 MB, Params: 833,919 (3.181 MB), Total: 3.26 MB, FLOPs: 63,945,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 1087/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1087\n",
      "\n",
      "Iteration 1088 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.077 MB, Params: 832,410 (3.175 MB), Total: 3.25 MB, FLOPs: 63,927,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1088/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1088\n",
      "\n",
      "Iteration 1089 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 9)]\n",
      "Input: 0.077 MB, Params: 832,373 (3.175 MB), Total: 3.25 MB, FLOPs: 62,533,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1089/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1089\n",
      "\n",
      "Iteration 1090 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.077 MB, Params: 831,381 (3.171 MB), Total: 3.25 MB, FLOPs: 62,072,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1090/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1090\n",
      "\n",
      "Iteration 1091 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 154)]\n",
      "Input: 0.077 MB, Params: 828,130 (3.159 MB), Total: 3.24 MB, FLOPs: 62,033,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1091/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1091\n",
      "\n",
      "Iteration 1092 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.077 MB, Params: 827,138 (3.155 MB), Total: 3.23 MB, FLOPs: 61,571,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1092/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1092\n",
      "\n",
      "Iteration 1093 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.077 MB, Params: 826,776 (3.154 MB), Total: 3.23 MB, FLOPs: 61,215,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1093/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1093\n",
      "\n",
      "Iteration 1094 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.077 MB, Params: 825,091 (3.147 MB), Total: 3.22 MB, FLOPs: 61,134,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1094/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1094\n",
      "\n",
      "Iteration 1095 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.077 MB, Params: 823,591 (3.142 MB), Total: 3.22 MB, FLOPs: 61,116,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1095/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1095\n",
      "\n",
      "Iteration 1096 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 3)]\n",
      "Input: 0.077 MB, Params: 823,554 (3.142 MB), Total: 3.22 MB, FLOPs: 60,908,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1096/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1096\n",
      "\n",
      "Iteration 1097 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.077 MB, Params: 822,054 (3.136 MB), Total: 3.21 MB, FLOPs: 60,890,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1097/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1097\n",
      "\n",
      "Iteration 1098 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 819,577 (3.126 MB), Total: 3.20 MB, FLOPs: 60,825,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1098/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1098\n",
      "\n",
      "Iteration 1099 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.077 MB, Params: 818,513 (3.122 MB), Total: 3.20 MB, FLOPs: 60,585,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1099/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1099\n",
      "\n",
      "Iteration 1100 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 816,036 (3.113 MB), Total: 3.19 MB, FLOPs: 60,520,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1100/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1100\n",
      "\n",
      "Iteration 1101 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.077 MB, Params: 814,536 (3.107 MB), Total: 3.18 MB, FLOPs: 60,502,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1101/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1101\n",
      "\n",
      "Iteration 1102 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 10)]\n",
      "Input: 0.077 MB, Params: 813,472 (3.103 MB), Total: 3.18 MB, FLOPs: 60,263,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1102/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1102\n",
      "\n",
      "Iteration 1103 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.077 MB, Params: 812,408 (3.099 MB), Total: 3.18 MB, FLOPs: 60,024,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1103/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1103\n",
      "\n",
      "Iteration 1104 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.077 MB, Params: 809,202 (3.087 MB), Total: 3.16 MB, FLOPs: 59,985,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1104/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1104\n",
      "\n",
      "Iteration 1105 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 51)]\n",
      "Input: 0.077 MB, Params: 807,711 (3.081 MB), Total: 3.16 MB, FLOPs: 59,968,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1105/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1105\n",
      "\n",
      "Iteration 1106 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.077 MB, Params: 806,044 (3.075 MB), Total: 3.15 MB, FLOPs: 59,888,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1106/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1106\n",
      "\n",
      "Iteration 1107 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.077 MB, Params: 802,847 (3.063 MB), Total: 3.14 MB, FLOPs: 59,849,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1107/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1107\n",
      "\n",
      "Iteration 1108 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.077 MB, Params: 801,180 (3.056 MB), Total: 3.13 MB, FLOPs: 59,769,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1108/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1108\n",
      "\n",
      "Iteration 1109 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 799,698 (3.051 MB), Total: 3.13 MB, FLOPs: 59,752,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1109/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1109\n",
      "\n",
      "Iteration 1110 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.077 MB, Params: 796,510 (3.038 MB), Total: 3.12 MB, FLOPs: 59,713,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1110/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1110\n",
      "\n",
      "Iteration 1111 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.077 MB, Params: 795,037 (3.033 MB), Total: 3.11 MB, FLOPs: 59,696,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1111/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1111\n",
      "\n",
      "Iteration 1112 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.077 MB, Params: 792,605 (3.024 MB), Total: 3.10 MB, FLOPs: 59,632,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1112/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1112\n",
      "\n",
      "Iteration 1113 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.077 MB, Params: 791,132 (3.018 MB), Total: 3.09 MB, FLOPs: 59,614,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1113/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1113\n",
      "\n",
      "Iteration 1114 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 228)]\n",
      "Input: 0.077 MB, Params: 789,659 (3.012 MB), Total: 3.09 MB, FLOPs: 59,596,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1114/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1114\n",
      "\n",
      "Iteration 1115 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 27)]\n",
      "Input: 0.077 MB, Params: 789,622 (3.012 MB), Total: 3.09 MB, FLOPs: 56,443,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1115/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1115\n",
      "\n",
      "Iteration 1116 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.077 MB, Params: 788,149 (3.007 MB), Total: 3.08 MB, FLOPs: 56,426,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1116/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1116\n",
      "\n",
      "Iteration 1117 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 3)]\n",
      "Input: 0.077 MB, Params: 787,184 (3.003 MB), Total: 3.08 MB, FLOPs: 56,003,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1117/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1117\n",
      "\n",
      "Iteration 1118 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.077 MB, Params: 785,711 (2.997 MB), Total: 3.07 MB, FLOPs: 55,986,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1118/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1118\n",
      "\n",
      "Iteration 1119 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.077 MB, Params: 784,238 (2.992 MB), Total: 3.07 MB, FLOPs: 55,968,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1119/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1119\n",
      "\n",
      "Iteration 1120 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.077 MB, Params: 784,201 (2.991 MB), Total: 3.07 MB, FLOPs: 55,760,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1120/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1120\n",
      "\n",
      "Iteration 1121 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.077 MB, Params: 782,543 (2.985 MB), Total: 3.06 MB, FLOPs: 55,680,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1121/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1121\n",
      "\n",
      "Iteration 1122 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.077 MB, Params: 781,070 (2.980 MB), Total: 3.06 MB, FLOPs: 55,663,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1122/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1122\n",
      "\n",
      "Iteration 1123 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.077 MB, Params: 779,502 (2.974 MB), Total: 3.05 MB, FLOPs: 55,494,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1123/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1123\n",
      "\n",
      "Iteration 1124 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.077 MB, Params: 776,386 (2.962 MB), Total: 3.04 MB, FLOPs: 55,457,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1124/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1124\n",
      "\n",
      "Iteration 1125 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.077 MB, Params: 774,922 (2.956 MB), Total: 3.03 MB, FLOPs: 55,439,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1125/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1125\n",
      "\n",
      "Iteration 1126 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.077 MB, Params: 772,508 (2.947 MB), Total: 3.02 MB, FLOPs: 55,376,288\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1126/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1126\n",
      "\n",
      "Iteration 1127 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.077 MB, Params: 769,410 (2.935 MB), Total: 3.01 MB, FLOPs: 55,339,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1127/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1127\n",
      "\n",
      "Iteration 1128 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 766,312 (2.923 MB), Total: 3.00 MB, FLOPs: 55,301,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1128/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1128\n",
      "\n",
      "Iteration 1129 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.077 MB, Params: 764,866 (2.918 MB), Total: 2.99 MB, FLOPs: 55,284,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1129/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1129\n",
      "\n",
      "Iteration 1130 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.077 MB, Params: 763,420 (2.912 MB), Total: 2.99 MB, FLOPs: 55,267,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1130/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1130\n",
      "\n",
      "Iteration 1131 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.077 MB, Params: 760,340 (2.900 MB), Total: 2.98 MB, FLOPs: 55,230,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 1131/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1131\n",
      "\n",
      "Iteration 1132 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 22)]\n",
      "Input: 0.077 MB, Params: 759,294 (2.896 MB), Total: 2.97 MB, FLOPs: 55,021,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1132/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1132\n",
      "\n",
      "Iteration 1133 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 5)]\n",
      "Input: 0.077 MB, Params: 758,338 (2.893 MB), Total: 2.97 MB, FLOPs: 54,600,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1133/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1133\n",
      "\n",
      "Iteration 1134 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 10)]\n",
      "Input: 0.077 MB, Params: 758,301 (2.893 MB), Total: 2.97 MB, FLOPs: 53,296,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1134/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1134\n",
      "\n",
      "Iteration 1135 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 21)]\n",
      "Input: 0.077 MB, Params: 756,742 (2.887 MB), Total: 2.96 MB, FLOPs: 53,129,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1135/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1135\n",
      "\n",
      "Iteration 1136 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.077 MB, Params: 755,305 (2.881 MB), Total: 2.96 MB, FLOPs: 53,112,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1136/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1136\n",
      "\n",
      "Iteration 1137 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.077 MB, Params: 753,674 (2.875 MB), Total: 2.95 MB, FLOPs: 53,033,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1137/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1137\n",
      "\n",
      "Iteration 1138 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 750,603 (2.863 MB), Total: 2.94 MB, FLOPs: 52,997,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1138/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1138\n",
      "\n",
      "Iteration 1139 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.077 MB, Params: 748,972 (2.857 MB), Total: 2.93 MB, FLOPs: 52,918,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1139/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1139\n",
      "\n",
      "Iteration 1140 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.077 MB, Params: 745,901 (2.845 MB), Total: 2.92 MB, FLOPs: 52,881,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1140/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1140\n",
      "\n",
      "Iteration 1141 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.077 MB, Params: 744,270 (2.839 MB), Total: 2.92 MB, FLOPs: 52,803,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1141/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1141\n",
      "\n",
      "Iteration 1142 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.077 MB, Params: 741,928 (2.830 MB), Total: 2.91 MB, FLOPs: 52,742,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1142/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1142\n",
      "\n",
      "Iteration 1143 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.077 MB, Params: 740,396 (2.824 MB), Total: 2.90 MB, FLOPs: 52,576,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1143/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1143\n",
      "\n",
      "Iteration 1144 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 15)]\n",
      "Input: 0.077 MB, Params: 739,440 (2.821 MB), Total: 2.90 MB, FLOPs: 52,173,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1144/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1144\n",
      "\n",
      "Iteration 1145 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.077 MB, Params: 738,021 (2.815 MB), Total: 2.89 MB, FLOPs: 52,156,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1145/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1145\n",
      "\n",
      "Iteration 1146 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.077 MB, Params: 734,968 (2.804 MB), Total: 2.88 MB, FLOPs: 52,120,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1146/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1146\n",
      "\n",
      "Iteration 1147 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 733,958 (2.800 MB), Total: 2.88 MB, FLOPs: 51,918,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1147/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1147\n",
      "\n",
      "Iteration 1148 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.077 MB, Params: 731,625 (2.791 MB), Total: 2.87 MB, FLOPs: 51,856,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1148/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1148\n",
      "\n",
      "Iteration 1149 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 18)]\n",
      "Input: 0.077 MB, Params: 731,074 (2.789 MB), Total: 2.87 MB, FLOPs: 51,416,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1149/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1149\n",
      "\n",
      "Iteration 1150 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.077 MB, Params: 729,470 (2.783 MB), Total: 2.86 MB, FLOPs: 51,339,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1150/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1150\n",
      "\n",
      "Iteration 1151 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.077 MB, Params: 727,956 (2.777 MB), Total: 2.85 MB, FLOPs: 51,176,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1151/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1151\n",
      "\n",
      "Iteration 1152 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.077 MB, Params: 726,546 (2.772 MB), Total: 2.85 MB, FLOPs: 51,159,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1152/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1152\n",
      "\n",
      "Iteration 1153 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.077 MB, Params: 723,511 (2.760 MB), Total: 2.84 MB, FLOPs: 51,123,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1153/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1153\n",
      "\n",
      "Iteration 1154 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 0)]\n",
      "Input: 0.077 MB, Params: 723,158 (2.759 MB), Total: 2.84 MB, FLOPs: 50,813,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1154/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1154\n",
      "\n",
      "Iteration 1155 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.077 MB, Params: 720,123 (2.747 MB), Total: 2.82 MB, FLOPs: 50,777,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1155/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1155\n",
      "\n",
      "Iteration 1156 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.077 MB, Params: 717,817 (2.738 MB), Total: 2.82 MB, FLOPs: 50,716,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1156/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1156\n",
      "\n",
      "Iteration 1157 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 205)]\n",
      "Input: 0.077 MB, Params: 716,425 (2.733 MB), Total: 2.81 MB, FLOPs: 50,699,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1157/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1157\n",
      "\n",
      "Iteration 1158 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 118)]\n",
      "Input: 0.077 MB, Params: 713,408 (2.721 MB), Total: 2.80 MB, FLOPs: 50,663,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1158/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1158\n",
      "\n",
      "Iteration 1159 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.077 MB, Params: 710,391 (2.710 MB), Total: 2.79 MB, FLOPs: 50,627,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1159/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1159\n",
      "\n",
      "Iteration 1160 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 17)]\n",
      "Input: 0.077 MB, Params: 709,453 (2.706 MB), Total: 2.78 MB, FLOPs: 50,233,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1160/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1160\n",
      "\n",
      "Iteration 1161 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 66)]\n",
      "Input: 0.077 MB, Params: 707,939 (2.701 MB), Total: 2.78 MB, FLOPs: 50,070,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1161/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1161\n",
      "\n",
      "Iteration 1162 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 705,651 (2.692 MB), Total: 2.77 MB, FLOPs: 50,009,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1162/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1162\n",
      "\n",
      "Iteration 1163 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 703,363 (2.683 MB), Total: 2.76 MB, FLOPs: 49,948,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1163/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1163\n",
      "\n",
      "Iteration 1164 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.077 MB, Params: 701,989 (2.678 MB), Total: 2.75 MB, FLOPs: 49,932,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1164/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1164\n",
      "\n",
      "Iteration 1165 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.077 MB, Params: 699,701 (2.669 MB), Total: 2.75 MB, FLOPs: 49,871,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1165/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1165\n",
      "\n",
      "Iteration 1166 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 185)]\n",
      "Input: 0.077 MB, Params: 698,327 (2.664 MB), Total: 2.74 MB, FLOPs: 49,855,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1166/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1166\n",
      "\n",
      "Iteration 1167 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 107)]\n",
      "Input: 0.077 MB, Params: 695,355 (2.653 MB), Total: 2.73 MB, FLOPs: 49,819,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1167/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1167\n",
      "\n",
      "Iteration 1168 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.077 MB, Params: 693,990 (2.647 MB), Total: 2.72 MB, FLOPs: 49,803,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1168/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1168\n",
      "\n",
      "Iteration 1169 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.077 MB, Params: 691,027 (2.636 MB), Total: 2.71 MB, FLOPs: 49,767,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1169/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1169\n",
      "\n",
      "Iteration 1170 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 19)]\n",
      "Input: 0.077 MB, Params: 690,044 (2.632 MB), Total: 2.71 MB, FLOPs: 49,571,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1170/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1170\n",
      "\n",
      "Iteration 1171 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.077 MB, Params: 687,081 (2.621 MB), Total: 2.70 MB, FLOPs: 49,535,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1171/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1171\n",
      "\n",
      "Iteration 1172 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 172)]\n",
      "Input: 0.077 MB, Params: 685,734 (2.616 MB), Total: 2.69 MB, FLOPs: 49,519,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1172/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1172\n",
      "\n",
      "Iteration 1173 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.077 MB, Params: 684,387 (2.611 MB), Total: 2.69 MB, FLOPs: 49,503,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1173/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1173\n",
      "\n",
      "Iteration 1174 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 46)]\n",
      "Input: 0.077 MB, Params: 682,882 (2.605 MB), Total: 2.68 MB, FLOPs: 49,342,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1174/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1174\n",
      "\n",
      "Iteration 1175 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 62)]\n",
      "Input: 0.077 MB, Params: 681,908 (2.601 MB), Total: 2.68 MB, FLOPs: 49,147,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1175/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1175\n",
      "\n",
      "Iteration 1176 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.077 MB, Params: 680,561 (2.596 MB), Total: 2.67 MB, FLOPs: 49,131,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1176/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1176\n",
      "\n",
      "Iteration 1177 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.077 MB, Params: 679,020 (2.590 MB), Total: 2.67 MB, FLOPs: 49,057,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1177/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1177\n",
      "\n",
      "Iteration 1178 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 676,084 (2.579 MB), Total: 2.66 MB, FLOPs: 49,022,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1178/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1178\n",
      "\n",
      "Iteration 1179 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 172)]\n",
      "Input: 0.077 MB, Params: 674,746 (2.574 MB), Total: 2.65 MB, FLOPs: 49,006,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1179/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1179\n",
      "\n",
      "Iteration 1180 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.077 MB, Params: 672,503 (2.565 MB), Total: 2.64 MB, FLOPs: 48,946,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1180/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1180\n",
      "\n",
      "Iteration 1181 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.077 MB, Params: 670,971 (2.560 MB), Total: 2.64 MB, FLOPs: 48,873,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1181/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1181\n",
      "\n",
      "Iteration 1182 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 668,053 (2.548 MB), Total: 2.63 MB, FLOPs: 48,838,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1182/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1182\n",
      "\n",
      "Iteration 1183 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.077 MB, Params: 665,135 (2.537 MB), Total: 2.61 MB, FLOPs: 48,803,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1183/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1183\n",
      "\n",
      "Iteration 1184 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.077 MB, Params: 663,603 (2.531 MB), Total: 2.61 MB, FLOPs: 48,729,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1184/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1184\n",
      "\n",
      "Iteration 1185 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 36)]\n",
      "Input: 0.077 MB, Params: 662,683 (2.528 MB), Total: 2.60 MB, FLOPs: 48,339,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1185/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1185\n",
      "\n",
      "Iteration 1186 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 660,476 (2.520 MB), Total: 2.60 MB, FLOPs: 48,280,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1186/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1186\n",
      "\n",
      "Iteration 1187 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.077 MB, Params: 657,567 (2.508 MB), Total: 2.59 MB, FLOPs: 48,245,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1187/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1187\n",
      "\n",
      "Iteration 1188 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 654,658 (2.497 MB), Total: 2.57 MB, FLOPs: 48,210,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1188/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1188\n",
      "\n",
      "Iteration 1189 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 653,693 (2.494 MB), Total: 2.57 MB, FLOPs: 48,017,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1189/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1189\n",
      "\n",
      "Iteration 1190 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.077 MB, Params: 650,784 (2.483 MB), Total: 2.56 MB, FLOPs: 47,983,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1190/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1190\n",
      "\n",
      "Iteration 1191 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 27)]\n",
      "Input: 0.077 MB, Params: 649,873 (2.479 MB), Total: 2.56 MB, FLOPs: 47,594,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1191/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1191\n",
      "\n",
      "Iteration 1192 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.077 MB, Params: 647,693 (2.471 MB), Total: 2.55 MB, FLOPs: 47,536,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1192/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1192\n",
      "\n",
      "Iteration 1193 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 9)]\n",
      "Input: 0.077 MB, Params: 646,233 (2.465 MB), Total: 2.54 MB, FLOPs: 47,379,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1193/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1193\n",
      "\n",
      "Iteration 1194 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.077 MB, Params: 644,940 (2.460 MB), Total: 2.54 MB, FLOPs: 47,364,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1194/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1194\n",
      "\n",
      "Iteration 1195 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.077 MB, Params: 643,647 (2.455 MB), Total: 2.53 MB, FLOPs: 47,348,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1195/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1195\n",
      "\n",
      "Iteration 1196 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.077 MB, Params: 640,765 (2.444 MB), Total: 2.52 MB, FLOPs: 47,314,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1196/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1196\n",
      "\n",
      "Iteration 1197 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.077 MB, Params: 639,481 (2.439 MB), Total: 2.52 MB, FLOPs: 47,298,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1197/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1197\n",
      "\n",
      "Iteration 1198 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.077 MB, Params: 636,608 (2.428 MB), Total: 2.51 MB, FLOPs: 47,264,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1198/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1198\n",
      "\n",
      "Iteration 1199 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.077 MB, Params: 635,661 (2.425 MB), Total: 2.50 MB, FLOPs: 47,075,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1199/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1199\n",
      "\n",
      "Iteration 1200 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.077 MB, Params: 634,714 (2.421 MB), Total: 2.50 MB, FLOPs: 46,885,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1200/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1200\n",
      "\n",
      "Iteration 1201 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.077 MB, Params: 633,209 (2.416 MB), Total: 2.49 MB, FLOPs: 46,813,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1201/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1201\n",
      "\n",
      "Iteration 1202 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.077 MB, Params: 630,336 (2.405 MB), Total: 2.48 MB, FLOPs: 46,779,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1202/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1202\n",
      "\n",
      "Iteration 1203 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 628,192 (2.396 MB), Total: 2.47 MB, FLOPs: 46,721,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1203/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1203\n",
      "\n",
      "Iteration 1204 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.077 MB, Params: 626,696 (2.391 MB), Total: 2.47 MB, FLOPs: 46,649,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1204/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1204\n",
      "\n",
      "Iteration 1205 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.077 MB, Params: 624,561 (2.383 MB), Total: 2.46 MB, FLOPs: 46,592,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1205/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1205\n",
      "\n",
      "Iteration 1206 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 2)]\n",
      "Input: 0.077 MB, Params: 623,668 (2.379 MB), Total: 2.46 MB, FLOPs: 46,207,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1206/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1206\n",
      "\n",
      "Iteration 1207 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 622,402 (2.374 MB), Total: 2.45 MB, FLOPs: 46,192,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1207/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1207\n",
      "\n",
      "Iteration 1208 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 61)]\n",
      "Input: 0.077 MB, Params: 620,267 (2.366 MB), Total: 2.44 MB, FLOPs: 46,135,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1208/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1208\n",
      "\n",
      "Iteration 1209 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 618,789 (2.360 MB), Total: 2.44 MB, FLOPs: 46,064,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1209/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1209\n",
      "\n",
      "Iteration 1210 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.077 MB, Params: 617,523 (2.356 MB), Total: 2.43 MB, FLOPs: 46,049,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1210/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1210\n",
      "\n",
      "Iteration 1211 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.077 MB, Params: 614,695 (2.345 MB), Total: 2.42 MB, FLOPs: 46,015,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1211/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1211\n",
      "\n",
      "Iteration 1212 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.077 MB, Params: 611,867 (2.334 MB), Total: 2.41 MB, FLOPs: 45,981,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1212/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1212\n",
      "\n",
      "Iteration 1213 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.077 MB, Params: 610,619 (2.329 MB), Total: 2.41 MB, FLOPs: 45,966,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1213/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1213\n",
      "\n",
      "Iteration 1214 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.077 MB, Params: 607,800 (2.319 MB), Total: 2.40 MB, FLOPs: 45,932,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1214/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1214\n",
      "\n",
      "Iteration 1215 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.077 MB, Params: 606,561 (2.314 MB), Total: 2.39 MB, FLOPs: 45,918,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1215/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1215\n",
      "\n",
      "Iteration 1216 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.077 MB, Params: 603,751 (2.303 MB), Total: 2.38 MB, FLOPs: 45,884,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1216/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1216\n",
      "\n",
      "Iteration 1217 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.077 MB, Params: 602,521 (2.298 MB), Total: 2.38 MB, FLOPs: 45,869,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1217/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1217\n",
      "\n",
      "Iteration 1218 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.077 MB, Params: 601,106 (2.293 MB), Total: 2.37 MB, FLOPs: 45,717,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1218/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1218\n",
      "\n",
      "Iteration 1219 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 55)]\n",
      "Input: 0.077 MB, Params: 599,691 (2.288 MB), Total: 2.36 MB, FLOPs: 45,566,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1219/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1219\n",
      "\n",
      "Iteration 1220 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 596,890 (2.277 MB), Total: 2.35 MB, FLOPs: 45,532,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1220/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1220\n",
      "\n",
      "Iteration 1221 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.077 MB, Params: 595,669 (2.272 MB), Total: 2.35 MB, FLOPs: 45,518,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1221/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1221\n",
      "\n",
      "Iteration 1222 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.077 MB, Params: 592,877 (2.262 MB), Total: 2.34 MB, FLOPs: 45,484,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1222/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1222\n",
      "\n",
      "Iteration 1223 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.077 MB, Params: 591,417 (2.256 MB), Total: 2.33 MB, FLOPs: 45,414,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1223/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1223\n",
      "\n",
      "Iteration 1224 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.077 MB, Params: 590,524 (2.253 MB), Total: 2.33 MB, FLOPs: 45,029,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1224/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1224\n",
      "\n",
      "Iteration 1225 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.077 MB, Params: 589,312 (2.248 MB), Total: 2.32 MB, FLOPs: 45,014,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1225/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1225\n",
      "\n",
      "Iteration 1226 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 587,906 (2.243 MB), Total: 2.32 MB, FLOPs: 44,863,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1226/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1226\n",
      "\n",
      "Iteration 1227 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.077 MB, Params: 586,455 (2.237 MB), Total: 2.31 MB, FLOPs: 44,794,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1227/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1227\n",
      "\n",
      "Iteration 1228 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.077 MB, Params: 585,243 (2.233 MB), Total: 2.31 MB, FLOPs: 44,779,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1228/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1228\n",
      "\n",
      "Iteration 1229 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.077 MB, Params: 583,792 (2.227 MB), Total: 2.30 MB, FLOPs: 44,710,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1229/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1229\n",
      "\n",
      "Iteration 1230 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.077 MB, Params: 582,580 (2.222 MB), Total: 2.30 MB, FLOPs: 44,695,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1230/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1230\n",
      "\n",
      "Iteration 1231 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 15)]\n",
      "Input: 0.077 MB, Params: 581,192 (2.217 MB), Total: 2.29 MB, FLOPs: 44,545,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1231/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1231\n",
      "\n",
      "Iteration 1232 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.077 MB, Params: 578,427 (2.207 MB), Total: 2.28 MB, FLOPs: 44,512,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1232/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1232\n",
      "\n",
      "Iteration 1233 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.077 MB, Params: 577,224 (2.202 MB), Total: 2.28 MB, FLOPs: 44,497,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1233/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1233\n",
      "\n",
      "Iteration 1234 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 40)]\n",
      "Input: 0.077 MB, Params: 575,188 (2.194 MB), Total: 2.27 MB, FLOPs: 44,442,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1234/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1234\n",
      "\n",
      "Iteration 1235 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.077 MB, Params: 573,152 (2.186 MB), Total: 2.26 MB, FLOPs: 44,388,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1235/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1235\n",
      "\n",
      "Iteration 1236 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 107)]\n",
      "Input: 0.077 MB, Params: 570,414 (2.176 MB), Total: 2.25 MB, FLOPs: 44,355,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1236/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1236\n",
      "\n",
      "Iteration 1237 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.077 MB, Params: 568,387 (2.168 MB), Total: 2.25 MB, FLOPs: 44,300,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1237/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1237\n",
      "\n",
      "Iteration 1238 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.077 MB, Params: 567,193 (2.164 MB), Total: 2.24 MB, FLOPs: 44,286,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1238/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1238\n",
      "\n",
      "Iteration 1239 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 33)]\n",
      "Input: 0.077 MB, Params: 566,696 (2.162 MB), Total: 2.24 MB, FLOPs: 43,889,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1239/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1239\n",
      "\n",
      "Iteration 1240 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.077 MB, Params: 565,803 (2.158 MB), Total: 2.24 MB, FLOPs: 43,711,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1240/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1240\n",
      "\n",
      "Iteration 1241 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.077 MB, Params: 564,910 (2.155 MB), Total: 2.23 MB, FLOPs: 43,533,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1241/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1241\n",
      "\n",
      "Iteration 1242 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 562,190 (2.145 MB), Total: 2.22 MB, FLOPs: 43,500,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1242/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1242\n",
      "\n",
      "Iteration 1243 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.077 MB, Params: 559,470 (2.134 MB), Total: 2.21 MB, FLOPs: 43,467,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1243/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1243\n",
      "\n",
      "Iteration 1244 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 62)]\n",
      "Input: 0.077 MB, Params: 558,100 (2.129 MB), Total: 2.21 MB, FLOPs: 43,321,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1244/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1244\n",
      "\n",
      "Iteration 1245 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 555,380 (2.119 MB), Total: 2.20 MB, FLOPs: 43,288,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1245/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1245\n",
      "\n",
      "Iteration 1246 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 99)]\n",
      "Input: 0.077 MB, Params: 552,660 (2.108 MB), Total: 2.19 MB, FLOPs: 43,255,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1246/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1246\n",
      "\n",
      "Iteration 1247 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.077 MB, Params: 551,776 (2.105 MB), Total: 2.18 MB, FLOPs: 43,079,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1247/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1247\n",
      "\n",
      "Iteration 1248 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.077 MB, Params: 550,618 (2.100 MB), Total: 2.18 MB, FLOPs: 43,065,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1248/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1248\n",
      "\n",
      "Iteration 1249 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.077 MB, Params: 547,907 (2.090 MB), Total: 2.17 MB, FLOPs: 43,032,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1249/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1249\n",
      "\n",
      "Iteration 1250 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.077 MB, Params: 546,758 (2.086 MB), Total: 2.16 MB, FLOPs: 43,019,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1250/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1250\n",
      "\n",
      "Iteration 1251 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.077 MB, Params: 546,261 (2.084 MB), Total: 2.16 MB, FLOPs: 42,622,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1251/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1251\n",
      "\n",
      "Iteration 1252 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.077 MB, Params: 544,855 (2.078 MB), Total: 2.16 MB, FLOPs: 42,554,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1252/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1252\n",
      "\n",
      "Iteration 1253 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 70)]\n",
      "Input: 0.077 MB, Params: 543,449 (2.073 MB), Total: 2.15 MB, FLOPs: 42,487,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1253/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1253\n",
      "\n",
      "Iteration 1254 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 22)]\n",
      "Input: 0.077 MB, Params: 542,601 (2.070 MB), Total: 2.15 MB, FLOPs: 42,122,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1254/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1254\n",
      "\n",
      "Iteration 1255 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.077 MB, Params: 541,726 (2.067 MB), Total: 2.14 MB, FLOPs: 41,947,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1255/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1255\n",
      "\n",
      "Iteration 1256 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.077 MB, Params: 540,392 (2.061 MB), Total: 2.14 MB, FLOPs: 41,805,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1256/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1256\n",
      "\n",
      "Iteration 1257 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 32)]\n",
      "Input: 0.077 MB, Params: 540,355 (2.061 MB), Total: 2.14 MB, FLOPs: 41,597,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1257/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1257\n",
      "\n",
      "Iteration 1258 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.077 MB, Params: 539,206 (2.057 MB), Total: 2.13 MB, FLOPs: 41,584,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1258/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1258\n",
      "\n",
      "Iteration 1259 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.077 MB, Params: 538,057 (2.053 MB), Total: 2.13 MB, FLOPs: 41,570,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1259/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1259\n",
      "\n",
      "Iteration 1260 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.077 MB, Params: 537,191 (2.049 MB), Total: 2.13 MB, FLOPs: 41,397,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1260/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1260\n",
      "\n",
      "Iteration 1261 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 31)]\n",
      "Input: 0.077 MB, Params: 535,866 (2.044 MB), Total: 2.12 MB, FLOPs: 41,256,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1261/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1261\n",
      "\n",
      "Iteration 1262 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.077 MB, Params: 533,182 (2.034 MB), Total: 2.11 MB, FLOPs: 41,224,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1262/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1262\n",
      "\n",
      "Iteration 1263 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.077 MB, Params: 530,498 (2.024 MB), Total: 2.10 MB, FLOPs: 41,192,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1263/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1263\n",
      "\n",
      "Iteration 1264 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.077 MB, Params: 529,110 (2.018 MB), Total: 2.10 MB, FLOPs: 41,125,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1264/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1264\n",
      "\n",
      "Iteration 1265 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 97)]\n",
      "Input: 0.077 MB, Params: 526,426 (2.008 MB), Total: 2.09 MB, FLOPs: 41,093,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1265/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1265\n",
      "\n",
      "Iteration 1266 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.077 MB, Params: 525,938 (2.006 MB), Total: 2.08 MB, FLOPs: 40,704,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1266/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1266\n",
      "\n",
      "Iteration 1267 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.077 MB, Params: 523,254 (1.996 MB), Total: 2.07 MB, FLOPs: 40,671,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1267/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1267\n",
      "\n",
      "Iteration 1268 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.077 MB, Params: 521,335 (1.989 MB), Total: 2.07 MB, FLOPs: 40,619,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1268/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1268\n",
      "\n",
      "Iteration 1269 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.077 MB, Params: 518,660 (1.979 MB), Total: 2.06 MB, FLOPs: 40,587,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1269/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1269\n",
      "\n",
      "Iteration 1270 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 49)]\n",
      "Input: 0.077 MB, Params: 517,281 (1.973 MB), Total: 2.05 MB, FLOPs: 40,521,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1270/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1270\n",
      "\n",
      "Iteration 1271 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.077 MB, Params: 515,380 (1.966 MB), Total: 2.04 MB, FLOPs: 40,469,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1271/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1271\n",
      "\n",
      "Iteration 1272 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 512,714 (1.956 MB), Total: 2.03 MB, FLOPs: 40,437,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1272/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1272\n",
      "\n",
      "Iteration 1273 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.077 MB, Params: 510,048 (1.946 MB), Total: 2.02 MB, FLOPs: 40,405,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1273/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1273\n",
      "\n",
      "Iteration 1274 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 9)]\n",
      "Input: 0.077 MB, Params: 509,227 (1.943 MB), Total: 2.02 MB, FLOPs: 40,051,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1274/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1274\n",
      "\n",
      "Iteration 1275 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.077 MB, Params: 506,561 (1.932 MB), Total: 2.01 MB, FLOPs: 40,019,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1275/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1275\n",
      "\n",
      "Iteration 1276 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.077 MB, Params: 503,895 (1.922 MB), Total: 2.00 MB, FLOPs: 39,987,354\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1276/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1276\n",
      "\n",
      "Iteration 1277 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.077 MB, Params: 501,229 (1.912 MB), Total: 1.99 MB, FLOPs: 39,955,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1277/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1277\n",
      "\n",
      "Iteration 1278 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.077 MB, Params: 499,859 (1.907 MB), Total: 1.98 MB, FLOPs: 39,889,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1278/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1278\n",
      "\n",
      "Iteration 1279 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.077 MB, Params: 497,193 (1.897 MB), Total: 1.97 MB, FLOPs: 39,857,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1279/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1279\n",
      "\n",
      "Iteration 1280 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.077 MB, Params: 496,345 (1.893 MB), Total: 1.97 MB, FLOPs: 39,688,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1280/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1280\n",
      "\n",
      "Iteration 1281 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.077 MB, Params: 494,507 (1.886 MB), Total: 1.96 MB, FLOPs: 39,637,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1281/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1281\n",
      "\n",
      "Iteration 1282 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.077 MB, Params: 493,457 (1.882 MB), Total: 1.96 MB, FLOPs: 39,625,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1282/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1282\n",
      "\n",
      "Iteration 1283 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.077 MB, Params: 492,407 (1.878 MB), Total: 1.96 MB, FLOPs: 39,612,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1283/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1283\n",
      "\n",
      "Iteration 1284 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 27)]\n",
      "Input: 0.077 MB, Params: 491,928 (1.877 MB), Total: 1.95 MB, FLOPs: 39,230,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1284/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1284\n",
      "\n",
      "Iteration 1285 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.077 MB, Params: 490,090 (1.870 MB), Total: 1.95 MB, FLOPs: 39,179,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1285/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1285\n",
      "\n",
      "Iteration 1286 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.077 MB, Params: 489,040 (1.866 MB), Total: 1.94 MB, FLOPs: 39,166,910\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1286/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1286\n",
      "\n",
      "Iteration 1287 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 51)]\n",
      "Input: 0.077 MB, Params: 487,990 (1.862 MB), Total: 1.94 MB, FLOPs: 39,154,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1287/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1287\n",
      "\n",
      "Iteration 1288 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.077 MB, Params: 486,152 (1.855 MB), Total: 1.93 MB, FLOPs: 39,103,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1288/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1288\n",
      "\n",
      "Iteration 1289 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.077 MB, Params: 485,349 (1.851 MB), Total: 1.93 MB, FLOPs: 38,758,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1289/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1289\n",
      "\n",
      "Iteration 1290 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.077 MB, Params: 484,006 (1.846 MB), Total: 1.92 MB, FLOPs: 38,693,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1290/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1290\n",
      "\n",
      "Iteration 1291 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.077 MB, Params: 481,403 (1.836 MB), Total: 1.91 MB, FLOPs: 38,662,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1291/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1291\n",
      "\n",
      "Iteration 1292 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.077 MB, Params: 480,060 (1.831 MB), Total: 1.91 MB, FLOPs: 38,598,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1292/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1292\n",
      "\n",
      "Iteration 1293 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.077 MB, Params: 478,789 (1.826 MB), Total: 1.90 MB, FLOPs: 38,461,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1293/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1293\n",
      "\n",
      "Iteration 1294 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.077 MB, Params: 476,186 (1.817 MB), Total: 1.89 MB, FLOPs: 38,430,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1294/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1294\n",
      "\n",
      "Iteration 1295 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.077 MB, Params: 475,154 (1.813 MB), Total: 1.89 MB, FLOPs: 38,418,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1295/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1295\n",
      "\n",
      "Iteration 1296 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.077 MB, Params: 474,122 (1.809 MB), Total: 1.89 MB, FLOPs: 38,405,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1296/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1296\n",
      "\n",
      "Iteration 1297 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.077 MB, Params: 471,537 (1.799 MB), Total: 1.88 MB, FLOPs: 38,374,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1297/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1297\n",
      "\n",
      "Iteration 1298 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.077 MB, Params: 470,514 (1.795 MB), Total: 1.87 MB, FLOPs: 38,362,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1298/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1298\n",
      "\n",
      "Iteration 1299 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.077 MB, Params: 469,180 (1.790 MB), Total: 1.87 MB, FLOPs: 38,298,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1299/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1299\n",
      "\n",
      "Iteration 1300 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.077 MB, Params: 466,604 (1.780 MB), Total: 1.86 MB, FLOPs: 38,267,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1300/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1300\n",
      "\n",
      "Iteration 1301 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.077 MB, Params: 465,801 (1.777 MB), Total: 1.85 MB, FLOPs: 37,922,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1301/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1301\n",
      "\n",
      "Iteration 1302 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.077 MB, Params: 464,467 (1.772 MB), Total: 1.85 MB, FLOPs: 37,858,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1302/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1302\n",
      "\n",
      "Iteration 1303 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.077 MB, Params: 463,453 (1.768 MB), Total: 1.84 MB, FLOPs: 37,846,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1303/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1303\n",
      "\n",
      "Iteration 1304 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.077 MB, Params: 462,119 (1.763 MB), Total: 1.84 MB, FLOPs: 37,782,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1304/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1304\n",
      "\n",
      "Iteration 1305 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.077 MB, Params: 460,362 (1.756 MB), Total: 1.83 MB, FLOPs: 37,734,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1305/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1305\n",
      "\n",
      "Iteration 1306 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.077 MB, Params: 459,037 (1.751 MB), Total: 1.83 MB, FLOPs: 37,670,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1306/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1306\n",
      "\n",
      "Iteration 1307 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.077 MB, Params: 456,479 (1.741 MB), Total: 1.82 MB, FLOPs: 37,639,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1307/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1307\n",
      "\n",
      "Iteration 1308 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.077 MB, Params: 455,474 (1.737 MB), Total: 1.81 MB, FLOPs: 37,627,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1308/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1308\n",
      "\n",
      "Iteration 1309 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 3)]\n",
      "Input: 0.077 MB, Params: 454,149 (1.732 MB), Total: 1.81 MB, FLOPs: 37,564,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1309/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1309\n",
      "\n",
      "Iteration 1310 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.077 MB, Params: 453,328 (1.729 MB), Total: 1.81 MB, FLOPs: 37,400,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1310/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1310\n",
      "\n",
      "Iteration 1311 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.077 MB, Params: 452,003 (1.724 MB), Total: 1.80 MB, FLOPs: 37,336,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1311/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1311\n",
      "\n",
      "Iteration 1312 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.077 MB, Params: 451,182 (1.721 MB), Total: 1.80 MB, FLOPs: 37,172,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1312/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1312\n",
      "\n",
      "Iteration 1313 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.077 MB, Params: 450,177 (1.717 MB), Total: 1.79 MB, FLOPs: 37,160,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1313/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1313\n",
      "\n",
      "Iteration 1314 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.077 MB, Params: 449,172 (1.713 MB), Total: 1.79 MB, FLOPs: 37,148,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1314/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1314\n",
      "\n",
      "Iteration 1315 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.077 MB, Params: 448,167 (1.710 MB), Total: 1.79 MB, FLOPs: 37,136,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1315/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1315\n",
      "\n",
      "Iteration 1316 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.077 MB, Params: 446,842 (1.705 MB), Total: 1.78 MB, FLOPs: 37,073,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1316/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1316\n",
      "\n",
      "Iteration 1317 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.077 MB, Params: 444,320 (1.695 MB), Total: 1.77 MB, FLOPs: 37,042,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1317/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1317\n",
      "\n",
      "Iteration 1318 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.077 MB, Params: 443,324 (1.691 MB), Total: 1.77 MB, FLOPs: 37,030,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1318/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1318\n",
      "\n",
      "Iteration 1319 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.077 MB, Params: 440,811 (1.682 MB), Total: 1.76 MB, FLOPs: 37,000,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1319/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1319\n",
      "\n",
      "Iteration 1320 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.077 MB, Params: 439,117 (1.675 MB), Total: 1.75 MB, FLOPs: 36,954,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1320/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1320\n",
      "\n",
      "Iteration 1321 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.077 MB, Params: 436,613 (1.666 MB), Total: 1.74 MB, FLOPs: 36,924,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1321/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1321\n",
      "\n",
      "Iteration 1322 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.077 MB, Params: 435,635 (1.662 MB), Total: 1.74 MB, FLOPs: 36,913,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1322/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1322\n",
      "\n",
      "Iteration 1323 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.077 MB, Params: 433,140 (1.652 MB), Total: 1.73 MB, FLOPs: 36,883,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1323/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1323\n",
      "\n",
      "Iteration 1324 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 13)]\n",
      "Input: 0.077 MB, Params: 432,823 (1.651 MB), Total: 1.73 MB, FLOPs: 36,603,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1324/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1324\n",
      "\n",
      "Iteration 1325 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.077 MB, Params: 431,507 (1.646 MB), Total: 1.72 MB, FLOPs: 36,540,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1325/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1325\n",
      "\n",
      "Iteration 1326 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.077 MB, Params: 430,326 (1.642 MB), Total: 1.72 MB, FLOPs: 36,410,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1326/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1326\n",
      "\n",
      "Iteration 1327 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 427,831 (1.632 MB), Total: 1.71 MB, FLOPs: 36,380,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1327/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1327\n",
      "\n",
      "Iteration 1328 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 54)]\n",
      "Input: 0.077 MB, Params: 426,650 (1.628 MB), Total: 1.70 MB, FLOPs: 36,251,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1328/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1328\n",
      "\n",
      "Iteration 1329 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.077 MB, Params: 425,690 (1.624 MB), Total: 1.70 MB, FLOPs: 36,239,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1329/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1329\n",
      "\n",
      "Iteration 1330 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.077 MB, Params: 423,204 (1.614 MB), Total: 1.69 MB, FLOPs: 36,209,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1330/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1330\n",
      "\n",
      "Iteration 1331 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.077 MB, Params: 420,718 (1.605 MB), Total: 1.68 MB, FLOPs: 36,179,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1331/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1331\n",
      "\n",
      "Iteration 1332 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 43)]\n",
      "Input: 0.077 MB, Params: 419,420 (1.600 MB), Total: 1.68 MB, FLOPs: 36,117,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1332/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1332\n",
      "\n",
      "Iteration 1333 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.077 MB, Params: 416,934 (1.590 MB), Total: 1.67 MB, FLOPs: 36,087,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1333/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1333\n",
      "\n",
      "Iteration 1334 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.077 MB, Params: 415,636 (1.586 MB), Total: 1.66 MB, FLOPs: 36,025,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1334/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1334\n",
      "\n",
      "Iteration 1335 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 414,338 (1.581 MB), Total: 1.66 MB, FLOPs: 35,963,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1335/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1335\n",
      "\n",
      "Iteration 1336 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.077 MB, Params: 411,852 (1.571 MB), Total: 1.65 MB, FLOPs: 35,933,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1336/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1336\n",
      "\n",
      "Iteration 1337 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.077 MB, Params: 410,257 (1.565 MB), Total: 1.64 MB, FLOPs: 35,890,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1337/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1337\n",
      "\n",
      "Iteration 1338 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.077 MB, Params: 408,662 (1.559 MB), Total: 1.64 MB, FLOPs: 35,846,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1338/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1338\n",
      "\n",
      "Iteration 1339 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.077 MB, Params: 408,345 (1.558 MB), Total: 1.63 MB, FLOPs: 35,566,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1339/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1339\n",
      "\n",
      "Iteration 1340 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.077 MB, Params: 407,065 (1.553 MB), Total: 1.63 MB, FLOPs: 35,505,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1340/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1340\n",
      "\n",
      "Iteration 1341 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.077 MB, Params: 406,141 (1.549 MB), Total: 1.63 MB, FLOPs: 35,494,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1341/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1341\n",
      "\n",
      "Iteration 1342 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.077 MB, Params: 405,217 (1.546 MB), Total: 1.62 MB, FLOPs: 35,483,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1342/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1342\n",
      "\n",
      "Iteration 1343 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.077 MB, Params: 404,293 (1.542 MB), Total: 1.62 MB, FLOPs: 35,472,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1343/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1343\n",
      "\n",
      "Iteration 1344 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.077 MB, Params: 403,369 (1.539 MB), Total: 1.62 MB, FLOPs: 35,460,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1344/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1344\n",
      "\n",
      "Iteration 1345 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.077 MB, Params: 402,089 (1.534 MB), Total: 1.61 MB, FLOPs: 35,399,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1345/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1345\n",
      "\n",
      "Iteration 1346 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 401,165 (1.530 MB), Total: 1.61 MB, FLOPs: 35,388,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1346/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1346\n",
      "\n",
      "Iteration 1347 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.077 MB, Params: 400,241 (1.527 MB), Total: 1.60 MB, FLOPs: 35,377,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1347/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1347\n",
      "\n",
      "Iteration 1348 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.077 MB, Params: 399,438 (1.524 MB), Total: 1.60 MB, FLOPs: 35,217,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1348/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1348\n",
      "\n",
      "Iteration 1349 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.077 MB, Params: 397,024 (1.515 MB), Total: 1.59 MB, FLOPs: 35,188,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1349/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1349\n",
      "\n",
      "Iteration 1350 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.077 MB, Params: 396,221 (1.511 MB), Total: 1.59 MB, FLOPs: 35,027,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1350/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1350\n",
      "\n",
      "Iteration 1351 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.077 MB, Params: 395,418 (1.508 MB), Total: 1.59 MB, FLOPs: 34,867,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1351/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1351\n",
      "\n",
      "Iteration 1352 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 43)]\n",
      "Input: 0.077 MB, Params: 394,309 (1.504 MB), Total: 1.58 MB, FLOPs: 34,745,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1352/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1352\n",
      "\n",
      "Iteration 1353 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.077 MB, Params: 393,394 (1.501 MB), Total: 1.58 MB, FLOPs: 34,734,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1353/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1353\n",
      "\n",
      "Iteration 1354 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.077 MB, Params: 390,989 (1.492 MB), Total: 1.57 MB, FLOPs: 34,705,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1354/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1354\n",
      "\n",
      "Iteration 1355 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.077 MB, Params: 390,083 (1.488 MB), Total: 1.56 MB, FLOPs: 34,694,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1355/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1355\n",
      "\n",
      "Iteration 1356 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.077 MB, Params: 389,177 (1.485 MB), Total: 1.56 MB, FLOPs: 34,683,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1356/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1356\n",
      "\n",
      "Iteration 1357 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.077 MB, Params: 387,906 (1.480 MB), Total: 1.56 MB, FLOPs: 34,622,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1357/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1357\n",
      "\n",
      "Iteration 1358 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.077 MB, Params: 387,148 (1.477 MB), Total: 1.55 MB, FLOPs: 34,286,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1358/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1358\n",
      "\n",
      "Iteration 1359 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.077 MB, Params: 385,877 (1.472 MB), Total: 1.55 MB, FLOPs: 34,225,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1359/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1359\n",
      "\n",
      "Iteration 1360 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.077 MB, Params: 384,336 (1.466 MB), Total: 1.54 MB, FLOPs: 34,184,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1360/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1360\n",
      "\n",
      "Iteration 1361 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.077 MB, Params: 382,795 (1.460 MB), Total: 1.54 MB, FLOPs: 34,142,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1361/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1361\n",
      "\n",
      "Iteration 1362 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.077 MB, Params: 381,254 (1.454 MB), Total: 1.53 MB, FLOPs: 34,100,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1362/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1362\n",
      "\n",
      "Iteration 1363 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.077 MB, Params: 380,163 (1.450 MB), Total: 1.53 MB, FLOPs: 33,979,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1363/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1363\n",
      "\n",
      "Iteration 1364 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.077 MB, Params: 379,257 (1.447 MB), Total: 1.52 MB, FLOPs: 33,968,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1364/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1364\n",
      "\n",
      "Iteration 1365 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.077 MB, Params: 378,823 (1.445 MB), Total: 1.52 MB, FLOPs: 33,622,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1365/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1365\n",
      "\n",
      "Iteration 1366 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.077 MB, Params: 377,282 (1.439 MB), Total: 1.52 MB, FLOPs: 33,581,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1366/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1366\n",
      "\n",
      "Iteration 1367 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.077 MB, Params: 376,376 (1.436 MB), Total: 1.51 MB, FLOPs: 33,570,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1367/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1367\n",
      "\n",
      "Iteration 1368 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.077 MB, Params: 374,043 (1.427 MB), Total: 1.50 MB, FLOPs: 33,542,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1368/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1368\n",
      "\n",
      "Iteration 1369 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.077 MB, Params: 371,710 (1.418 MB), Total: 1.49 MB, FLOPs: 33,514,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1369/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1369\n",
      "\n",
      "Iteration 1370 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.077 MB, Params: 370,822 (1.415 MB), Total: 1.49 MB, FLOPs: 33,503,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1370/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1370\n",
      "\n",
      "Iteration 1371 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.077 MB, Params: 369,596 (1.410 MB), Total: 1.49 MB, FLOPs: 33,444,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1371/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1371\n",
      "\n",
      "Iteration 1372 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.077 MB, Params: 367,272 (1.401 MB), Total: 1.48 MB, FLOPs: 33,416,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1372/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1372\n",
      "\n",
      "Iteration 1373 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.077 MB, Params: 364,948 (1.392 MB), Total: 1.47 MB, FLOPs: 33,389,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1373/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1373\n",
      "\n",
      "Iteration 1374 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.077 MB, Params: 363,722 (1.387 MB), Total: 1.46 MB, FLOPs: 33,330,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1374/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1374\n",
      "\n",
      "Iteration 1375 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.077 MB, Params: 362,973 (1.385 MB), Total: 1.46 MB, FLOPs: 33,001,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1375/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1375\n",
      "\n",
      "Iteration 1376 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.077 MB, Params: 362,206 (1.382 MB), Total: 1.46 MB, FLOPs: 32,847,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1376/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1376\n",
      "\n",
      "Iteration 1377 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.077 MB, Params: 359,882 (1.373 MB), Total: 1.45 MB, FLOPs: 32,819,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1377/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1377\n",
      "\n",
      "Iteration 1378 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 357,558 (1.364 MB), Total: 1.44 MB, FLOPs: 32,792,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1378/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1378\n",
      "\n",
      "Iteration 1379 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.077 MB, Params: 356,089 (1.358 MB), Total: 1.44 MB, FLOPs: 32,752,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1379/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1379\n",
      "\n",
      "Iteration 1380 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.077 MB, Params: 355,237 (1.355 MB), Total: 1.43 MB, FLOPs: 32,741,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1380/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1380\n",
      "\n",
      "Iteration 1381 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.077 MB, Params: 354,385 (1.352 MB), Total: 1.43 MB, FLOPs: 32,731,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1381/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1381\n",
      "\n",
      "Iteration 1382 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.077 MB, Params: 353,533 (1.349 MB), Total: 1.43 MB, FLOPs: 32,721,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1382/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1382\n",
      "\n",
      "Iteration 1383 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.077 MB, Params: 351,245 (1.340 MB), Total: 1.42 MB, FLOPs: 32,694,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1383/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1383\n",
      "\n",
      "Iteration 1384 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.077 MB, Params: 349,785 (1.334 MB), Total: 1.41 MB, FLOPs: 32,654,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1384/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1384\n",
      "\n",
      "Iteration 1385 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.077 MB, Params: 348,942 (1.331 MB), Total: 1.41 MB, FLOPs: 32,644,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1385/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1385\n",
      "\n",
      "Iteration 1386 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.077 MB, Params: 348,517 (1.329 MB), Total: 1.41 MB, FLOPs: 32,304,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1386/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1386\n",
      "\n",
      "Iteration 1387 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.077 MB, Params: 347,453 (1.325 MB), Total: 1.40 MB, FLOPs: 32,186,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1387/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1387\n",
      "\n",
      "Iteration 1388 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.077 MB, Params: 346,610 (1.322 MB), Total: 1.40 MB, FLOPs: 32,176,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1388/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1388\n",
      "\n",
      "Iteration 1389 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 43)]\n",
      "Input: 0.077 MB, Params: 345,411 (1.318 MB), Total: 1.39 MB, FLOPs: 32,118,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1389/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1389\n",
      "\n",
      "Iteration 1390 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 22)]\n",
      "Input: 0.077 MB, Params: 344,986 (1.316 MB), Total: 1.39 MB, FLOPs: 31,779,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1390/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1390\n",
      "\n",
      "Iteration 1391 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.077 MB, Params: 344,143 (1.313 MB), Total: 1.39 MB, FLOPs: 31,769,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1391/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1391\n",
      "\n",
      "Iteration 1392 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.077 MB, Params: 341,891 (1.304 MB), Total: 1.38 MB, FLOPs: 31,742,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1392/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1392\n",
      "\n",
      "Iteration 1393 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.077 MB, Params: 340,692 (1.300 MB), Total: 1.38 MB, FLOPs: 31,685,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1393/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1393\n",
      "\n",
      "Iteration 1394 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 39)]\n",
      "Input: 0.077 MB, Params: 339,493 (1.295 MB), Total: 1.37 MB, FLOPs: 31,627,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1394/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1394\n",
      "\n",
      "Iteration 1395 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.077 MB, Params: 338,069 (1.290 MB), Total: 1.37 MB, FLOPs: 31,588,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1395/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1395\n",
      "\n",
      "Iteration 1396 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.077 MB, Params: 337,311 (1.287 MB), Total: 1.36 MB, FLOPs: 31,437,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1396/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1396\n",
      "\n",
      "Iteration 1397 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.077 MB, Params: 336,121 (1.282 MB), Total: 1.36 MB, FLOPs: 31,380,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1397/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1397\n",
      "\n",
      "Iteration 1398 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.077 MB, Params: 335,287 (1.279 MB), Total: 1.36 MB, FLOPs: 31,370,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1398/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1398\n",
      "\n",
      "Iteration 1399 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 333,872 (1.274 MB), Total: 1.35 MB, FLOPs: 31,332,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1399/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1399\n",
      "\n",
      "Iteration 1400 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 141)]\n",
      "Input: 0.077 MB, Params: 333,038 (1.270 MB), Total: 1.35 MB, FLOPs: 31,322,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1400/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1400\n",
      "\n",
      "Iteration 1401 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.077 MB, Params: 332,204 (1.267 MB), Total: 1.34 MB, FLOPs: 31,312,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1401/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1401\n",
      "\n",
      "Iteration 1402 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.077 MB, Params: 331,370 (1.264 MB), Total: 1.34 MB, FLOPs: 31,302,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1402/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1402\n",
      "\n",
      "Iteration 1403 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 329,172 (1.256 MB), Total: 1.33 MB, FLOPs: 31,276,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1403/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1403\n",
      "\n",
      "Iteration 1404 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 327,991 (1.251 MB), Total: 1.33 MB, FLOPs: 31,219,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1404/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1404\n",
      "\n",
      "Iteration 1405 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.077 MB, Params: 325,793 (1.243 MB), Total: 1.32 MB, FLOPs: 31,193,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1405/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1405\n",
      "\n",
      "Iteration 1406 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.077 MB, Params: 323,595 (1.234 MB), Total: 1.31 MB, FLOPs: 31,166,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1406/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1406\n",
      "\n",
      "Iteration 1407 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.077 MB, Params: 322,216 (1.229 MB), Total: 1.31 MB, FLOPs: 31,129,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1407/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1407\n",
      "\n",
      "Iteration 1408 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.077 MB, Params: 321,409 (1.226 MB), Total: 1.30 MB, FLOPs: 31,119,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1408/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1408\n",
      "\n",
      "Iteration 1409 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.077 MB, Params: 320,237 (1.222 MB), Total: 1.30 MB, FLOPs: 31,063,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1409/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1409\n",
      "\n",
      "Iteration 1410 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 55)]\n",
      "Input: 0.077 MB, Params: 319,236 (1.218 MB), Total: 1.29 MB, FLOPs: 30,949,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1410/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1410\n",
      "\n",
      "Iteration 1411 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 318,487 (1.215 MB), Total: 1.29 MB, FLOPs: 30,799,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1411/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1411\n",
      "\n",
      "Iteration 1412 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.077 MB, Params: 316,307 (1.207 MB), Total: 1.28 MB, FLOPs: 30,773,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1412/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1412\n",
      "\n",
      "Iteration 1413 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 4)]\n",
      "Input: 0.077 MB, Params: 315,315 (1.203 MB), Total: 1.28 MB, FLOPs: 30,661,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1413/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1413\n",
      "\n",
      "Iteration 1414 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.077 MB, Params: 314,890 (1.201 MB), Total: 1.28 MB, FLOPs: 30,322,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1414/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1414\n",
      "\n",
      "Iteration 1415 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.077 MB, Params: 313,736 (1.197 MB), Total: 1.27 MB, FLOPs: 30,267,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1415/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1415\n",
      "\n",
      "Iteration 1416 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.077 MB, Params: 312,582 (1.192 MB), Total: 1.27 MB, FLOPs: 30,211,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1416/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1416\n",
      "\n",
      "Iteration 1417 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.077 MB, Params: 310,402 (1.184 MB), Total: 1.26 MB, FLOPs: 30,185,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1417/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1417\n",
      "\n",
      "Iteration 1418 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.077 MB, Params: 309,068 (1.179 MB), Total: 1.26 MB, FLOPs: 30,149,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1418/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1418\n",
      "\n",
      "Iteration 1419 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.077 MB, Params: 308,643 (1.177 MB), Total: 1.25 MB, FLOPs: 29,810,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 1419/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1419\n",
      "\n",
      "Iteration 1420 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 307,498 (1.173 MB), Total: 1.25 MB, FLOPs: 29,755,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1420/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1420\n",
      "\n",
      "Iteration 1421 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.077 MB, Params: 307,073 (1.171 MB), Total: 1.25 MB, FLOPs: 29,416,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1421/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1421\n",
      "\n",
      "Iteration 1422 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 10)]\n",
      "Input: 0.077 MB, Params: 306,396 (1.169 MB), Total: 1.25 MB, FLOPs: 29,128,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 1422/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1422\n",
      "\n",
      "Iteration 1423 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.077 MB, Params: 304,225 (1.161 MB), Total: 1.24 MB, FLOPs: 29,102,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1423/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1423\n",
      "\n",
      "Iteration 1424 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.077 MB, Params: 303,260 (1.157 MB), Total: 1.23 MB, FLOPs: 28,991,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1424/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1424\n",
      "\n",
      "Iteration 1425 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 302,295 (1.153 MB), Total: 1.23 MB, FLOPs: 28,880,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1425/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1425\n",
      "\n",
      "Iteration 1426 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.077 MB, Params: 301,515 (1.150 MB), Total: 1.23 MB, FLOPs: 28,871,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1426/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1426\n",
      "\n",
      "Iteration 1427 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 300,802 (1.147 MB), Total: 1.22 MB, FLOPs: 28,729,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1427/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1427\n",
      "\n",
      "Iteration 1428 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.077 MB, Params: 300,386 (1.146 MB), Total: 1.22 MB, FLOPs: 28,397,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1428/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1428\n",
      "\n",
      "Iteration 1429 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.077 MB, Params: 299,606 (1.143 MB), Total: 1.22 MB, FLOPs: 28,387,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1429/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1429\n",
      "\n",
      "Iteration 1430 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.077 MB, Params: 298,479 (1.139 MB), Total: 1.22 MB, FLOPs: 28,333,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1430/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1430\n",
      "\n",
      "Iteration 1431 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.077 MB, Params: 297,699 (1.136 MB), Total: 1.21 MB, FLOPs: 28,324,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1431/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1431\n",
      "\n",
      "Iteration 1432 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.077 MB, Params: 296,919 (1.133 MB), Total: 1.21 MB, FLOPs: 28,315,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1432/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1432\n",
      "\n",
      "Iteration 1433 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.077 MB, Params: 296,139 (1.130 MB), Total: 1.21 MB, FLOPs: 28,305,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1433/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1433\n",
      "\n",
      "Iteration 1434 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 294,013 (1.122 MB), Total: 1.20 MB, FLOPs: 28,280,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1434/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1434\n",
      "\n",
      "Iteration 1435 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.077 MB, Params: 292,886 (1.117 MB), Total: 1.19 MB, FLOPs: 28,226,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1435/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1435\n",
      "\n",
      "Iteration 1436 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 292,115 (1.114 MB), Total: 1.19 MB, FLOPs: 28,216,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1436/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1436\n",
      "\n",
      "Iteration 1437 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.077 MB, Params: 290,826 (1.109 MB), Total: 1.19 MB, FLOPs: 28,182,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1437/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1437\n",
      "\n",
      "Iteration 1438 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.077 MB, Params: 289,537 (1.104 MB), Total: 1.18 MB, FLOPs: 28,148,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1438/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1438\n",
      "\n",
      "Iteration 1439 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.077 MB, Params: 288,599 (1.101 MB), Total: 1.18 MB, FLOPs: 28,040,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1439/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1439\n",
      "\n",
      "Iteration 1440 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.077 MB, Params: 287,661 (1.097 MB), Total: 1.17 MB, FLOPs: 27,931,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1440/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1440\n",
      "\n",
      "Iteration 1441 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 286,372 (1.092 MB), Total: 1.17 MB, FLOPs: 27,897,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1441/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1441\n",
      "\n",
      "Iteration 1442 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.077 MB, Params: 285,083 (1.088 MB), Total: 1.16 MB, FLOPs: 27,863,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 1442/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1442\n",
      "\n",
      "Iteration 1443 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.077 MB, Params: 284,010 (1.083 MB), Total: 1.16 MB, FLOPs: 27,811,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1443/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1443\n",
      "\n",
      "Iteration 1444 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.077 MB, Params: 282,730 (1.079 MB), Total: 1.16 MB, FLOPs: 27,777,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1444/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1444\n",
      "\n",
      "Iteration 1445 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 39)]\n",
      "Input: 0.077 MB, Params: 281,801 (1.075 MB), Total: 1.15 MB, FLOPs: 27,669,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1445/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1445\n",
      "\n",
      "Iteration 1446 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 280,521 (1.070 MB), Total: 1.15 MB, FLOPs: 27,636,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1446/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1446\n",
      "\n",
      "Iteration 1447 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.077 MB, Params: 279,592 (1.067 MB), Total: 1.14 MB, FLOPs: 27,528,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1447/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1447\n",
      "\n",
      "Iteration 1448 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 21)]\n",
      "Input: 0.077 MB, Params: 278,933 (1.064 MB), Total: 1.14 MB, FLOPs: 27,249,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1448/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1448\n",
      "\n",
      "Iteration 1449 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 43)]\n",
      "Input: 0.077 MB, Params: 277,896 (1.060 MB), Total: 1.14 MB, FLOPs: 27,199,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1449/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1449\n",
      "\n",
      "Iteration 1450 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 275,833 (1.052 MB), Total: 1.13 MB, FLOPs: 27,174,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1450/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1450\n",
      "\n",
      "Iteration 1451 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.077 MB, Params: 275,071 (1.049 MB), Total: 1.13 MB, FLOPs: 27,165,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1451/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1451\n",
      "\n",
      "Iteration 1452 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 18)]\n",
      "Input: 0.077 MB, Params: 274,664 (1.048 MB), Total: 1.12 MB, FLOPs: 26,841,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1452/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1452\n",
      "\n",
      "Iteration 1453 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 5)]\n",
      "Input: 0.077 MB, Params: 274,014 (1.045 MB), Total: 1.12 MB, FLOPs: 26,569,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1453/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1453\n",
      "\n",
      "Iteration 1454 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 18)]\n",
      "Input: 0.077 MB, Params: 273,616 (1.044 MB), Total: 1.12 MB, FLOPs: 26,251,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1454/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1454\n",
      "\n",
      "Iteration 1455 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 37)]\n",
      "Input: 0.077 MB, Params: 272,696 (1.040 MB), Total: 1.12 MB, FLOPs: 26,144,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1455/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1455\n",
      "\n",
      "Iteration 1456 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 45)]\n",
      "Input: 0.077 MB, Params: 271,776 (1.037 MB), Total: 1.11 MB, FLOPs: 26,037,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1456/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1456\n",
      "\n",
      "Iteration 1457 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.077 MB, Params: 270,757 (1.033 MB), Total: 1.11 MB, FLOPs: 25,988,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1457/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1457\n",
      "\n",
      "Iteration 1458 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.077 MB, Params: 268,703 (1.025 MB), Total: 1.10 MB, FLOPs: 25,963,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1458/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1458\n",
      "\n",
      "Iteration 1459 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 17)]\n",
      "Input: 0.077 MB, Params: 268,305 (1.024 MB), Total: 1.10 MB, FLOPs: 25,645,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1459/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1459\n",
      "\n",
      "Iteration 1460 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.077 MB, Params: 267,394 (1.020 MB), Total: 1.10 MB, FLOPs: 25,539,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1460/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1460\n",
      "\n",
      "Iteration 1461 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.077 MB, Params: 266,641 (1.017 MB), Total: 1.09 MB, FLOPs: 25,530,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1461/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1461\n",
      "\n",
      "Iteration 1462 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.077 MB, Params: 265,888 (1.014 MB), Total: 1.09 MB, FLOPs: 25,521,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1462/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1462\n",
      "\n",
      "Iteration 1463 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.077 MB, Params: 265,256 (1.012 MB), Total: 1.09 MB, FLOPs: 25,394,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1463/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1463\n",
      "\n",
      "Iteration 1464 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.077 MB, Params: 264,354 (1.008 MB), Total: 1.09 MB, FLOPs: 25,289,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1464/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1464\n",
      "\n",
      "Iteration 1465 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.077 MB, Params: 262,318 (1.001 MB), Total: 1.08 MB, FLOPs: 25,265,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1465/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1465\n",
      "\n",
      "Iteration 1466 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.077 MB, Params: 261,317 (0.997 MB), Total: 1.07 MB, FLOPs: 25,217,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1466/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1466\n",
      "\n",
      "Iteration 1467 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 260,694 (0.994 MB), Total: 1.07 MB, FLOPs: 25,092,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1467/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1467\n",
      "\n",
      "Iteration 1468 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 5)]\n",
      "Input: 0.077 MB, Params: 260,071 (0.992 MB), Total: 1.07 MB, FLOPs: 24,968,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1468/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1468\n",
      "\n",
      "Iteration 1469 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.077 MB, Params: 259,327 (0.989 MB), Total: 1.07 MB, FLOPs: 24,959,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1469/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1469\n",
      "\n",
      "Iteration 1470 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.077 MB, Params: 258,704 (0.987 MB), Total: 1.06 MB, FLOPs: 24,835,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1470/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1470\n",
      "\n",
      "Iteration 1471 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.077 MB, Params: 257,478 (0.982 MB), Total: 1.06 MB, FLOPs: 24,802,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1471/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1471\n",
      "\n",
      "Iteration 1472 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.077 MB, Params: 256,252 (0.978 MB), Total: 1.05 MB, FLOPs: 24,770,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1472/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1472\n",
      "\n",
      "Iteration 1473 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.077 MB, Params: 255,269 (0.974 MB), Total: 1.05 MB, FLOPs: 24,723,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1473/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1473\n",
      "\n",
      "Iteration 1474 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.077 MB, Params: 253,260 (0.966 MB), Total: 1.04 MB, FLOPs: 24,699,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1474/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1474\n",
      "\n",
      "Iteration 1475 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 252,525 (0.963 MB), Total: 1.04 MB, FLOPs: 24,690,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1475/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1475\n",
      "\n",
      "Iteration 1476 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.077 MB, Params: 251,542 (0.960 MB), Total: 1.04 MB, FLOPs: 24,643,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1476/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1476\n",
      "\n",
      "Iteration 1477 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.077 MB, Params: 250,807 (0.957 MB), Total: 1.03 MB, FLOPs: 24,634,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1477/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1477\n",
      "\n",
      "Iteration 1478 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.077 MB, Params: 248,816 (0.949 MB), Total: 1.03 MB, FLOPs: 24,610,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1478/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1478\n",
      "\n",
      "Iteration 1479 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.077 MB, Params: 247,626 (0.945 MB), Total: 1.02 MB, FLOPs: 24,579,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1479/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1479\n",
      "\n",
      "Iteration 1480 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.077 MB, Params: 246,436 (0.940 MB), Total: 1.02 MB, FLOPs: 24,548,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1480/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1480\n",
      "\n",
      "Iteration 1481 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.077 MB, Params: 245,710 (0.937 MB), Total: 1.01 MB, FLOPs: 24,539,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1481/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1481\n",
      "\n",
      "Iteration 1482 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.077 MB, Params: 244,520 (0.933 MB), Total: 1.01 MB, FLOPs: 24,508,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1482/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1482\n",
      "\n",
      "Iteration 1483 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.077 MB, Params: 242,565 (0.925 MB), Total: 1.00 MB, FLOPs: 24,485,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1483/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1483\n",
      "\n",
      "Iteration 1484 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.077 MB, Params: 241,717 (0.922 MB), Total: 1.00 MB, FLOPs: 24,386,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1484/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1484\n",
      "\n",
      "Iteration 1485 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.077 MB, Params: 241,000 (0.919 MB), Total: 1.00 MB, FLOPs: 24,378,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1485/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1485\n",
      "\n",
      "Iteration 1486 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 2)]\n",
      "Input: 0.077 MB, Params: 240,404 (0.917 MB), Total: 0.99 MB, FLOPs: 24,128,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1486/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1486\n",
      "\n",
      "Iteration 1487 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.077 MB, Params: 239,687 (0.914 MB), Total: 0.99 MB, FLOPs: 24,119,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1487/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1487\n",
      "\n",
      "Iteration 1488 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.077 MB, Params: 238,839 (0.911 MB), Total: 0.99 MB, FLOPs: 24,020,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1488/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1488\n",
      "\n",
      "Iteration 1489 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 237,658 (0.907 MB), Total: 0.98 MB, FLOPs: 23,989,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1489/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1489\n",
      "\n",
      "Iteration 1490 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.077 MB, Params: 235,730 (0.899 MB), Total: 0.98 MB, FLOPs: 23,966,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1490/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1490\n",
      "\n",
      "Iteration 1491 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 235,022 (0.897 MB), Total: 0.97 MB, FLOPs: 23,958,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1491/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1491\n",
      "\n",
      "Iteration 1492 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.077 MB, Params: 234,314 (0.894 MB), Total: 0.97 MB, FLOPs: 23,949,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1492/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1492\n",
      "\n",
      "Iteration 1493 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.077 MB, Params: 233,606 (0.891 MB), Total: 0.97 MB, FLOPs: 23,941,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1493/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1493\n",
      "\n",
      "Iteration 1494 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 40)]\n",
      "Input: 0.077 MB, Params: 232,758 (0.888 MB), Total: 0.96 MB, FLOPs: 23,842,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1494/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1494\n",
      "\n",
      "Iteration 1495 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.077 MB, Params: 230,857 (0.881 MB), Total: 0.96 MB, FLOPs: 23,820,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1495/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1495\n",
      "\n",
      "Iteration 1496 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 64)]\n",
      "Input: 0.077 MB, Params: 230,158 (0.878 MB), Total: 0.95 MB, FLOPs: 23,811,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1496/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1496\n",
      "\n",
      "Iteration 1497 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.077 MB, Params: 229,769 (0.876 MB), Total: 0.95 MB, FLOPs: 23,501,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1497/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1497\n",
      "\n",
      "Iteration 1498 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 15)]\n",
      "Input: 0.077 MB, Params: 229,182 (0.874 MB), Total: 0.95 MB, FLOPs: 23,258,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1498/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1498\n",
      "\n",
      "Iteration 1499 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.077 MB, Params: 228,483 (0.872 MB), Total: 0.95 MB, FLOPs: 23,250,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1499/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1499\n",
      "\n",
      "Iteration 1500 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.077 MB, Params: 227,784 (0.869 MB), Total: 0.95 MB, FLOPs: 23,241,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1500/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1500\n",
      "\n",
      "Iteration 1501 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.077 MB, Params: 227,085 (0.866 MB), Total: 0.94 MB, FLOPs: 23,233,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1501/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1501\n",
      "\n",
      "Iteration 1502 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.077 MB, Params: 226,507 (0.864 MB), Total: 0.94 MB, FLOPs: 23,118,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1502/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1502\n",
      "\n",
      "Iteration 1503 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.077 MB, Params: 225,668 (0.861 MB), Total: 0.94 MB, FLOPs: 23,021,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1503/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1503\n",
      "\n",
      "Iteration 1504 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.077 MB, Params: 224,757 (0.857 MB), Total: 0.93 MB, FLOPs: 22,977,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1504/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1504\n",
      "\n",
      "Iteration 1505 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 14)]\n",
      "Input: 0.077 MB, Params: 224,377 (0.856 MB), Total: 0.93 MB, FLOPs: 22,674,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1505/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1505\n",
      "\n",
      "Iteration 1506 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 4)]\n",
      "Input: 0.077 MB, Params: 223,997 (0.854 MB), Total: 0.93 MB, FLOPs: 22,371,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1506/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1506\n",
      "\n",
      "Iteration 1507 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.077 MB, Params: 223,428 (0.852 MB), Total: 0.93 MB, FLOPs: 22,257,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1507/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1507\n",
      "\n",
      "Iteration 1508 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.077 MB, Params: 222,729 (0.850 MB), Total: 0.93 MB, FLOPs: 22,249,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1508/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1508\n",
      "\n",
      "Iteration 1509 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.077 MB, Params: 222,030 (0.847 MB), Total: 0.92 MB, FLOPs: 22,241,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 1509/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1509\n",
      "\n",
      "Iteration 1510 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.077 MB, Params: 220,183 (0.840 MB), Total: 0.92 MB, FLOPs: 22,218,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1510/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1510\n",
      "\n",
      "Iteration 1511 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.077 MB, Params: 219,362 (0.837 MB), Total: 0.91 MB, FLOPs: 22,124,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1511/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1511\n",
      "\n",
      "Iteration 1512 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 218,672 (0.834 MB), Total: 0.91 MB, FLOPs: 22,116,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1512/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1512\n",
      "\n",
      "Iteration 1513 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 217,527 (0.830 MB), Total: 0.91 MB, FLOPs: 22,085,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1513/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1513\n",
      "\n",
      "Iteration 1514 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.077 MB, Params: 216,382 (0.825 MB), Total: 0.90 MB, FLOPs: 22,055,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1514/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1514\n",
      "\n",
      "Iteration 1515 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.077 MB, Params: 215,561 (0.822 MB), Total: 0.90 MB, FLOPs: 21,961,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1515/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1515\n",
      "\n",
      "Iteration 1516 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.077 MB, Params: 214,416 (0.818 MB), Total: 0.89 MB, FLOPs: 21,930,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1516/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1516\n",
      "\n",
      "Iteration 1517 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.077 MB, Params: 213,595 (0.815 MB), Total: 0.89 MB, FLOPs: 21,836,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1517/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1517\n",
      "\n",
      "Iteration 1518 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.077 MB, Params: 212,905 (0.812 MB), Total: 0.89 MB, FLOPs: 21,828,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1518/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1518\n",
      "\n",
      "Iteration 1519 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 9)]\n",
      "Input: 0.077 MB, Params: 212,084 (0.809 MB), Total: 0.89 MB, FLOPs: 21,733,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1519/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1519\n",
      "\n",
      "Iteration 1520 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 210,939 (0.805 MB), Total: 0.88 MB, FLOPs: 21,703,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1520/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1520\n",
      "\n",
      "Iteration 1521 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.077 MB, Params: 210,249 (0.802 MB), Total: 0.88 MB, FLOPs: 21,695,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1521/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1521\n",
      "\n",
      "Iteration 1522 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 3)]\n",
      "Input: 0.077 MB, Params: 209,698 (0.800 MB), Total: 0.88 MB, FLOPs: 21,470,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1522/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1522\n",
      "\n",
      "Iteration 1523 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 207,914 (0.793 MB), Total: 0.87 MB, FLOPs: 21,448,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1523/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1523\n",
      "\n",
      "Iteration 1524 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.077 MB, Params: 207,093 (0.790 MB), Total: 0.87 MB, FLOPs: 21,354,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1524/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1524\n",
      "\n",
      "Iteration 1525 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.077 MB, Params: 206,578 (0.788 MB), Total: 0.86 MB, FLOPs: 21,251,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1525/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1525\n",
      "\n",
      "Iteration 1526 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.077 MB, Params: 205,897 (0.785 MB), Total: 0.86 MB, FLOPs: 21,243,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1526/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1526\n",
      "\n",
      "Iteration 1527 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 113)]\n",
      "Input: 0.077 MB, Params: 205,216 (0.783 MB), Total: 0.86 MB, FLOPs: 21,235,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1527/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1527\n",
      "\n",
      "Iteration 1528 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.077 MB, Params: 204,386 (0.780 MB), Total: 0.86 MB, FLOPs: 21,195,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1528/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1528\n",
      "\n",
      "Iteration 1529 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.077 MB, Params: 203,556 (0.777 MB), Total: 0.85 MB, FLOPs: 21,155,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1529/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1529\n",
      "\n",
      "Iteration 1530 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.077 MB, Params: 202,438 (0.772 MB), Total: 0.85 MB, FLOPs: 21,126,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1530/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1530\n",
      "\n",
      "Iteration 1531 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.077 MB, Params: 201,757 (0.770 MB), Total: 0.85 MB, FLOPs: 21,118,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1531/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1531\n",
      "\n",
      "Iteration 1532 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.077 MB, Params: 200,936 (0.767 MB), Total: 0.84 MB, FLOPs: 21,079,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1532/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1532\n",
      "\n",
      "Iteration 1533 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 199,188 (0.760 MB), Total: 0.84 MB, FLOPs: 21,058,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1533/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1533\n",
      "\n",
      "Iteration 1534 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.077 MB, Params: 197,440 (0.753 MB), Total: 0.83 MB, FLOPs: 21,037,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1534/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1534\n",
      "\n",
      "Iteration 1535 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.077 MB, Params: 196,925 (0.751 MB), Total: 0.83 MB, FLOPs: 20,934,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1535/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1535\n",
      "\n",
      "Iteration 1536 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 195,834 (0.747 MB), Total: 0.82 MB, FLOPs: 20,905,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1536/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1536\n",
      "\n",
      "Iteration 1537 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.077 MB, Params: 195,171 (0.745 MB), Total: 0.82 MB, FLOPs: 20,897,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1537/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1537\n",
      "\n",
      "Iteration 1538 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.077 MB, Params: 194,395 (0.742 MB), Total: 0.82 MB, FLOPs: 20,808,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1538/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1538\n",
      "\n",
      "Iteration 1539 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 45)]\n",
      "Input: 0.077 MB, Params: 193,592 (0.738 MB), Total: 0.82 MB, FLOPs: 20,769,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1539/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1539\n",
      "\n",
      "Iteration 1540 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 40)]\n",
      "Input: 0.077 MB, Params: 192,510 (0.734 MB), Total: 0.81 MB, FLOPs: 20,741,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1540/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1540\n",
      "\n",
      "Iteration 1541 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.077 MB, Params: 191,743 (0.731 MB), Total: 0.81 MB, FLOPs: 20,652,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1541/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1541\n",
      "\n",
      "Iteration 1542 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.077 MB, Params: 190,661 (0.727 MB), Total: 0.80 MB, FLOPs: 20,623,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1542/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1542\n",
      "\n",
      "Iteration 1543 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.077 MB, Params: 189,894 (0.724 MB), Total: 0.80 MB, FLOPs: 20,534,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1543/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1543\n",
      "\n",
      "Iteration 1544 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.077 MB, Params: 189,127 (0.721 MB), Total: 0.80 MB, FLOPs: 20,498,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1544/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1544\n",
      "\n",
      "Iteration 1545 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.077 MB, Params: 188,464 (0.719 MB), Total: 0.80 MB, FLOPs: 20,490,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1545/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1545\n",
      "\n",
      "Iteration 1546 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 187,391 (0.715 MB), Total: 0.79 MB, FLOPs: 20,462,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1546/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1546\n",
      "\n",
      "Iteration 1547 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 186,318 (0.711 MB), Total: 0.79 MB, FLOPs: 20,434,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1547/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1547\n",
      "\n",
      "Iteration 1548 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 17)]\n",
      "Input: 0.077 MB, Params: 185,785 (0.709 MB), Total: 0.79 MB, FLOPs: 20,213,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1548/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1548\n",
      "\n",
      "Iteration 1549 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.077 MB, Params: 185,122 (0.706 MB), Total: 0.78 MB, FLOPs: 20,205,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1549/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1549\n",
      "\n",
      "Iteration 1550 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.077 MB, Params: 184,459 (0.704 MB), Total: 0.78 MB, FLOPs: 20,197,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1550/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1550\n",
      "\n",
      "Iteration 1551 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.077 MB, Params: 183,796 (0.701 MB), Total: 0.78 MB, FLOPs: 20,189,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1551/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1551\n",
      "\n",
      "Iteration 1552 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 4)]\n",
      "Input: 0.077 MB, Params: 183,625 (0.700 MB), Total: 0.78 MB, FLOPs: 19,283,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1552/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1552\n",
      "\n",
      "Iteration 1553 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.077 MB, Params: 182,962 (0.698 MB), Total: 0.77 MB, FLOPs: 19,275,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1553/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1553\n",
      "\n",
      "Iteration 1554 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 181,889 (0.694 MB), Total: 0.77 MB, FLOPs: 19,247,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1554/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1554\n",
      "\n",
      "Iteration 1555 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 180,816 (0.690 MB), Total: 0.77 MB, FLOPs: 19,219,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1555/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1555\n",
      "\n",
      "Iteration 1556 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.077 MB, Params: 180,058 (0.687 MB), Total: 0.76 MB, FLOPs: 19,131,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1556/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1556\n",
      "\n",
      "Iteration 1557 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 3)]\n",
      "Input: 0.077 MB, Params: 179,300 (0.684 MB), Total: 0.76 MB, FLOPs: 19,042,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1557/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1557\n",
      "\n",
      "Iteration 1558 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.077 MB, Params: 178,637 (0.681 MB), Total: 0.76 MB, FLOPs: 19,034,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1558/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1558\n",
      "\n",
      "Iteration 1559 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.077 MB, Params: 177,974 (0.679 MB), Total: 0.76 MB, FLOPs: 19,026,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1559/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1559\n",
      "\n",
      "Iteration 1560 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.077 MB, Params: 177,311 (0.676 MB), Total: 0.75 MB, FLOPs: 19,018,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1560/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1560\n",
      "\n",
      "Iteration 1561 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.077 MB, Params: 175,707 (0.670 MB), Total: 0.75 MB, FLOPs: 18,999,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1561/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1561\n",
      "\n",
      "Iteration 1562 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 174,103 (0.664 MB), Total: 0.74 MB, FLOPs: 18,980,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1562/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1562\n",
      "\n",
      "Iteration 1563 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.077 MB, Params: 173,390 (0.661 MB), Total: 0.74 MB, FLOPs: 18,946,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1563/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1563\n",
      "\n",
      "Iteration 1564 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.077 MB, Params: 172,344 (0.657 MB), Total: 0.73 MB, FLOPs: 18,918,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1564/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1564\n",
      "\n",
      "Iteration 1565 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.077 MB, Params: 171,298 (0.653 MB), Total: 0.73 MB, FLOPs: 18,891,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1565/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1565\n",
      "\n",
      "Iteration 1566 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.077 MB, Params: 170,549 (0.651 MB), Total: 0.73 MB, FLOPs: 18,803,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1566/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1566\n",
      "\n",
      "Iteration 1567 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 23)]\n",
      "Input: 0.077 MB, Params: 169,800 (0.648 MB), Total: 0.72 MB, FLOPs: 18,715,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1567/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1567\n",
      "\n",
      "Iteration 1568 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.077 MB, Params: 169,155 (0.645 MB), Total: 0.72 MB, FLOPs: 18,707,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1568/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1568\n",
      "\n",
      "Iteration 1569 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.077 MB, Params: 168,712 (0.644 MB), Total: 0.72 MB, FLOPs: 18,619,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1569/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1569\n",
      "\n",
      "Iteration 1570 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 9)]\n",
      "Input: 0.077 MB, Params: 168,512 (0.643 MB), Total: 0.72 MB, FLOPs: 18,432,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1570/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1570\n",
      "\n",
      "Iteration 1571 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.077 MB, Params: 166,935 (0.637 MB), Total: 0.71 MB, FLOPs: 18,413,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1571/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1571\n",
      "\n",
      "Iteration 1572 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.077 MB, Params: 166,299 (0.634 MB), Total: 0.71 MB, FLOPs: 18,406,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1572/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1572\n",
      "\n",
      "Iteration 1573 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.077 MB, Params: 164,731 (0.628 MB), Total: 0.71 MB, FLOPs: 18,387,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1573/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1573\n",
      "\n",
      "Iteration 1574 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.077 MB, Params: 164,288 (0.627 MB), Total: 0.70 MB, FLOPs: 18,298,932\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1574/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1574\n",
      "\n",
      "Iteration 1575 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 163,260 (0.623 MB), Total: 0.70 MB, FLOPs: 18,271,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1575/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1575\n",
      "\n",
      "Iteration 1576 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.077 MB, Params: 161,701 (0.617 MB), Total: 0.69 MB, FLOPs: 18,253,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1576/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1576\n",
      "\n",
      "Iteration 1577 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.077 MB, Params: 161,258 (0.615 MB), Total: 0.69 MB, FLOPs: 18,164,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1577/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1577\n",
      "\n",
      "Iteration 1578 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.077 MB, Params: 160,640 (0.613 MB), Total: 0.69 MB, FLOPs: 18,157,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1578/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1578\n",
      "\n",
      "Iteration 1579 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.077 MB, Params: 159,972 (0.610 MB), Total: 0.69 MB, FLOPs: 18,125,452\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1579/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1579\n",
      "\n",
      "Iteration 1580 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.077 MB, Params: 159,354 (0.608 MB), Total: 0.68 MB, FLOPs: 18,118,072\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1580/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1580\n",
      "\n",
      "Iteration 1581 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.077 MB, Params: 159,001 (0.607 MB), Total: 0.68 MB, FLOPs: 17,836,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1581/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1581\n",
      "\n",
      "Iteration 1582 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.077 MB, Params: 158,383 (0.604 MB), Total: 0.68 MB, FLOPs: 17,829,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1582/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1582\n",
      "\n",
      "Iteration 1583 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.077 MB, Params: 157,765 (0.602 MB), Total: 0.68 MB, FLOPs: 17,821,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1583/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1583\n",
      "\n",
      "Iteration 1584 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.077 MB, Params: 157,147 (0.599 MB), Total: 0.68 MB, FLOPs: 17,814,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1584/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1584\n",
      "\n",
      "Iteration 1585 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.077 MB, Params: 156,137 (0.596 MB), Total: 0.67 MB, FLOPs: 17,787,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1585/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1585\n",
      "\n",
      "Iteration 1586 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 16)]\n",
      "Input: 0.077 MB, Params: 155,640 (0.594 MB), Total: 0.67 MB, FLOPs: 17,579,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1586/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1586\n",
      "\n",
      "Iteration 1587 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.077 MB, Params: 154,135 (0.588 MB), Total: 0.66 MB, FLOPs: 17,561,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1587/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1587\n",
      "\n",
      "Iteration 1588 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.077 MB, Params: 152,630 (0.582 MB), Total: 0.66 MB, FLOPs: 17,543,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1588/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1588\n",
      "\n",
      "Iteration 1589 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.077 MB, Params: 151,125 (0.576 MB), Total: 0.65 MB, FLOPs: 17,525,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1589/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1589\n",
      "\n",
      "Iteration 1590 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 150,466 (0.574 MB), Total: 0.65 MB, FLOPs: 17,493,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1590/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1590\n",
      "\n",
      "Iteration 1591 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.077 MB, Params: 149,875 (0.572 MB), Total: 0.65 MB, FLOPs: 17,486,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1591/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1591\n",
      "\n",
      "Iteration 1592 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.077 MB, Params: 149,284 (0.569 MB), Total: 0.65 MB, FLOPs: 17,479,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1592/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1592\n",
      "\n",
      "Iteration 1593 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.077 MB, Params: 148,693 (0.567 MB), Total: 0.64 MB, FLOPs: 17,472,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1593/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1593\n",
      "\n",
      "Iteration 1594 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.077 MB, Params: 147,215 (0.562 MB), Total: 0.64 MB, FLOPs: 17,454,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1594/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1594\n",
      "\n",
      "Iteration 1595 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.077 MB, Params: 146,633 (0.559 MB), Total: 0.64 MB, FLOPs: 17,447,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1595/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1595\n",
      "\n",
      "Iteration 1596 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 145,164 (0.554 MB), Total: 0.63 MB, FLOPs: 17,430,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1596/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1596\n",
      "\n",
      "Iteration 1597 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.077 MB, Params: 143,695 (0.548 MB), Total: 0.63 MB, FLOPs: 17,412,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1597/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1597\n",
      "\n",
      "Iteration 1598 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.077 MB, Params: 143,131 (0.546 MB), Total: 0.62 MB, FLOPs: 17,405,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1598/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1598\n",
      "\n",
      "Iteration 1599 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.077 MB, Params: 142,567 (0.544 MB), Total: 0.62 MB, FLOPs: 17,399,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1599/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1599\n",
      "\n",
      "Iteration 1600 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.077 MB, Params: 142,003 (0.542 MB), Total: 0.62 MB, FLOPs: 17,392,288\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1600/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1600\n",
      "\n",
      "Iteration 1601 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 141,439 (0.540 MB), Total: 0.62 MB, FLOPs: 17,385,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1601/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1601\n",
      "\n",
      "Iteration 1602 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.077 MB, Params: 140,492 (0.536 MB), Total: 0.61 MB, FLOPs: 17,360,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1602/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1602\n",
      "\n",
      "Iteration 1603 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.077 MB, Params: 139,842 (0.533 MB), Total: 0.61 MB, FLOPs: 17,329,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1603/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1603\n",
      "\n",
      "Iteration 1604 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 138,904 (0.530 MB), Total: 0.61 MB, FLOPs: 17,304,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1604/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1604\n",
      "\n",
      "Iteration 1605 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.077 MB, Params: 138,263 (0.527 MB), Total: 0.60 MB, FLOPs: 17,273,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1605/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1605\n",
      "\n",
      "Iteration 1606 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.077 MB, Params: 137,699 (0.525 MB), Total: 0.60 MB, FLOPs: 17,266,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1606/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1606\n",
      "\n",
      "Iteration 1607 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.077 MB, Params: 137,265 (0.524 MB), Total: 0.60 MB, FLOPs: 17,180,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1607/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1607\n",
      "\n",
      "Iteration 1608 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 135,859 (0.518 MB), Total: 0.60 MB, FLOPs: 17,163,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1608/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1608\n",
      "\n",
      "Iteration 1609 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.077 MB, Params: 135,304 (0.516 MB), Total: 0.59 MB, FLOPs: 17,156,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1609/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1609\n",
      "\n",
      "Iteration 1610 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.077 MB, Params: 134,627 (0.514 MB), Total: 0.59 MB, FLOPs: 17,077,260\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1610/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1610\n",
      "\n",
      "Iteration 1611 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.077 MB, Params: 133,707 (0.510 MB), Total: 0.59 MB, FLOPs: 17,052,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1611/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1611\n",
      "\n",
      "Iteration 1612 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 132,787 (0.507 MB), Total: 0.58 MB, FLOPs: 17,028,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1612/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1612\n",
      "\n",
      "Iteration 1613 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.077 MB, Params: 132,232 (0.504 MB), Total: 0.58 MB, FLOPs: 17,021,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1613/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1613\n",
      "\n",
      "Iteration 1614 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.077 MB, Params: 131,312 (0.501 MB), Total: 0.58 MB, FLOPs: 16,997,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1614/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1614\n",
      "\n",
      "Iteration 1615 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.077 MB, Params: 130,392 (0.497 MB), Total: 0.57 MB, FLOPs: 16,973,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1615/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1615\n",
      "\n",
      "Iteration 1616 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 129,715 (0.495 MB), Total: 0.57 MB, FLOPs: 16,893,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1616/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1616\n",
      "\n",
      "Iteration 1617 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.077 MB, Params: 129,128 (0.493 MB), Total: 0.57 MB, FLOPs: 16,865,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1617/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1617\n",
      "\n",
      "Iteration 1618 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.077 MB, Params: 128,573 (0.490 MB), Total: 0.57 MB, FLOPs: 16,858,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1618/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1618\n",
      "\n",
      "Iteration 1619 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.077 MB, Params: 128,018 (0.488 MB), Total: 0.57 MB, FLOPs: 16,852,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1619/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1619\n",
      "\n",
      "Iteration 1620 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 127,463 (0.486 MB), Total: 0.56 MB, FLOPs: 16,845,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1620/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1620\n",
      "\n",
      "Iteration 1621 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.077 MB, Params: 126,908 (0.484 MB), Total: 0.56 MB, FLOPs: 16,839,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1621/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1621\n",
      "\n",
      "Iteration 1622 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.077 MB, Params: 126,353 (0.482 MB), Total: 0.56 MB, FLOPs: 16,832,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1622/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1622\n",
      "\n",
      "Iteration 1623 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.077 MB, Params: 125,798 (0.480 MB), Total: 0.56 MB, FLOPs: 16,825,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1623/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1623\n",
      "\n",
      "Iteration 1624 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.077 MB, Params: 125,211 (0.478 MB), Total: 0.55 MB, FLOPs: 16,797,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1624/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1624\n",
      "\n",
      "Iteration 1625 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.077 MB, Params: 124,552 (0.475 MB), Total: 0.55 MB, FLOPs: 16,719,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1625/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1625\n",
      "\n",
      "Iteration 1626 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 2)]\n",
      "Input: 0.077 MB, Params: 123,893 (0.473 MB), Total: 0.55 MB, FLOPs: 16,640,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1626/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1626\n",
      "\n",
      "Iteration 1627 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 61)]\n",
      "Input: 0.077 MB, Params: 123,338 (0.470 MB), Total: 0.55 MB, FLOPs: 16,634,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1627/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1627\n",
      "\n",
      "Iteration 1628 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 1)]\n",
      "Input: 0.077 MB, Params: 123,147 (0.470 MB), Total: 0.55 MB, FLOPs: 16,455,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1628/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1628\n",
      "\n",
      "Iteration 1629 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.077 MB, Params: 122,592 (0.468 MB), Total: 0.54 MB, FLOPs: 16,448,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1629/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1629\n",
      "\n",
      "Iteration 1630 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.077 MB, Params: 122,194 (0.466 MB), Total: 0.54 MB, FLOPs: 16,369,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1630/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1630\n",
      "\n",
      "Iteration 1631 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 120,914 (0.461 MB), Total: 0.54 MB, FLOPs: 16,353,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1631/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1631\n",
      "\n",
      "Iteration 1632 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.077 MB, Params: 119,634 (0.456 MB), Total: 0.53 MB, FLOPs: 16,338,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1632/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1632\n",
      "\n",
      "Iteration 1633 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.077 MB, Params: 119,065 (0.454 MB), Total: 0.53 MB, FLOPs: 16,311,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1633/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1633\n",
      "\n",
      "Iteration 1634 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.077 MB, Params: 118,496 (0.452 MB), Total: 0.53 MB, FLOPs: 16,283,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1634/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1634\n",
      "\n",
      "Iteration 1635 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 117,216 (0.447 MB), Total: 0.52 MB, FLOPs: 16,268,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1635/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1635\n",
      "\n",
      "Iteration 1636 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.077 MB, Params: 115,936 (0.442 MB), Total: 0.52 MB, FLOPs: 16,253,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1636/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1636\n",
      "\n",
      "Iteration 1637 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 115,088 (0.439 MB), Total: 0.52 MB, FLOPs: 16,230,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1637/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1637\n",
      "\n",
      "Iteration 1638 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 10)]\n",
      "Input: 0.077 MB, Params: 114,897 (0.438 MB), Total: 0.52 MB, FLOPs: 16,051,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1638/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1638\n",
      "\n",
      "Iteration 1639 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 22)]\n",
      "Input: 0.077 MB, Params: 114,499 (0.437 MB), Total: 0.51 MB, FLOPs: 15,972,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1639/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1639\n",
      "\n",
      "Iteration 1640 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.077 MB, Params: 113,980 (0.435 MB), Total: 0.51 MB, FLOPs: 15,966,072\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1640/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1640\n",
      "\n",
      "Iteration 1641 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.077 MB, Params: 113,461 (0.433 MB), Total: 0.51 MB, FLOPs: 15,959,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1641/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1641\n",
      "\n",
      "Iteration 1642 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.077 MB, Params: 112,208 (0.428 MB), Total: 0.50 MB, FLOPs: 15,944,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1642/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1642\n",
      "\n",
      "Iteration 1643 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.077 MB, Params: 111,369 (0.425 MB), Total: 0.50 MB, FLOPs: 15,922,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1643/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1643\n",
      "\n",
      "Iteration 1644 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 3)]\n",
      "Input: 0.077 MB, Params: 110,746 (0.422 MB), Total: 0.50 MB, FLOPs: 15,848,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1644/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1644\n",
      "\n",
      "Iteration 1645 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 110,357 (0.421 MB), Total: 0.50 MB, FLOPs: 15,771,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1645/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1645\n",
      "\n",
      "Iteration 1646 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.077 MB, Params: 109,113 (0.416 MB), Total: 0.49 MB, FLOPs: 15,756,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1646/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1646\n",
      "\n",
      "Iteration 1647 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 108,283 (0.413 MB), Total: 0.49 MB, FLOPs: 15,734,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1647/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1647\n",
      "\n",
      "Iteration 1648 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.077 MB, Params: 107,453 (0.410 MB), Total: 0.49 MB, FLOPs: 15,712,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1648/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1648\n",
      "\n",
      "Iteration 1649 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 106,623 (0.407 MB), Total: 0.48 MB, FLOPs: 15,690,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1649/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1649\n",
      "\n",
      "Iteration 1650 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.077 MB, Params: 106,108 (0.405 MB), Total: 0.48 MB, FLOPs: 15,665,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1650/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1650\n",
      "\n",
      "Iteration 1651 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.077 MB, Params: 104,891 (0.400 MB), Total: 0.48 MB, FLOPs: 15,650,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1651/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1651\n",
      "\n",
      "Iteration 1652 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.077 MB, Params: 104,376 (0.398 MB), Total: 0.48 MB, FLOPs: 15,626,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1652/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1652\n",
      "\n",
      "Iteration 1653 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.077 MB, Params: 103,573 (0.395 MB), Total: 0.47 MB, FLOPs: 15,605,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1653/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1653\n",
      "\n",
      "Iteration 1654 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.077 MB, Params: 103,081 (0.393 MB), Total: 0.47 MB, FLOPs: 15,599,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1654/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1654\n",
      "\n",
      "Iteration 1655 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.077 MB, Params: 102,589 (0.391 MB), Total: 0.47 MB, FLOPs: 15,593,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1655/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1655\n",
      "\n",
      "Iteration 1656 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 2)]\n",
      "Input: 0.077 MB, Params: 102,128 (0.390 MB), Total: 0.47 MB, FLOPs: 15,392,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1656/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1656\n",
      "\n",
      "Iteration 1657 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.077 MB, Params: 101,937 (0.389 MB), Total: 0.47 MB, FLOPs: 15,212,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1657/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1657\n",
      "\n",
      "Iteration 1658 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.077 MB, Params: 101,445 (0.387 MB), Total: 0.46 MB, FLOPs: 15,206,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1658/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1658\n",
      "\n",
      "Iteration 1659 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.077 MB, Params: 101,137 (0.386 MB), Total: 0.46 MB, FLOPs: 14,961,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1659/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1659\n",
      "\n",
      "Iteration 1660 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.077 MB, Params: 99,956 (0.381 MB), Total: 0.46 MB, FLOPs: 14,947,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1660/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1660\n",
      "\n",
      "Iteration 1661 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.077 MB, Params: 99,450 (0.379 MB), Total: 0.46 MB, FLOPs: 14,922,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1661/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1661\n",
      "\n",
      "Iteration 1662 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.077 MB, Params: 98,967 (0.378 MB), Total: 0.45 MB, FLOPs: 14,917,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1662/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1662\n",
      "\n",
      "Iteration 1663 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 98,461 (0.376 MB), Total: 0.45 MB, FLOPs: 14,892,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1663/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1663\n",
      "\n",
      "Iteration 1664 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 5)]\n",
      "Input: 0.077 MB, Params: 98,153 (0.374 MB), Total: 0.45 MB, FLOPs: 14,647,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1664/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1664\n",
      "\n",
      "Iteration 1665 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.077 MB, Params: 97,670 (0.373 MB), Total: 0.45 MB, FLOPs: 14,641,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1665/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1665\n",
      "\n",
      "Iteration 1666 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.077 MB, Params: 97,187 (0.371 MB), Total: 0.45 MB, FLOPs: 14,635,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1666/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1666\n",
      "\n",
      "Iteration 1667 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.077 MB, Params: 96,704 (0.369 MB), Total: 0.45 MB, FLOPs: 14,630,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1667/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1667\n",
      "\n",
      "Iteration 1668 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.077 MB, Params: 95,928 (0.366 MB), Total: 0.44 MB, FLOPs: 14,610,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1668/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1668\n",
      "\n",
      "Iteration 1669 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.077 MB, Params: 95,445 (0.364 MB), Total: 0.44 MB, FLOPs: 14,604,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1669/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1669\n",
      "\n",
      "Iteration 1670 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.077 MB, Params: 94,318 (0.360 MB), Total: 0.44 MB, FLOPs: 14,590,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1670/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1670\n",
      "\n",
      "Iteration 1671 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 3)]\n",
      "Input: 0.077 MB, Params: 93,740 (0.358 MB), Total: 0.43 MB, FLOPs: 14,520,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1671/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1671\n",
      "\n",
      "Iteration 1672 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 92,613 (0.353 MB), Total: 0.43 MB, FLOPs: 14,506,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1672/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1672\n",
      "\n",
      "Iteration 1673 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 91,855 (0.350 MB), Total: 0.43 MB, FLOPs: 14,486,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1673/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1673\n",
      "\n",
      "Iteration 1674 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 11)]\n",
      "Input: 0.077 MB, Params: 91,547 (0.349 MB), Total: 0.43 MB, FLOPs: 14,241,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1674/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1674\n",
      "\n",
      "Iteration 1675 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.077 MB, Params: 90,789 (0.346 MB), Total: 0.42 MB, FLOPs: 14,221,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1675/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1675\n",
      "\n",
      "Iteration 1676 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.077 MB, Params: 90,324 (0.345 MB), Total: 0.42 MB, FLOPs: 14,215,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1676/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1676\n",
      "\n",
      "Iteration 1677 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.077 MB, Params: 89,224 (0.340 MB), Total: 0.42 MB, FLOPs: 14,202,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1677/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1677\n",
      "\n",
      "Iteration 1678 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 6)]\n",
      "Input: 0.077 MB, Params: 88,853 (0.339 MB), Total: 0.42 MB, FLOPs: 14,128,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1678/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1678\n",
      "\n",
      "Iteration 1679 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.077 MB, Params: 88,397 (0.337 MB), Total: 0.41 MB, FLOPs: 14,123,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1679/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1679\n",
      "\n",
      "Iteration 1680 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.077 MB, Params: 87,306 (0.333 MB), Total: 0.41 MB, FLOPs: 14,110,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1680/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1680\n",
      "\n",
      "Iteration 1681 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 86,836 (0.331 MB), Total: 0.41 MB, FLOPs: 14,087,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1681/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1681\n",
      "\n",
      "Iteration 1682 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.077 MB, Params: 86,672 (0.331 MB), Total: 0.41 MB, FLOPs: 13,930,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1682/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1682\n",
      "\n",
      "Iteration 1683 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 85,941 (0.328 MB), Total: 0.40 MB, FLOPs: 13,910,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1683/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1683\n",
      "\n",
      "Iteration 1684 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 8)]\n",
      "Input: 0.077 MB, Params: 85,777 (0.327 MB), Total: 0.40 MB, FLOPs: 13,753,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1684/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1684\n",
      "\n",
      "Iteration 1685 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 85,046 (0.324 MB), Total: 0.40 MB, FLOPs: 13,734,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1685/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1685\n",
      "\n",
      "Iteration 1686 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.077 MB, Params: 84,594 (0.323 MB), Total: 0.40 MB, FLOPs: 13,712,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1686/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1686\n",
      "\n",
      "Iteration 1687 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.077 MB, Params: 84,147 (0.321 MB), Total: 0.40 MB, FLOPs: 13,707,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1687/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1687\n",
      "\n",
      "Iteration 1688 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.077 MB, Params: 83,083 (0.317 MB), Total: 0.39 MB, FLOPs: 13,694,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1688/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1688\n",
      "\n",
      "Iteration 1689 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.077 MB, Params: 82,631 (0.315 MB), Total: 0.39 MB, FLOPs: 13,672,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1689/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1689\n",
      "\n",
      "Iteration 1690 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.077 MB, Params: 82,260 (0.314 MB), Total: 0.39 MB, FLOPs: 13,598,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1690/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1690\n",
      "\n",
      "Iteration 1691 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 81,196 (0.310 MB), Total: 0.39 MB, FLOPs: 13,585,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1691/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1691\n",
      "\n",
      "Iteration 1692 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 80,501 (0.307 MB), Total: 0.38 MB, FLOPs: 13,567,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1692/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1692\n",
      "\n",
      "Iteration 1693 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.077 MB, Params: 80,072 (0.305 MB), Total: 0.38 MB, FLOPs: 13,562,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1693/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1693\n",
      "\n",
      "Iteration 1694 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.077 MB, Params: 79,026 (0.301 MB), Total: 0.38 MB, FLOPs: 13,550,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1694/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1694\n",
      "\n",
      "Iteration 1695 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.077 MB, Params: 78,340 (0.299 MB), Total: 0.38 MB, FLOPs: 13,532,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1695/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1695\n",
      "\n",
      "Iteration 1696 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.077 MB, Params: 77,654 (0.296 MB), Total: 0.37 MB, FLOPs: 13,514,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1696/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1696\n",
      "\n",
      "Iteration 1697 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.077 MB, Params: 77,234 (0.295 MB), Total: 0.37 MB, FLOPs: 13,509,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1697/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1697\n",
      "\n",
      "Iteration 1698 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.077 MB, Params: 76,809 (0.293 MB), Total: 0.37 MB, FLOPs: 13,488,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1698/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1698\n",
      "\n",
      "Iteration 1699 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 15)]\n",
      "Input: 0.077 MB, Params: 76,393 (0.291 MB), Total: 0.37 MB, FLOPs: 13,312,572\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1699/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1699\n",
      "\n",
      "Iteration 1700 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 75,716 (0.289 MB), Total: 0.37 MB, FLOPs: 13,294,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1700/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1700\n",
      "\n",
      "Iteration 1701 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 75,039 (0.286 MB), Total: 0.36 MB, FLOPs: 13,277,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1701/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1701\n",
      "\n",
      "Iteration 1702 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.077 MB, Params: 74,619 (0.285 MB), Total: 0.36 MB, FLOPs: 13,272,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1702/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1702\n",
      "\n",
      "Iteration 1703 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.077 MB, Params: 73,627 (0.281 MB), Total: 0.36 MB, FLOPs: 13,260,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1703/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1703\n",
      "\n",
      "Iteration 1704 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.077 MB, Params: 72,635 (0.277 MB), Total: 0.35 MB, FLOPs: 13,248,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1704/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1704\n",
      "\n",
      "Iteration 1705 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 72,228 (0.276 MB), Total: 0.35 MB, FLOPs: 13,229,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1705/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1705\n",
      "\n",
      "Iteration 1706 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.077 MB, Params: 71,866 (0.274 MB), Total: 0.35 MB, FLOPs: 13,156,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1706/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1706\n",
      "\n",
      "Iteration 1707 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.077 MB, Params: 71,464 (0.273 MB), Total: 0.35 MB, FLOPs: 13,152,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1707/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1707\n",
      "\n",
      "Iteration 1708 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 70,814 (0.270 MB), Total: 0.35 MB, FLOPs: 13,135,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1708/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1708\n",
      "\n",
      "Iteration 1709 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.077 MB, Params: 70,308 (0.268 MB), Total: 0.35 MB, FLOPs: 13,072,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 1709/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1709\n",
      "\n",
      "Iteration 1710 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 68)]\n",
      "Input: 0.077 MB, Params: 69,906 (0.267 MB), Total: 0.34 MB, FLOPs: 13,067,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1710/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1710\n",
      "\n",
      "Iteration 1711 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.077 MB, Params: 69,504 (0.265 MB), Total: 0.34 MB, FLOPs: 13,062,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1711/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1711\n",
      "\n",
      "Iteration 1712 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.077 MB, Params: 68,854 (0.263 MB), Total: 0.34 MB, FLOPs: 13,045,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1712/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1712\n",
      "\n",
      "Iteration 1713 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.077 MB, Params: 68,204 (0.260 MB), Total: 0.34 MB, FLOPs: 13,028,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1713/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1713\n",
      "\n",
      "Iteration 1714 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.077 MB, Params: 67,833 (0.259 MB), Total: 0.34 MB, FLOPs: 13,011,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1714/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1714\n",
      "\n",
      "Iteration 1715 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.077 MB, Params: 67,336 (0.257 MB), Total: 0.33 MB, FLOPs: 12,948,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1715/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1715\n",
      "\n",
      "Iteration 1716 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.077 MB, Params: 66,934 (0.255 MB), Total: 0.33 MB, FLOPs: 12,943,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1716/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1716\n",
      "\n",
      "Iteration 1717 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.077 MB, Params: 66,437 (0.253 MB), Total: 0.33 MB, FLOPs: 12,881,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1717/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1717\n",
      "\n",
      "Iteration 1718 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.077 MB, Params: 65,508 (0.250 MB), Total: 0.33 MB, FLOPs: 12,870,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1718/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1718\n",
      "\n",
      "Iteration 1719 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.077 MB, Params: 65,115 (0.248 MB), Total: 0.33 MB, FLOPs: 12,865,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1719/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1719\n",
      "\n",
      "Iteration 1720 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 6)]\n",
      "Input: 0.077 MB, Params: 64,951 (0.248 MB), Total: 0.32 MB, FLOPs: 12,707,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.973%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 1720/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1720\n",
      "\n",
      "Iteration 1721 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.077 MB, Params: 64,616 (0.246 MB), Total: 0.32 MB, FLOPs: 12,641,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1721/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1721\n",
      "\n",
      "Iteration 1722 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.077 MB, Params: 64,223 (0.245 MB), Total: 0.32 MB, FLOPs: 12,636,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1722/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1722\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 20150)     (6, 1, 10071)         54      543,834\n",
      "  BatchNorm2d-2     (6, 1, 10071)     (6, 1, 10071)         12            0\n",
      "         ReLu-3     (6, 1, 10071)     (6, 1, 10071)          0       60,426\n",
      "       Conv2d-4     (6, 1, 10071)     (32, 1, 5034)        960    4,832,640\n",
      "  BatchNorm2d-5     (32, 1, 5034)     (32, 1, 5034)         64            0\n",
      "         ReLu-6     (32, 1, 5034)     (32, 1, 5034)          0      161,088\n",
      "    MaxPool2d-7     (32, 1, 5034)      (32, 1, 100)          0      160,000\n",
      "      Permute-8      (32, 1, 100)      (1, 32, 100)          0            0\n",
      "       Conv2d-9      (1, 32, 100)     (12, 32, 100)        108      345,600\n",
      " BatchNorm2d-10     (12, 32, 100)     (12, 32, 100)         24            0\n",
      "        ReLu-11     (12, 32, 100)     (12, 32, 100)          0       38,400\n",
      "   MaxPool2d-12     (12, 32, 100)      (12, 16, 50)          0       38,400\n",
      "      Conv2d-13      (12, 16, 50)      (17, 16, 50)      1,836    1,468,800\n",
      " BatchNorm2d-14      (17, 16, 50)      (17, 16, 50)         34            0\n",
      "        ReLu-15      (17, 16, 50)      (17, 16, 50)          0       13,600\n",
      "      Conv2d-16      (17, 16, 50)      (18, 16, 50)      2,754    2,203,200\n",
      " BatchNorm2d-17      (18, 16, 50)      (18, 16, 50)         36            0\n",
      "        ReLu-18      (18, 16, 50)      (18, 16, 50)          0       14,400\n",
      "   MaxPool2d-19      (18, 16, 50)       (18, 8, 25)          0       14,400\n",
      "      Conv2d-20       (18, 8, 25)       (27, 8, 25)      4,374      874,800\n",
      " BatchNorm2d-21       (27, 8, 25)       (27, 8, 25)         54            0\n",
      "        ReLu-22       (27, 8, 25)       (27, 8, 25)          0        5,400\n",
      "      Conv2d-23       (27, 8, 25)       (19, 8, 25)      4,617      923,400\n",
      " BatchNorm2d-24       (19, 8, 25)       (19, 8, 25)         38            0\n",
      "        ReLu-25       (19, 8, 25)       (19, 8, 25)          0        3,800\n",
      "   MaxPool2d-26       (19, 8, 25)       (19, 4, 12)          0        3,648\n",
      "      Conv2d-27       (19, 4, 12)       (27, 4, 12)      4,617      221,616\n",
      " BatchNorm2d-28       (27, 4, 12)       (27, 4, 12)         54            0\n",
      "        ReLu-29       (27, 4, 12)       (27, 4, 12)          0        1,296\n",
      "      Conv2d-30       (27, 4, 12)       (20, 4, 12)      4,860      233,280\n",
      " BatchNorm2d-31       (20, 4, 12)       (20, 4, 12)         40            0\n",
      "        ReLu-32       (20, 4, 12)       (20, 4, 12)          0          960\n",
      "   MaxPool2d-33       (20, 4, 12)        (20, 2, 6)          0          960\n",
      "      Conv2d-34        (20, 2, 6)        (43, 2, 6)      7,740       92,880\n",
      " BatchNorm2d-35        (43, 2, 6)        (43, 2, 6)         86            0\n",
      "        ReLu-36        (43, 2, 6)        (43, 2, 6)          0          516\n",
      "      Conv2d-37        (43, 2, 6)        (81, 2, 6)     31,347      376,164\n",
      " BatchNorm2d-38        (81, 2, 6)        (81, 2, 6)        162            0\n",
      "        ReLu-39        (81, 2, 6)        (81, 2, 6)          0          972\n",
      "   MaxPool2d-40        (81, 2, 6)        (81, 1, 3)          0          972\n",
      "      Conv2d-41        (81, 1, 3)         (4, 1, 3)        324          972\n",
      " BatchNorm2d-42         (4, 1, 3)         (4, 1, 3)          8            0\n",
      "        ReLu-43         (4, 1, 3)         (4, 1, 3)          0           12\n",
      "   AvgPool2d-44         (4, 1, 3)         (4, 1, 1)          0           12\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 64,223\n",
      "Total FLOPs : 12,636,472\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.08\n",
      "Params size (MB): 0.24\n",
      "Total size (MB) : 0.32\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
