{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bf6d57-a4ca-466b-8573-c0136beedc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import glob;\n",
    "import random;\n",
    "import time;\n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "import json\n",
    "sys.path.append(os.getcwd());\n",
    "sys.path.append('../../../');\n",
    "sys.path.append(os.path.abspath('../../../src/'));\n",
    "# sys.path.append(os.path.join(os.getcwd(), 'torch/resources'));\n",
    "import common.utils as U;\n",
    "import common.opts as opts;\n",
    "# import resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "import common.tlopts as tlopts\n",
    "# import resources.train_generator as train_generator;\n",
    "import argparse\n",
    "from itertools import repeat\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7689e377-b82a-49c3-ad0e-39c577601df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SharedLibs.config_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8275f2-c36a-4364-af02-50f1a95649af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ca33aa-674b-4dd7-811d-7ef3b6837698",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sec_input_len = 20150;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28c39e16-406e-4d15-892b-d2253acc7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_layers(in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "#     conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "#     nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "#     bn = nn.BatchNorm2d(out_channels);\n",
    "#     return conv, bn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c90a575-6a3b-4d89-8639-10db9fb57bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a170c226-560a-4aa6-8800-85d3a22c0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59e4bd5d-11ac-4a64-b653-95a6d4a49eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChkAndCreateSingleDir(dir_path):\n",
    "    if not pathlib.Path(dir_path).is_dir():\n",
    "        os.mkdir(dir_path);\n",
    "        print(f\"'{dir_path}' folder is created.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c29566-7f50-4ce7-bcbc-bc4cc181613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logObj = None;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d912792-acf8-455f-b151-a239265a2d33",
   "metadata": {},
   "source": [
    "## define ACDNet Fundamental Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0a2923-8e53-4dc7-884d-2d00d079c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "#GetACDNetModel中的nclass不能改50以外的值，因為pretrain model本來的分類為50，載入後，下面的函式會再改動後面的分類。\n",
    "def GetACDNetModel(input_len=30225, nclass=50, sr=20000, channel_config=None):\n",
    "    net = ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b962632-05bd-4265-86ba-3fac7ea1b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net  = GetACDNetModel(input_len=one_sec_input_len, nclass=4, sr=20000, channel_config=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b3e4f5-16ce-40da-ad20-932fe55c3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc.summary(net, (1,1,one_sec_input_len));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb748e-ab69-4fe8-b773-474ef698f777",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ade142-c4e4-48b9-8c71-2e28c1828137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples=None, labels=None, options=None, classes_dict=None):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        # print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = classes_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        # batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX, batchY = self.generate_batch_select_fixed_class(batchIndex)\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            # print(f\"nClasses:{self.opt.nClasses}, type of mapdict:{type(self.mapdict)}, type of label1:{type(label1)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        return sounds, labels;\n",
    "\n",
    "    def generate_batch_select_fixed_class(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        #two variables recording alarm and moaning sounds count\n",
    "        alarm_selected = 0;\n",
    "        moaning_selected = 0;\n",
    "        help_eng_selected = 0;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                # print(\"enter while true\")\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                lbl1_int = np.int16(label1);\n",
    "                lbl2_int = np.int16(label2);\n",
    "                # print(f\"label1:{label1} and label2:{label2}\")\n",
    "                # print(f\"label1:{type(label1)} and label2:{type(label2)}\")\n",
    "                if label1 != label2:\n",
    "                    # print(\"enter first layer if\");\n",
    "                    if (lbl1_int == 52 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int ==52):\n",
    "                        # print(\"enter 52 second layer if\");\n",
    "                        # if (alarm_selected < moaning_selected) or (alarm_selected == moaning_selected):\n",
    "                        if (alarm_selected == moaning_selected) and (alarm_selected == help_eng_selected):\n",
    "                            # print(\"enter 52 third layer if\");\n",
    "                            alarm_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 52\");\n",
    "                            break;\n",
    "                    if (lbl1_int == 56 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 56):\n",
    "                        # print(\"enter 56 second layer if\");\n",
    "                        # if (moaning_selected < alarm_selected) or (alarm_selected == moaning_selected):\n",
    "                        if (moaning_selected < alarm_selected) and (moaning_selected == help_eng_selected):\n",
    "                            # print(\"enter 56 third layer if\");\n",
    "                            moaning_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 56\");\n",
    "                            break;\n",
    "                    if (lbl1_int == 71 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 71):\n",
    "                        # print(\"enter 56 second layer if\");\n",
    "                        if (help_eng_selected < alarm_selected) and (help_eng_selected < moaning_selected):\n",
    "                            # print(\"enter 56 third layer if\");\n",
    "                            help_eng_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 56\");\n",
    "                            break;\n",
    "            # print(f\"escape for loop\");\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random());\n",
    "            #######make wanted class mix ration above 0.5##########\n",
    "            # iLbl1 = np.int16(label1);\n",
    "            # iLbl2 = np.int16(label2);\n",
    "            # r = 1.0;\n",
    "            # p_ratio1 = 0.4\n",
    "            # p_ratio2 = 0.6\n",
    "            # while True:\n",
    "            #     r = np.array(random.random());\n",
    "            #     if r > p_ratio1 and iLbl1 != 99 :\n",
    "            #         break;\n",
    "            #     if r < p_ratio2 and iLbl2 != 99 :\n",
    "            #         break;\n",
    "            #######################End#######################\n",
    "            # print(f\"r:{r}, lbl1:{label1}, lbl2:{label2}\")  \n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            \n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        # print(f\"alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "        return sounds, labels;\n",
    "    \n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2), # or use U.padding((0,self.opt.inputLength // 2))\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b21d70d-b5b1-4711-aa59-d943d1222064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, fold=None, classes_dict=None):\n",
    "    dataset = np.load(opt.trainData, allow_pickle=True);\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    # train_sounds = dataset['fold1'].item()['sounds']\n",
    "    # train_labels = dataset['fold1'].item()['labels']\n",
    "    train_sounds = dataset[fold].item()['sounds']\n",
    "    train_labels = dataset[fold].item()['labels']\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt, classes_dict=classes_dict);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523a36e-96c9-4539-b18f-13eca354ef11",
   "metadata": {},
   "source": [
    "## training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88f76e6c-ae8b-483b-804f-0ffb83f3a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args();\n",
    "    \n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 64;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-4#9e-3;#5e-3;#5e-2;#1e-2;#5e-4;\n",
    "    opt.momentum = 0.9;\n",
    "    opt.nEpochs = 1800;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    print(f\"***Use device:{opt.device}\");\n",
    "    # opt.device = torch.device(\"cuda:0\" if  else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 4#50;\n",
    "    opt.nFolds = 1;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 20150;#30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.TLAcdnetConfig = [8,64,32,64,64,128,128,256,256,512,512,4];\n",
    "    return opt\n",
    "    # opt = parser.parse_args();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d35d9-15ab-494d-b086-f98a6b5042ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35b7aeaf-e110-487a-9320-0f32ff90c52d",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602db74f-1475-4948-b46f-303661981bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLTrainer:\n",
    "    global logObj;\n",
    "    def __init__(self, opt=None, fold=None, classes_dict=None):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "        self.current_fold = fold;\n",
    "        self.trainGen = getTrainGen(opt,fold=fold, classes_dict=classes_dict)#train_generator.setup(opt, split);\n",
    "\n",
    "    def Train(self):\n",
    "        train_start_time = time.time();\n",
    "        net = GetACDNetModel(input_len=self.opt.inputLength, nclass=4, sr=20000, channel_config=None).to(self.opt.device);\n",
    "        #print networks parameters' require_grade value\n",
    "        for k_, v_ in net.named_parameters():\n",
    "            print(f\"{k_}:{v_.requires_grad}\")\n",
    "        print('ACDNet model has been prepared for training');\n",
    "\n",
    "        calc.summary(net, (1,1,self.opt.inputLength));\n",
    "\n",
    "        # training_text = \"Re-Training\" if self.opt.retrain else \"Training from Scratch\";\n",
    "        # print(\"{} has been started. You will see update after finishing every training epoch and validation\".format(training_text));\n",
    "\n",
    "        lossFunc = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True);\n",
    "\n",
    "        # self.opt.nEpochs = 1957 if self.opt.split == 4 else 2000;\n",
    "        for epochIdx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epochIdx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            for batchIdx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batchIdx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "                y = torch.tensor(y).to(self.opt.device);\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(x);\n",
    "                running_acc += (((outputs.data.argmax(dim=1) == y.argmax(dim=1))*1).float().mean()).item();\n",
    "                loss = lossFunc(outputs.log(), y);\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                running_loss += loss.item();\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, lossFunc);\n",
    "            #Save best model\n",
    "            # self.__save_model(val_acc, epochIdx, net);\n",
    "            self.__save_model_refined(val_acc, tr_acc, epochIdx, net);\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epochIdx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - train_start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "    def load_test_data(self):\n",
    "        # data = np.load(os.path.join(self.opt.data, self.opt.dataset, 'test_data_{}khz/fold{}_test4000.npz'.format(self.opt.sr//1000, self.opt.split)), allow_pickle=True);\n",
    "        data = np.load(self.opt.testData, allow_pickle=True);\n",
    "        print(f\"device is :{self.opt.device}\")\n",
    "        print(f\"len of Y:{len(data['y'])}\")\n",
    "        # self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "        dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "        self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "        self.testY = torch.tensor(data['y']).type(torch.float32).to(self.opt.device);\n",
    "\n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __get_batch(self, index):\n",
    "        x = self.trainX[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        y = self.trainY[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        return x.to(self.opt.device), y.to(self.opt.device);\n",
    "\n",
    "    def __validate(self, net, lossFunc):\n",
    "        if self.testX is None:\n",
    "            self.load_test_data();\n",
    "        net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = len(self.testX);\n",
    "            x = self.testX[:];\n",
    "            scores = net(x);\n",
    "            y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "            acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "        net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        # print(f\"shape of y_pred:{y_pred.shape}\");\n",
    "        # print(f\"shape of y_target:{y_target.shape}\");\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            if self.opt.nCrops == 1:\n",
    "                y_pred = y_pred.argmax(dim=1);\n",
    "                y_target = y_target.argmax(dim=1);\n",
    "            else:\n",
    "                y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                print(f\"after: len of y_pred:{len(y_pred)}, len of y_target:{len(y_target)}\")\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def __on_epoch_end(self, start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        line = 'SP-{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.splits, epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "        logObj.write(line);\n",
    "        logObj.write(\"\\n\");\n",
    "        logObj.flush();\n",
    "\n",
    "    # def __save_model(self, acc, epochIdx, net):\n",
    "    #     print(\"__save_model is called\")\n",
    "    #     print(f\"current best Acc is {self.bestAcc}\")\n",
    "    #     print(f\"pass in acc is {acc}\")\n",
    "    #     if acc > self.bestAcc or acc > 95.0:\n",
    "    #         dir = os.getcwd();\n",
    "    #         model_name = self.opt.model_name.format(genDataTimeStr(),acc,epochIdx);\n",
    "    #         save_path = os.path.join(self.opt.modelSaveDir,model_name);\n",
    "    #         self.bestAcc = acc;\n",
    "    #         self.bestAccEpoch = epochIdx +1;\n",
    "    #         torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_path);\n",
    "    #         print(f\"model saved....., acc: {acc}\")\n",
    "    #         logObj.write(f\"save model:{model_name}, bestAcc:{self.bestAcc}, currentAcc:{acc}@{epochIdx}\");\n",
    "    #         logObj.write(\"\\n\");\n",
    "    #         logObj.flush();\n",
    "    \"\"\"\n",
    "    save_val_acc = 94.0;\n",
    "    opt.save_train_acc=77.0 \n",
    "    \"\"\"\n",
    "\n",
    "    def __save_model_refined(self, acc, train_acc, epochIdx, net):\n",
    "        if acc > self.bestAcc and acc > self.opt.first_save_acc and epochIdx>self.opt.least_save_epoch:\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            self.__do_save_model(acc, train_acc, self.bestAccEpoch, net);\n",
    "        else:\n",
    "            if acc > self.opt.save_val_acc and train_acc > self.opt.save_train_acc and epochIdx>self.opt.least_save_epoch: \n",
    "                self.__do_save_model(acc, train_acc, epochIdx, net);\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def __do_save_model(self, acc, tr_acc, epochIdx, net):\n",
    "        save_model_name = self.opt.model_name.format(self.current_foldm, self.bestAcc, acc, tr_acc, epochIdx);\n",
    "        save_model_fullpath = self.opt.modelSaveDir + save_model_name;\n",
    "        print(f\"save model to {save_model_fullpath}\")\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "        logObj.write(f\"save model:{self.opt.model_name}, bestAcc:{self.bestAcc}, ValAcc:{acc}-TrAcc{tr_acc}-@{epochIdx}\");\n",
    "        logObj.write(\"\\n\");\n",
    "        logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a01216-388b-4f9d-8fc9-b19e6e4c6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================ \n",
    "final acc(highest):train:, val:\n",
    "required grade : True\n",
    "dataset:version11\n",
    "at epochs:\n",
    "opt.batchSize = 64;\n",
    "opt.LR = 0.1;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.momentum = 0.9;\n",
    "opt.nEpochs = 1200;\n",
    "opt.schedule = [0.3, 0.5, 0.9];\n",
    "opt.warmup = 10;\n",
    "================================================\n",
    "final acc(highest):train:, val:\n",
    "required grade : True\n",
    "dataset:version15-fold1\n",
    "train_type:CV\n",
    "at epochs:\n",
    "opt.batchSize = 64;\n",
    "opt.LR = 0.1;\n",
    "opt.weightDecay = 5e-4#9e-3;#5e-3;#5e-2;#1e-2;#5e-4;\n",
    "opt.momentum = 0.9;\n",
    "opt.nEpochs = 1800;\n",
    "opt.schedule = [0.3, 0.5, 0.9];\n",
    "opt.warmup = 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d402a6c-e278-473e-98d1-94b4d25c69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global logObj;\n",
    "    map_dict_train = {\n",
    "        '52':1, #alarm\n",
    "        '56':2, #moaning\n",
    "        '71':3, #english-help-speech\n",
    "        '99':4, #other_sounds\n",
    "    };\n",
    "    opt = getOpts();\n",
    "    opt.sr = 20000;\n",
    "    opt.least_save_epoch = 500;\n",
    "    opt.first_save_acc = 80.0;\n",
    "    opt.save_val_acc = 80.0;\n",
    "    opt.save_train_acc = 85.0;\n",
    "    opt.trainer = None\n",
    "    ###office\n",
    "    # opt.trainData=\"../../../../../uec_iot_models_datasets/version12_4class_onesecond_input_office/single_fold_train_20240619110117.npz\";\n",
    "    # opt.testData=\"../../../../../uec_iot_models_datasets/version12_4class_onesecond_input_office/final_single_val_20240619112602.npz\";\n",
    "    ###home\n",
    "    opt.trainData=\"../../../../uec_iot_dev_training_datasets/generated_datasets/multifold/train/version15_multifold_home_fold1/fold1_train_20240721013720.npz\";\n",
    "    opt.testData=\"../../../../uec_iot_dev_training_datasets/generated_datasets/multifold/val/version15_multifold_home_fold1/final_fold1_val_version15_multifold_home.npz\";\n",
    "    trainStartTime = genDataTimeStr();\n",
    "    current_fold = \"fold1\";\n",
    "    opt.modelSaveDir = \"../../../trained_models/step_1_base_train/multifold/onesecond/base4C_cv_{}_lr{}_bs{}_wd{}_{}/\".format(current_fold,opt.LR, opt.batchSize, opt.weightDecay,trainStartTime);\n",
    "    if not pathlib.Path(opt.modelSaveDir).is_dir():\n",
    "        os.makedirs(opt.modelSaveDir,exist_ok=True);\n",
    "        print(f\"'{opt.modelSaveDir}' is created.\");\n",
    "    tlopts.display_info(opt)\n",
    "    opt.model_name = \"Base4C_{}_hacc{}_valacc_{}_tracc_{}_{}th_epoch.pt\"\n",
    "    ###\n",
    "    logSaveDir = \"./base_cv_training_logs/\"\n",
    "    ChkAndCreateSingleDir(logSaveDir);\n",
    "    logName = \"BaseCVTrainLog_{}.log\".format(trainStartTime);\n",
    "    logObj = open(os.path.join(logSaveDir,logName),'w');\n",
    "    \n",
    "    print(\"Initializing TLTrainer Object.....\")\n",
    "    trainer = TLTrainer(opt,fold=current_fold,classes_dict=map_dict_train)\n",
    "    print(\"Start to training.....\")\n",
    "    trainer.Train();\n",
    "    logObj.flush();\n",
    "    logObj.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd345f7-82eb-4121-9aa2-7ec6c2947be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Use device:mps\n",
      "'../../../trained_models/step_1_base_train/multifold/onesecond/base4C_cv_fold1_lr0.1_bs64_wd0.0005_20240721105739/' is created.\n",
      "+------------------------------+\n",
      "| ACDNet_TL_Model_Extend Sound classification\n",
      "+------------------------------+\n",
      "| dataset  : uec_iot\n",
      "| nEpochs  : 1800\n",
      "| LRInit   : 0.1\n",
      "| batchSize: 64\n",
      "| Momentum   : 0.9\n",
      "| weightDecay: 0.0005\n",
      "| schedule : [0.3, 0.6, 0.9]\n",
      "| warmup   : 10\n",
      "| nFolds: 1\n",
      "| Splits: [1]\n",
      "+------------------------------+\n",
      "Initializing TLTrainer Object.....\n",
      "Start to training.....\n",
      "sfeb.0.weight:True\n",
      "sfeb.1.weight:True\n",
      "sfeb.1.bias:True\n",
      "sfeb.3.weight:True\n",
      "sfeb.4.weight:True\n",
      "sfeb.4.bias:True\n",
      "tfeb.0.weight:True\n",
      "tfeb.1.weight:True\n",
      "tfeb.1.bias:True\n",
      "tfeb.4.weight:True\n",
      "tfeb.5.weight:True\n",
      "tfeb.5.bias:True\n",
      "tfeb.7.weight:True\n",
      "tfeb.8.weight:True\n",
      "tfeb.8.bias:True\n",
      "tfeb.11.weight:True\n",
      "tfeb.12.weight:True\n",
      "tfeb.12.bias:True\n",
      "tfeb.14.weight:True\n",
      "tfeb.15.weight:True\n",
      "tfeb.15.bias:True\n",
      "tfeb.18.weight:True\n",
      "tfeb.19.weight:True\n",
      "tfeb.19.bias:True\n",
      "tfeb.21.weight:True\n",
      "tfeb.22.weight:True\n",
      "tfeb.22.bias:True\n",
      "tfeb.25.weight:True\n",
      "tfeb.26.weight:True\n",
      "tfeb.26.bias:True\n",
      "tfeb.28.weight:True\n",
      "tfeb.29.weight:True\n",
      "tfeb.29.bias:True\n",
      "tfeb.33.weight:True\n",
      "tfeb.34.weight:True\n",
      "tfeb.34.bias:True\n",
      "tfeb.38.weight:True\n",
      "tfeb.38.bias:True\n",
      "ACDNet model has been prepared for training\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 20150)     (8, 1, 10071)         72      725,112\n",
      "  BatchNorm2d-2     (8, 1, 10071)     (8, 1, 10071)         16            0\n",
      "         ReLu-3     (8, 1, 10071)     (8, 1, 10071)          0       80,568\n",
      "       Conv2d-4     (8, 1, 10071)     (64, 1, 5034)      2,560   12,887,040\n",
      "  BatchNorm2d-5     (64, 1, 5034)     (64, 1, 5034)        128            0\n",
      "         ReLu-6     (64, 1, 5034)     (64, 1, 5034)          0      322,176\n",
      "    MaxPool2d-7     (64, 1, 5034)      (64, 1, 100)          0      320,000\n",
      "      Permute-8      (64, 1, 100)      (1, 64, 100)          0            0\n",
      "       Conv2d-9      (1, 64, 100)     (32, 64, 100)        288    1,843,200\n",
      " BatchNorm2d-10     (32, 64, 100)     (32, 64, 100)         64            0\n",
      "        ReLu-11     (32, 64, 100)     (32, 64, 100)          0      204,800\n",
      "   MaxPool2d-12     (32, 64, 100)      (32, 32, 50)          0      204,800\n",
      "      Conv2d-13      (32, 32, 50)      (64, 32, 50)     18,432   29,491,200\n",
      " BatchNorm2d-14      (64, 32, 50)      (64, 32, 50)        128            0\n",
      "        ReLu-15      (64, 32, 50)      (64, 32, 50)          0      102,400\n",
      "      Conv2d-16      (64, 32, 50)      (64, 32, 50)     36,864   58,982,400\n",
      " BatchNorm2d-17      (64, 32, 50)      (64, 32, 50)        128            0\n",
      "        ReLu-18      (64, 32, 50)      (64, 32, 50)          0      102,400\n",
      "   MaxPool2d-19      (64, 32, 50)      (64, 16, 25)          0      102,400\n",
      "      Conv2d-20      (64, 16, 25)     (128, 16, 25)     73,728   29,491,200\n",
      " BatchNorm2d-21     (128, 16, 25)     (128, 16, 25)        256            0\n",
      "        ReLu-22     (128, 16, 25)     (128, 16, 25)          0       51,200\n",
      "      Conv2d-23     (128, 16, 25)     (128, 16, 25)    147,456   58,982,400\n",
      " BatchNorm2d-24     (128, 16, 25)     (128, 16, 25)        256            0\n",
      "        ReLu-25     (128, 16, 25)     (128, 16, 25)          0       51,200\n",
      "   MaxPool2d-26     (128, 16, 25)      (128, 8, 12)          0       49,152\n",
      "      Conv2d-27      (128, 8, 12)      (256, 8, 12)    294,912   28,311,552\n",
      " BatchNorm2d-28      (256, 8, 12)      (256, 8, 12)        512            0\n",
      "        ReLu-29      (256, 8, 12)      (256, 8, 12)          0       24,576\n",
      "      Conv2d-30      (256, 8, 12)      (256, 8, 12)    589,824   56,623,104\n",
      " BatchNorm2d-31      (256, 8, 12)      (256, 8, 12)        512            0\n",
      "        ReLu-32      (256, 8, 12)      (256, 8, 12)          0       24,576\n",
      "   MaxPool2d-33      (256, 8, 12)       (256, 4, 6)          0       24,576\n",
      "      Conv2d-34       (256, 4, 6)       (512, 4, 6)  1,179,648   28,311,552\n",
      " BatchNorm2d-35       (512, 4, 6)       (512, 4, 6)      1,024            0\n",
      "        ReLu-36       (512, 4, 6)       (512, 4, 6)          0       12,288\n",
      "      Conv2d-37       (512, 4, 6)       (512, 4, 6)  2,359,296   56,623,104\n",
      " BatchNorm2d-38       (512, 4, 6)       (512, 4, 6)      1,024            0\n",
      "        ReLu-39       (512, 4, 6)       (512, 4, 6)          0       12,288\n",
      "   MaxPool2d-40       (512, 4, 6)       (512, 2, 3)          0       12,288\n",
      "      Conv2d-41       (512, 2, 3)         (4, 2, 3)      2,048       12,288\n",
      " BatchNorm2d-42         (4, 2, 3)         (4, 2, 3)          8            0\n",
      "        ReLu-43         (4, 2, 3)         (4, 2, 3)          0           24\n",
      "   AvgPool2d-44         (4, 2, 3)         (4, 1, 1)          0           24\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 4,709,204\n",
      "Total FLOPs : 363,985,912\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.08\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.04\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "device is :mps\n",
      "len of Y:352\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 1/1800 | Time: 0m04s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.75  Acc 49.74% | Val: Loss -0.46  Acc(top1) 26.14% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 2/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.70  Acc 51.17% | Val: Loss -0.46  Acc(top1) 26.14% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 3/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.69  Acc 52.34% | Val: Loss -0.46  Acc(top1) 26.14% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 4/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.67  Acc 55.34% | Val: Loss -0.43  Acc(top1) 30.11% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 5/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.67  Acc 53.26% | Val: Loss nan  Acc(top1) 34.09% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 6/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.64  Acc 57.94% | Val: Loss nan  Acc(top1) 34.09% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 7/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.66  Acc 54.69% | Val: Loss nan  Acc(top1) 36.93% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 8/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.62  Acc 56.90% | Val: Loss nan  Acc(top1) 46.59% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 9/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.60  Acc 61.07% | Val: Loss nan  Acc(top1) 37.50% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 10/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.58  Acc 61.33% | Val: Loss nan  Acc(top1) 48.30% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 11/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.70  Acc 51.30% | Val: Loss nan  Acc(top1) 28.41% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 12/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.63  Acc 58.20% | Val: Loss nan  Acc(top1) 44.32% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 13/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.60  Acc 58.85% | Val: Loss nan  Acc(top1) 41.48% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 14/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.57  Acc 63.41% | Val: Loss nan  Acc(top1) 47.16% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 15/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.58  Acc 62.50% | Val: Loss nan  Acc(top1) 50.00% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 16/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.57  Acc 63.15% | Val: Loss nan  Acc(top1) 53.41% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 17/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.53  Acc 62.63% | Val: Loss nan  Acc(top1) 45.45% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 18/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.53  Acc 62.63% | Val: Loss nan  Acc(top1) 56.25% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 19/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.56  Acc 60.03% | Val: Loss nan  Acc(top1) 48.30% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 20/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.55  Acc 60.55% | Val: Loss nan  Acc(top1) 46.02% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 21/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.54  Acc 63.80% | Val: Loss nan  Acc(top1) 46.59% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 22/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.52  Acc 65.23% | Val: Loss nan  Acc(top1) 44.89% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 23/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 66.67% | Val: Loss nan  Acc(top1) 43.18% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 24/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 64.97% | Val: Loss nan  Acc(top1) 55.68% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 25/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 68.23% | Val: Loss nan  Acc(top1) 43.18% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 26/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 65.36% | Val: Loss nan  Acc(top1) 51.14% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 27/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.52  Acc 63.67% | Val: Loss nan  Acc(top1) 54.55% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 28/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.52  Acc 63.28% | Val: Loss nan  Acc(top1) 47.16% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 29/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 66.02% | Val: Loss nan  Acc(top1) 44.89% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 30/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.46  Acc 66.15% | Val: Loss nan  Acc(top1) 59.09% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 31/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 63.02% | Val: Loss nan  Acc(top1) 47.73% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 32/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 63.67% | Val: Loss nan  Acc(top1) 57.39% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 33/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 63.67% | Val: Loss nan  Acc(top1) 52.84% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 34/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 66.54% | Val: Loss nan  Acc(top1) 48.30% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 35/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.47  Acc 64.84% | Val: Loss nan  Acc(top1) 60.80% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 36/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 66.54% | Val: Loss nan  Acc(top1) 58.52% | HA 0.00@0\n",
      "after: len of y_pred:176, len of y_target:176\n",
      "SP-[1] Epoch: 37/1800 | Time: 0m03s (Train 0m03s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 65.62% | Val: Loss nan  Acc(top1) 61.36% | HA 0.00@0\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a0ead-0598-4f1b-9b98-5b9127f9bfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
