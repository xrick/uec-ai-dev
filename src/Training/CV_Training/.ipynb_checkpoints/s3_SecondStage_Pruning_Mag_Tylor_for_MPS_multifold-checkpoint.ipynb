{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../src/\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True;\n",
    "# torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00a2415-5a75-4b21-aca7-aa4ad28798ac",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('71',3),('99',4)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        # batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX, batchY = self.generate_batch_select_fixed_class(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def generate_batch_select_fixed_class(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        #two variables recording alarm and moaning sounds count\n",
    "        alarm_selected = 0;\n",
    "        moaning_selected = 0;\n",
    "        help_eng_selected = 0;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                # print(\"enter while true\")\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                lbl1_int = np.int16(label1);\n",
    "                lbl2_int = np.int16(label2);\n",
    "                # print(f\"label1:{label1} and label2:{label2}\")\n",
    "                # print(f\"label1:{type(label1)} and label2:{type(label2)}\")\n",
    "                if (lbl1_int == 52 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int ==52):\n",
    "                    # if (alarm_selected < moaning_selected) or (alarm_selected == moaning_selected):\n",
    "                    if (alarm_selected == moaning_selected) and (alarm_selected == help_eng_selected):\n",
    "                        alarm_selected += 1;\n",
    "                        break;\n",
    "                if (lbl1_int == 56 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 56):\n",
    "                    if (moaning_selected < alarm_selected) and (moaning_selected == help_eng_selected):\n",
    "                        moaning_selected += 1;\n",
    "                        break;\n",
    "                if (lbl1_int == 71 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 71):\n",
    "                    if (help_eng_selected < alarm_selected) and (help_eng_selected < moaning_selected):\n",
    "                        help_eng_selected += 1;\n",
    "                        break;\n",
    "            # print(f\"escape for loop\");\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random());\n",
    "            #######make wanted class mix ration above 0.5##########\n",
    "            # iLbl1 = np.int16(label1);\n",
    "            # iLbl2 = np.int16(label2);\n",
    "            # r = 1.0;\n",
    "            # p_ratio1 = 0.4\n",
    "            # p_ratio2 = 0.6\n",
    "            # while True:\n",
    "            #     r = np.array(random.random());\n",
    "            #     if r > p_ratio1 and iLbl1 != 99 :\n",
    "            #         break;\n",
    "            #     if r < p_ratio2 and iLbl2 != 99 :\n",
    "            #         break;\n",
    "            #######################End#######################\n",
    "            # print(f\"r:{r}, lbl1:{label1}, lbl2:{label2}\")  \n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            \n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        # print(f\"alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess_setup_withoutt_normalize(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength)\n",
    "                 ]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['{}'.format(opt.current_fold)].item()['sounds']\n",
    "    train_labels = dataset['{}'.format(opt.current_fold)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392ff48-c5c7-4e0f-a7f5-4eb243d1ab56",
   "metadata": {},
   "source": [
    "### option object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='None',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9873d-61b4-47b1-a0e5-95d8f156a7f2",
   "metadata": {},
   "source": [
    "### ACDNet Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  self.ch_config[-1];#n_class #self.ch_config[-1];\n",
    "        # ch_confing_10 = 512 #8 * 64\n",
    "        # ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=20150, nclass=4, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = opt.prun_type; #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        # self.opt.device = 'cuda:0'#office\n",
    "        self.opt.device = opt.device;#home\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        print(f\"Start to Prune and Train Using device:{self.opt.device}\");\n",
    "        dir = os.getcwd();\n",
    "        \n",
    "        trained_model = \"../../../trained_models/step_2_first_stage_pruning/multifold/s2_wprun_4C_fold5_2024072310_prunratio85.0/selected/uec_4C_weight_prun_fold5_haacc_95.62841033935547_valacc94.53551483154297_tracc91.19318181818183_epoch_1078_20240723111906.pt\"\n",
    "        state= torch.load(trained_model, map_location=self.opt.device);\n",
    "        self.net = GetCustomedACDNetModel(channel_config=state[\"config\"]).to(self.opt.device);\n",
    "        self.net.load_state_dict(state['weight']);#home\n",
    "        self.net = self.net.to(self.opt.device);\n",
    "        \n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda(); #in office, use cuda(better) or cpu\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # y_target = y_target.cuda();\n",
    "            y_target =y_target.to(self.opt.device);\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                # label = label.cpu() #use apple m2, in office use cuda\n",
    "                # output = output.cpu() #use apple m2, in office use cuda\n",
    "                label = label.to(self.opt.device);\n",
    "                output = output.to(self.opt.device);\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                # x = x.type(torch.cuda.FloatTensor);\n",
    "                x = x.type(torch.FloatTensor)\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);\n",
    "\n",
    "        \n",
    "    # def __save_model(self, acc, train_acc, epochIdx, net):\n",
    "    #     if acc > self.bestAcc:\n",
    "    #         self.bestAcc = acc;\n",
    "    #         self.bestAccEpoch = epochIdx +1;\n",
    "    #         __do_save_model(self, acc, train_acc, self.bestAccEpoch, net);\n",
    "    #     else:\n",
    "    #         if acc > 94.0 or train_acc > 85.0: \n",
    "    #             __do_save_model(self, acc, train_acc, epochIdx, net);\n",
    "    #         else:\n",
    "    #             pass\n",
    "\n",
    "    # def __do_save_model(self, acc, tr_acc, bestAccIdx, net):\n",
    "    #     save_model_name = self.opt.model_name.format(self.bestAcc, acc, train_acc, epochIdx, genDataTimeStr());\n",
    "    #     save_model_fullpath = self.opt.save_dir + save_model_name;\n",
    "    #     print(f\"save model to {save_model_fullpath}\")\n",
    "    #     torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "    #     logObj.write(f\"save model:{model_name}, bestAcc:{self.bestAcc}@{self.}, currentAcc:{acc}@{epochIdx}\");\n",
    "    #     logObj.write(\"\\n\");\n",
    "    #     logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n===============================================\\nprune_type = Magnitude Pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n=============================================\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "===============================================\n",
    "prune_type = Magnitude Pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "=============================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 64;\n",
    "    #set train and validation sets\n",
    "    # opt.trainSet = \"../../../../uec_iot_models_datasets/version11/single_fold_train_20240603063535.npz\" #office\n",
    "    # opt.valSet = \"../../../../uec_iot_models_datasets/version11/final_single_val_20240603063755.npz\" #office\n",
    "    opt.trainSet = \"../../../../uec_iot_dev_training_datasets/generated_datasets/multifold/train/version15_multifold_home_fold5/fold5_train_20240721013721.npz\";#home\n",
    "    opt.valSet = \"../../../../uec_iot_dev_training_datasets/generated_datasets/multifold/val/version15_multifold_home_fold5/final_fold5_val_version15_multifold_home_20240721024402.npz\";#home\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    opt.prun_type = 2; #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "    opt.nClasses = 4\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 20150;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.trainer = None\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    # opt.device = 'mps';#home\n",
    "    # tlopts.display_info(opt)\n",
    "    opt.current_fold='fold5';\n",
    "    save_dir = \"../../../trained_models/step_4_second_stage_pruning/multifold/s3_prun_{}_4C_{}_prunratio{}/\".format(opt.current_fold,getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    # \"uec_4C_weight_prun_{}_\".format(opt.current_fold)+\"haacc_{}_valacc{}_tracc{}_epoch_{}_{}.pt\"\n",
    "    model_name = \"uec_4C_IterPrun_{}_ratio{}_{}.pt\".format(opt.current_fold, (opt.prune_ratio*100), genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "\n",
    "    print(f\"save model full path:{opt.model_name}\")\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model full path:../../../trained_models/step_4_second_stage_pruning/multifold/s3_prun_fold5_4C_2024072902_prunratio85.0/uec_4C_IterPrun_fold5_ratio85.0_20240729023127.pt\n",
      "Initializing PruneAndTrain Object.....\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../uec_iot_models_datasets/multifold/train/version15_multifold_home_fold5/fold5_train_20240721013721.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 41\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# valid_path = False;\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing PruneAndTrain Object.....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mPruningTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#TLTrainer(opt)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart to pruning.....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m trainer\u001b[38;5;241m.\u001b[39mPruneAndTrain()\n",
      "Cell \u001b[0;32mIn[12], line 19\u001b[0m, in \u001b[0;36mPruningTrainer.__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m;\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mKLDivLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m'\u001b[39m);\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainGen \u001b[38;5;241m=\u001b[39m \u001b[43mgetTrainGen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#train_generator.setup(self.opt, self.opt.split);\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m;\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m;\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36mgetTrainGen\u001b[0;34m(opt, split)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetTrainGen\u001b[39m(opt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n\u001b[1;32m      3\u001b[0m     train_sounds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m     train_labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/miniconda3/envs/acdnetenv/lib/python3.11/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../uec_iot_models_datasets/multifold/train/version15_multifold_home_fold5/fold5_train_20240721013721.npz'"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
