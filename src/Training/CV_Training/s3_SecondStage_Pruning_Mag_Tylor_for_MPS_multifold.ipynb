{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../src/\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "if torch.backends.mps.is_available():\n",
    "    torch.mps.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True;\n",
    "# torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c00a2415-5a75-4b21-aca7-aa4ad28798ac",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('71',3),('99',4)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        # batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX, batchY = self.generate_batch_select_fixed_class(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def generate_batch_select_fixed_class(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        #two variables recording alarm and moaning sounds count\n",
    "        alarm_selected = 0;\n",
    "        moaning_selected = 0;\n",
    "        help_eng_selected = 0;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                # print(\"enter while true\")\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                lbl1_int = np.int16(label1);\n",
    "                lbl2_int = np.int16(label2);\n",
    "                # print(f\"label1:{label1} and label2:{label2}\")\n",
    "                # print(f\"label1:{type(label1)} and label2:{type(label2)}\")\n",
    "                if (lbl1_int == 52 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int ==52):\n",
    "                    # if (alarm_selected < moaning_selected) or (alarm_selected == moaning_selected):\n",
    "                    if (alarm_selected == moaning_selected) and (alarm_selected == help_eng_selected):\n",
    "                        alarm_selected += 1;\n",
    "                        break;\n",
    "                if (lbl1_int == 56 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 56):\n",
    "                    if (moaning_selected < alarm_selected) and (moaning_selected == help_eng_selected):\n",
    "                        moaning_selected += 1;\n",
    "                        break;\n",
    "                if (lbl1_int == 71 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 71):\n",
    "                    if (help_eng_selected < alarm_selected) and (help_eng_selected < moaning_selected):\n",
    "                        help_eng_selected += 1;\n",
    "                        break;\n",
    "            # print(f\"escape for loop\");\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random());\n",
    "            #######make wanted class mix ration above 0.5##########\n",
    "            # iLbl1 = np.int16(label1);\n",
    "            # iLbl2 = np.int16(label2);\n",
    "            # r = 1.0;\n",
    "            # p_ratio1 = 0.4\n",
    "            # p_ratio2 = 0.6\n",
    "            # while True:\n",
    "            #     r = np.array(random.random());\n",
    "            #     if r > p_ratio1 and iLbl1 != 99 :\n",
    "            #         break;\n",
    "            #     if r < p_ratio2 and iLbl2 != 99 :\n",
    "            #         break;\n",
    "            #######################End#######################\n",
    "            # print(f\"r:{r}, lbl1:{label1}, lbl2:{label2}\")  \n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            \n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        # print(f\"alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess_setup_withoutt_normalize(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength)\n",
    "                 ]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['{}'.format(opt.current_fold)].item()['sounds']\n",
    "    train_labels = dataset['{}'.format(opt.current_fold)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8392ff48-c5c7-4e0f-a7f5-4eb243d1ab56",
   "metadata": {},
   "source": [
    "### option object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='None',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9873d-61b4-47b1-a0e5-95d8f156a7f2",
   "metadata": {},
   "source": [
    "### ACDNet Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  self.ch_config[-1];#n_class #self.ch_config[-1];\n",
    "        # ch_confing_10 = 512 #8 * 64\n",
    "        # ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=20150, nclass=4, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = opt.prun_type; #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        # self.opt.device = 'cuda:0'#office\n",
    "        self.opt.device = opt.device;#home\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        print(f\"Start to Prune and Train Using device:{self.opt.device}\");\n",
    "        dir = os.getcwd();\n",
    "        \n",
    "        trained_model = \"../../../trained_models/step_2_first_stage_pruning/multifold/s2_wprun_4C_fold5_2024072310_prunratio85.0/selected/uec_4C_weight_prun_fold5_haacc_95.62841033935547_valacc94.53551483154297_tracc91.19318181818183_epoch_1078_20240723111906.pt\"\n",
    "    \n",
    "        state= torch.load(trained_model, map_location=self.opt.device);\n",
    "        self.net = GetCustomedACDNetModel(channel_config=state[\"config\"]).to(self.opt.device);\n",
    "        self.net.load_state_dict(state['weight']);#home\n",
    "        self.net = self.net.to(self.opt.device);\n",
    "        \n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda(); #in office, use cuda(better) or cpu\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # y_target = y_target.cuda();\n",
    "            y_target =y_target.to(self.opt.device);\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                # label = label.cpu() #use apple m2, in office use cuda\n",
    "                # output = output.cpu() #use apple m2, in office use cuda\n",
    "                label = label.to(self.opt.device);\n",
    "                output = output.to(self.opt.device);\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                # x = x.type(torch.cuda.FloatTensor);\n",
    "                x = x.type(torch.FloatTensor).to(self.opt.device);\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);\n",
    "\n",
    "        \n",
    "    # def __save_model(self, acc, train_acc, epochIdx, net):\n",
    "    #     if acc > self.bestAcc:\n",
    "    #         self.bestAcc = acc;\n",
    "    #         self.bestAccEpoch = epochIdx +1;\n",
    "    #         __do_save_model(self, acc, train_acc, self.bestAccEpoch, net);\n",
    "    #     else:\n",
    "    #         if acc > 94.0 or train_acc > 85.0: \n",
    "    #             __do_save_model(self, acc, train_acc, epochIdx, net);\n",
    "    #         else:\n",
    "    #             pass\n",
    "\n",
    "    # def __do_save_model(self, acc, tr_acc, bestAccIdx, net):\n",
    "    #     save_model_name = self.opt.model_name.format(self.bestAcc, acc, train_acc, epochIdx, genDataTimeStr());\n",
    "    #     save_model_fullpath = self.opt.save_dir + save_model_name;\n",
    "    #     print(f\"save model to {save_model_fullpath}\")\n",
    "    #     torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "    #     logObj.write(f\"save model:{model_name}, bestAcc:{self.bestAcc}@{self.}, currentAcc:{acc}@{epochIdx}\");\n",
    "    #     logObj.write(\"\\n\");\n",
    "    #     logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n===============================================\\nprune_type = Magnitude Pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n=============================================\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "===============================================\n",
    "prune_type = Magnitude Pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "=============================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 64;\n",
    "    #set train and validation sets\n",
    "    # opt.trainSet = \"../../../../uec_iot_models_datasets/version11/single_fold_train_20240603063535.npz\" #office\n",
    "    # opt.valSet = \"../../../../uec_iot_models_datasets/version11/final_single_val_20240603063755.npz\" #office\n",
    "    opt.trainSet = \"../../../../uec_iot_dev_training_datasets/generated_datasets/multifold/train/version15_multifold_home_fold5/fold5_train_20240721013721.npz\";#home\n",
    "    opt.valSet = \"../../../../uec_iot_dev_training_datasets/generated_datasets/multifold/val/version15_multifold_home_fold5/final_fold5_val_version15_multifold_home_20240721024402.npz\";#home\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    opt.prun_type = 2; #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "    opt.nClasses = 4\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 20150;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.trainer = None\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    # opt.device = 'mps';#home\n",
    "    # tlopts.display_info(opt)\n",
    "    opt.current_fold='fold5';\n",
    "    save_dir = \"../../../trained_models/step_4_second_stage_pruning/multifold/s3_prun_{}_4C_{}_prunratio{}/\".format(opt.current_fold,getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    # \"uec_4C_weight_prun_{}_\".format(opt.current_fold)+\"haacc_{}_valacc{}_tracc{}_epoch_{}_{}.pt\"\n",
    "    model_name = \"uec_4C_IterPrun_{}_ratio{}_{}.pt\".format(opt.current_fold, (opt.prune_ratio*100), genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "\n",
    "    print(f\"save model full path:{opt.model_name}\")\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model full path:../../../trained_models/step_4_second_stage_pruning/multifold/s3_prun_fold5_4C_2024072902_prunratio85.0/uec_4C_IterPrun_fold5_ratio85.0_20240729023606.pt\n",
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:704\n",
      "Start to pruning.....\n",
      "Start to Prune and Train Using device:mps\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.536%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 20150)     (8, 1, 10071)         72      725,112\n",
      "  BatchNorm2d-2     (8, 1, 10071)     (8, 1, 10071)         16            0\n",
      "         ReLu-3     (8, 1, 10071)     (8, 1, 10071)          0       80,568\n",
      "       Conv2d-4     (8, 1, 10071)     (64, 1, 5034)      2,560   12,887,040\n",
      "  BatchNorm2d-5     (64, 1, 5034)     (64, 1, 5034)        128            0\n",
      "         ReLu-6     (64, 1, 5034)     (64, 1, 5034)          0      322,176\n",
      "    MaxPool2d-7     (64, 1, 5034)      (64, 1, 100)          0      320,000\n",
      "      Permute-8      (64, 1, 100)      (1, 64, 100)          0            0\n",
      "       Conv2d-9      (1, 64, 100)     (32, 64, 100)        288    1,843,200\n",
      " BatchNorm2d-10     (32, 64, 100)     (32, 64, 100)         64            0\n",
      "        ReLu-11     (32, 64, 100)     (32, 64, 100)          0      204,800\n",
      "   MaxPool2d-12     (32, 64, 100)      (32, 32, 50)          0      204,800\n",
      "      Conv2d-13      (32, 32, 50)      (64, 32, 50)     18,432   29,491,200\n",
      " BatchNorm2d-14      (64, 32, 50)      (64, 32, 50)        128            0\n",
      "        ReLu-15      (64, 32, 50)      (64, 32, 50)          0      102,400\n",
      "      Conv2d-16      (64, 32, 50)      (64, 32, 50)     36,864   58,982,400\n",
      " BatchNorm2d-17      (64, 32, 50)      (64, 32, 50)        128            0\n",
      "        ReLu-18      (64, 32, 50)      (64, 32, 50)          0      102,400\n",
      "   MaxPool2d-19      (64, 32, 50)      (64, 16, 25)          0      102,400\n",
      "      Conv2d-20      (64, 16, 25)     (128, 16, 25)     73,728   29,491,200\n",
      " BatchNorm2d-21     (128, 16, 25)     (128, 16, 25)        256            0\n",
      "        ReLu-22     (128, 16, 25)     (128, 16, 25)          0       51,200\n",
      "      Conv2d-23     (128, 16, 25)     (128, 16, 25)    147,456   58,982,400\n",
      " BatchNorm2d-24     (128, 16, 25)     (128, 16, 25)        256            0\n",
      "        ReLu-25     (128, 16, 25)     (128, 16, 25)          0       51,200\n",
      "   MaxPool2d-26     (128, 16, 25)      (128, 8, 12)          0       49,152\n",
      "      Conv2d-27      (128, 8, 12)      (256, 8, 12)    294,912   28,311,552\n",
      " BatchNorm2d-28      (256, 8, 12)      (256, 8, 12)        512            0\n",
      "        ReLu-29      (256, 8, 12)      (256, 8, 12)          0       24,576\n",
      "      Conv2d-30      (256, 8, 12)      (256, 8, 12)    589,824   56,623,104\n",
      " BatchNorm2d-31      (256, 8, 12)      (256, 8, 12)        512            0\n",
      "        ReLu-32      (256, 8, 12)      (256, 8, 12)          0       24,576\n",
      "   MaxPool2d-33      (256, 8, 12)       (256, 4, 6)          0       24,576\n",
      "      Conv2d-34       (256, 4, 6)       (512, 4, 6)  1,179,648   28,311,552\n",
      " BatchNorm2d-35       (512, 4, 6)       (512, 4, 6)      1,024            0\n",
      "        ReLu-36       (512, 4, 6)       (512, 4, 6)          0       12,288\n",
      "      Conv2d-37       (512, 4, 6)       (512, 4, 6)  2,359,296   56,623,104\n",
      " BatchNorm2d-38       (512, 4, 6)       (512, 4, 6)      1,024            0\n",
      "        ReLu-39       (512, 4, 6)       (512, 4, 6)          0       12,288\n",
      "   MaxPool2d-40       (512, 4, 6)       (512, 2, 3)          0       12,288\n",
      "      Conv2d-41       (512, 2, 3)         (4, 2, 3)      2,048       12,288\n",
      " BatchNorm2d-42         (4, 2, 3)         (4, 2, 3)          8            0\n",
      "        ReLu-43         (4, 2, 3)         (4, 2, 3)          0           24\n",
      "   AvgPool2d-44         (4, 2, 3)         (4, 1, 1)          0           24\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 4,709,204\n",
      "Total FLOPs : 363,985,912\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.08\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.04\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2028, Prunable: 2028, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (85%): 1722\n",
      "Total iterations required: 1722\n",
      "\n",
      "Iteration 1 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 5)]\n",
      "Input: 0.077 MB, Params: 4,709,162 (17.964 MB), Total: 18.04 MB, FLOPs: 323,535,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 28.415%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1724 finished in 0m17s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.077 MB, Params: 4,709,120 (17.964 MB), Total: 18.04 MB, FLOPs: 323,291,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1724 finished in 0m10s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.077 MB, Params: 4,709,078 (17.964 MB), Total: 18.04 MB, FLOPs: 320,270,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1724 finished in 0m10s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 30)]\n",
      "Input: 0.077 MB, Params: 4,709,036 (17.964 MB), Total: 18.04 MB, FLOPs: 320,027,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1724 finished in 0m09s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 31)]\n",
      "Input: 0.077 MB, Params: 4,708,994 (17.963 MB), Total: 18.04 MB, FLOPs: 311,463,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1724 finished in 0m10s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 38)]\n",
      "Input: 0.077 MB, Params: 4,708,952 (17.963 MB), Total: 18.04 MB, FLOPs: 311,220,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1724 finished in 0m09s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.077 MB, Params: 4,708,365 (17.961 MB), Total: 18.04 MB, FLOPs: 310,321,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1724 finished in 0m09s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.077 MB, Params: 4,707,778 (17.959 MB), Total: 18.04 MB, FLOPs: 309,422,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1724 finished in 0m09s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.077 MB, Params: 4,707,191 (17.957 MB), Total: 18.03 MB, FLOPs: 308,523,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1724 finished in 0m09s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.077 MB, Params: 4,703,733 (17.943 MB), Total: 18.02 MB, FLOPs: 308,233,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1724 finished in 0m09s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.077 MB, Params: 4,699,119 (17.926 MB), Total: 18.00 MB, FLOPs: 308,150,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1724 finished in 0m09s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.077 MB, Params: 4,694,505 (17.908 MB), Total: 17.98 MB, FLOPs: 308,067,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1724 finished in 0m09s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.077 MB, Params: 4,689,891 (17.891 MB), Total: 17.97 MB, FLOPs: 307,984,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1724 finished in 0m09s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 399)]\n",
      "Input: 0.077 MB, Params: 4,685,277 (17.873 MB), Total: 17.95 MB, FLOPs: 307,901,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1724 finished in 0m09s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 444)]\n",
      "Input: 0.077 MB, Params: 4,680,663 (17.855 MB), Total: 17.93 MB, FLOPs: 307,818,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1724 finished in 0m09s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.077 MB, Params: 4,673,794 (17.829 MB), Total: 17.91 MB, FLOPs: 307,694,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1724 finished in 0m09s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.077 MB, Params: 4,672,064 (17.823 MB), Total: 17.90 MB, FLOPs: 307,089,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1724 finished in 0m09s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 336)]\n",
      "Input: 0.077 MB, Params: 4,667,459 (17.805 MB), Total: 17.88 MB, FLOPs: 307,006,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1724 finished in 0m09s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 320)]\n",
      "Input: 0.077 MB, Params: 4,662,854 (17.787 MB), Total: 17.86 MB, FLOPs: 306,923,824\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1724 finished in 0m09s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 414)]\n",
      "Input: 0.077 MB, Params: 4,658,249 (17.770 MB), Total: 17.85 MB, FLOPs: 306,841,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1724 finished in 0m09s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 314)]\n",
      "Input: 0.077 MB, Params: 4,653,644 (17.752 MB), Total: 17.83 MB, FLOPs: 306,758,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1724 finished in 0m09s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.077 MB, Params: 4,650,204 (17.739 MB), Total: 17.82 MB, FLOPs: 306,164,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1724 finished in 0m09s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 394)]\n",
      "Input: 0.077 MB, Params: 4,645,599 (17.722 MB), Total: 17.80 MB, FLOPs: 306,081,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1724 finished in 0m09s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 4,638,775 (17.696 MB), Total: 17.77 MB, FLOPs: 305,959,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1724 finished in 0m09s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 82)]\n",
      "Input: 0.077 MB, Params: 4,631,888 (17.669 MB), Total: 17.75 MB, FLOPs: 305,683,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1724 finished in 0m09s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 409)]\n",
      "Input: 0.077 MB, Params: 4,627,292 (17.652 MB), Total: 17.73 MB, FLOPs: 305,600,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1724 finished in 0m09s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 414)]\n",
      "Input: 0.077 MB, Params: 4,620,486 (17.626 MB), Total: 17.70 MB, FLOPs: 305,478,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1724 finished in 0m09s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 2)]\n",
      "Input: 0.077 MB, Params: 4,617,046 (17.613 MB), Total: 17.69 MB, FLOPs: 305,189,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1724 finished in 0m09s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 209)]\n",
      "Input: 0.077 MB, Params: 4,612,459 (17.595 MB), Total: 17.67 MB, FLOPs: 305,106,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1724 finished in 0m09s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.077 MB, Params: 4,605,662 (17.569 MB), Total: 17.65 MB, FLOPs: 304,984,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1724 finished in 0m09s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.077 MB, Params: 4,601,084 (17.552 MB), Total: 17.63 MB, FLOPs: 304,902,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1724 finished in 0m09s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.077 MB, Params: 4,594,296 (17.526 MB), Total: 17.60 MB, FLOPs: 304,780,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1724 finished in 0m09s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.077 MB, Params: 4,587,508 (17.500 MB), Total: 17.58 MB, FLOPs: 304,657,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1724 finished in 0m09s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.077 MB, Params: 4,580,720 (17.474 MB), Total: 17.55 MB, FLOPs: 304,535,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1724 finished in 0m09s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.077 MB, Params: 4,576,169 (17.457 MB), Total: 17.53 MB, FLOPs: 304,453,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1724 finished in 0m09s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.077 MB, Params: 4,572,729 (17.444 MB), Total: 17.52 MB, FLOPs: 304,165,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1724 finished in 0m09s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 73)]\n",
      "Input: 0.077 MB, Params: 4,569,307 (17.431 MB), Total: 17.51 MB, FLOPs: 303,573,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1724 finished in 0m09s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 423)]\n",
      "Input: 0.077 MB, Params: 4,564,756 (17.413 MB), Total: 17.49 MB, FLOPs: 303,491,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1724 finished in 0m09s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.077 MB, Params: 4,561,334 (17.400 MB), Total: 17.48 MB, FLOPs: 302,899,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1724 finished in 0m09s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.077 MB, Params: 4,557,912 (17.387 MB), Total: 17.46 MB, FLOPs: 302,611,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1724 finished in 0m09s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 308)]\n",
      "Input: 0.077 MB, Params: 4,551,142 (17.361 MB), Total: 17.44 MB, FLOPs: 302,489,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1724 finished in 0m09s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.077 MB, Params: 4,544,372 (17.335 MB), Total: 17.41 MB, FLOPs: 302,368,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1724 finished in 0m09s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 105)]\n",
      "Input: 0.077 MB, Params: 4,542,669 (17.329 MB), Total: 17.41 MB, FLOPs: 301,772,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1724 finished in 0m09s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 287)]\n",
      "Input: 0.077 MB, Params: 4,535,899 (17.303 MB), Total: 17.38 MB, FLOPs: 301,650,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1724 finished in 0m09s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 238)]\n",
      "Input: 0.077 MB, Params: 4,529,111 (17.277 MB), Total: 17.35 MB, FLOPs: 301,378,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1724 finished in 0m09s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.077 MB, Params: 4,524,587 (17.260 MB), Total: 17.34 MB, FLOPs: 301,297,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1724 finished in 0m09s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.077 MB, Params: 4,521,174 (17.247 MB), Total: 17.32 MB, FLOPs: 301,010,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1724 finished in 0m09s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.077 MB, Params: 4,516,650 (17.230 MB), Total: 17.31 MB, FLOPs: 300,929,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1724 finished in 0m09s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 220)]\n",
      "Input: 0.077 MB, Params: 4,513,237 (17.217 MB), Total: 17.29 MB, FLOPs: 300,642,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1724 finished in 0m09s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 402)]\n",
      "Input: 0.077 MB, Params: 4,506,494 (17.191 MB), Total: 17.27 MB, FLOPs: 300,521,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1724 finished in 0m09s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.077 MB, Params: 4,503,108 (17.178 MB), Total: 17.25 MB, FLOPs: 299,934,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1724 finished in 0m09s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.077 MB, Params: 4,498,593 (17.161 MB), Total: 17.24 MB, FLOPs: 299,853,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1724 finished in 0m09s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.077 MB, Params: 4,494,078 (17.144 MB), Total: 17.22 MB, FLOPs: 299,772,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1724 finished in 0m09s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 278)]\n",
      "Input: 0.077 MB, Params: 4,487,353 (17.118 MB), Total: 17.19 MB, FLOPs: 299,651,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1724 finished in 0m09s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 170)]\n",
      "Input: 0.077 MB, Params: 4,480,628 (17.092 MB), Total: 17.17 MB, FLOPs: 299,530,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1724 finished in 0m09s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.077 MB, Params: 4,473,903 (17.067 MB), Total: 17.14 MB, FLOPs: 299,409,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1724 finished in 0m09s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 440)]\n",
      "Input: 0.077 MB, Params: 4,467,178 (17.041 MB), Total: 17.12 MB, FLOPs: 299,288,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1724 finished in 0m09s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 119)]\n",
      "Input: 0.077 MB, Params: 4,465,484 (17.034 MB), Total: 17.11 MB, FLOPs: 298,695,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1724 finished in 0m09s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 35)]\n",
      "Input: 0.077 MB, Params: 4,465,442 (17.034 MB), Total: 17.11 MB, FLOPs: 295,764,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1724 finished in 0m09s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 430)]\n",
      "Input: 0.077 MB, Params: 4,458,717 (17.009 MB), Total: 17.09 MB, FLOPs: 295,643,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1724 finished in 0m09s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 4,451,992 (16.983 MB), Total: 17.06 MB, FLOPs: 295,522,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1724 finished in 0m09s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 404)]\n",
      "Input: 0.077 MB, Params: 4,445,267 (16.957 MB), Total: 17.03 MB, FLOPs: 295,401,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1724 finished in 0m09s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 408)]\n",
      "Input: 0.077 MB, Params: 4,440,815 (16.940 MB), Total: 17.02 MB, FLOPs: 295,321,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1724 finished in 0m09s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 418)]\n",
      "Input: 0.077 MB, Params: 4,434,099 (16.915 MB), Total: 16.99 MB, FLOPs: 295,200,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1724 finished in 0m09s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 59)]\n",
      "Input: 0.077 MB, Params: 4,432,396 (16.908 MB), Total: 16.99 MB, FLOPs: 293,997,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.984%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1724 finished in 0m09s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 218)]\n",
      "Input: 0.077 MB, Params: 4,425,707 (16.883 MB), Total: 16.96 MB, FLOPs: 293,728,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1724 finished in 0m08s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.077 MB, Params: 4,421,264 (16.866 MB), Total: 16.94 MB, FLOPs: 293,648,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1724 finished in 0m09s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.077 MB, Params: 4,416,821 (16.849 MB), Total: 16.93 MB, FLOPs: 293,568,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1724 finished in 0m09s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.077 MB, Params: 4,410,132 (16.823 MB), Total: 16.90 MB, FLOPs: 293,448,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1724 finished in 0m09s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.077 MB, Params: 4,406,737 (16.810 MB), Total: 16.89 MB, FLOPs: 293,163,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1724 finished in 0m09s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.077 MB, Params: 4,403,342 (16.797 MB), Total: 16.87 MB, FLOPs: 292,878,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1724 finished in 0m09s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.077 MB, Params: 4,399,947 (16.784 MB), Total: 16.86 MB, FLOPs: 292,593,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1724 finished in 0m09s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.077 MB, Params: 4,393,258 (16.759 MB), Total: 16.84 MB, FLOPs: 292,472,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1724 finished in 0m09s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 395)]\n",
      "Input: 0.077 MB, Params: 4,386,569 (16.733 MB), Total: 16.81 MB, FLOPs: 292,352,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1724 finished in 0m09s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 388)]\n",
      "Input: 0.077 MB, Params: 4,382,153 (16.717 MB), Total: 16.79 MB, FLOPs: 292,272,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1724 finished in 0m09s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 379)]\n",
      "Input: 0.077 MB, Params: 4,377,737 (16.700 MB), Total: 16.78 MB, FLOPs: 292,193,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1724 finished in 0m09s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.077 MB, Params: 4,371,066 (16.674 MB), Total: 16.75 MB, FLOPs: 292,073,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1724 finished in 0m09s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.077 MB, Params: 4,364,440 (16.649 MB), Total: 16.73 MB, FLOPs: 291,807,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1724 finished in 0m09s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 401)]\n",
      "Input: 0.077 MB, Params: 4,360,033 (16.632 MB), Total: 16.71 MB, FLOPs: 291,728,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1724 finished in 0m09s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 61)]\n",
      "Input: 0.077 MB, Params: 4,358,348 (16.626 MB), Total: 16.70 MB, FLOPs: 291,138,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1724 finished in 0m09s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.077 MB, Params: 4,355,007 (16.613 MB), Total: 16.69 MB, FLOPs: 290,560,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1724 finished in 0m09s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 220)]\n",
      "Input: 0.077 MB, Params: 4,348,354 (16.588 MB), Total: 16.66 MB, FLOPs: 290,440,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1724 finished in 0m09s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 438)]\n",
      "Input: 0.077 MB, Params: 4,343,956 (16.571 MB), Total: 16.65 MB, FLOPs: 290,361,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1724 finished in 0m09s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.077 MB, Params: 4,342,280 (16.564 MB), Total: 16.64 MB, FLOPs: 289,775,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1724 finished in 0m09s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 276)]\n",
      "Input: 0.077 MB, Params: 4,337,882 (16.548 MB), Total: 16.62 MB, FLOPs: 289,696,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1724 finished in 0m09s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.077 MB, Params: 4,331,247 (16.522 MB), Total: 16.60 MB, FLOPs: 289,577,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1724 finished in 0m09s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.077 MB, Params: 4,329,571 (16.516 MB), Total: 16.59 MB, FLOPs: 288,990,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1724 finished in 0m09s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 314)]\n",
      "Input: 0.077 MB, Params: 4,322,936 (16.491 MB), Total: 16.57 MB, FLOPs: 288,871,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1724 finished in 0m09s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 4,316,301 (16.465 MB), Total: 16.54 MB, FLOPs: 288,752,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1724 finished in 0m09s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.077 MB, Params: 4,309,666 (16.440 MB), Total: 16.52 MB, FLOPs: 288,632,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1724 finished in 0m09s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 196)]\n",
      "Input: 0.077 MB, Params: 4,303,085 (16.415 MB), Total: 16.49 MB, FLOPs: 288,367,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1724 finished in 0m09s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.077 MB, Params: 4,296,459 (16.390 MB), Total: 16.47 MB, FLOPs: 288,248,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1724 finished in 0m08s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.077 MB, Params: 4,292,106 (16.373 MB), Total: 16.45 MB, FLOPs: 288,169,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1724 finished in 0m09s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 424)]\n",
      "Input: 0.077 MB, Params: 4,285,489 (16.348 MB), Total: 16.42 MB, FLOPs: 288,050,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1724 finished in 0m09s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.077 MB, Params: 4,281,145 (16.331 MB), Total: 16.41 MB, FLOPs: 287,972,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.984%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1724 finished in 0m09s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 245)]\n",
      "Input: 0.077 MB, Params: 4,274,537 (16.306 MB), Total: 16.38 MB, FLOPs: 287,853,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1724 finished in 0m09s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.077 MB, Params: 4,270,202 (16.290 MB), Total: 16.37 MB, FLOPs: 287,775,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1724 finished in 0m09s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.077 MB, Params: 4,263,603 (16.264 MB), Total: 16.34 MB, FLOPs: 287,656,900\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1724 finished in 0m09s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.077 MB, Params: 4,259,277 (16.248 MB), Total: 16.32 MB, FLOPs: 287,579,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1724 finished in 0m09s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.077 MB, Params: 4,252,687 (16.223 MB), Total: 16.30 MB, FLOPs: 287,460,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1724 finished in 0m08s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 49)]\n",
      "Input: 0.077 MB, Params: 4,251,011 (16.216 MB), Total: 16.29 MB, FLOPs: 286,874,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1724 finished in 0m09s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.077 MB, Params: 4,246,694 (16.200 MB), Total: 16.28 MB, FLOPs: 286,796,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1724 finished in 0m09s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.077 MB, Params: 4,242,377 (16.183 MB), Total: 16.26 MB, FLOPs: 286,718,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1724 finished in 0m09s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.077 MB, Params: 4,239,009 (16.171 MB), Total: 16.25 MB, FLOPs: 286,436,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1724 finished in 0m09s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.077 MB, Params: 4,234,692 (16.154 MB), Total: 16.23 MB, FLOPs: 286,358,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1724 finished in 0m09s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 298)]\n",
      "Input: 0.077 MB, Params: 4,228,129 (16.129 MB), Total: 16.21 MB, FLOPs: 286,240,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1724 finished in 0m09s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 229)]\n",
      "Input: 0.077 MB, Params: 4,221,566 (16.104 MB), Total: 16.18 MB, FLOPs: 286,122,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1724 finished in 0m09s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 257)]\n",
      "Input: 0.077 MB, Params: 4,215,003 (16.079 MB), Total: 16.16 MB, FLOPs: 286,004,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1724 finished in 0m09s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.077 MB, Params: 4,211,698 (16.066 MB), Total: 16.14 MB, FLOPs: 285,436,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1724 finished in 0m09s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.077 MB, Params: 4,208,339 (16.054 MB), Total: 16.13 MB, FLOPs: 285,154,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1724 finished in 0m09s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 333)]\n",
      "Input: 0.077 MB, Params: 4,201,776 (16.029 MB), Total: 16.11 MB, FLOPs: 285,036,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1724 finished in 0m09s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 442)]\n",
      "Input: 0.077 MB, Params: 4,197,495 (16.012 MB), Total: 16.09 MB, FLOPs: 284,959,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1724 finished in 0m09s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 49)]\n",
      "Input: 0.077 MB, Params: 4,195,828 (16.006 MB), Total: 16.08 MB, FLOPs: 284,376,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1724 finished in 0m09s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 407)]\n",
      "Input: 0.077 MB, Params: 4,189,274 (15.981 MB), Total: 16.06 MB, FLOPs: 284,258,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1724 finished in 0m09s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.077 MB, Params: 4,185,002 (15.965 MB), Total: 16.04 MB, FLOPs: 284,181,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1724 finished in 0m09s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.077 MB, Params: 4,178,457 (15.940 MB), Total: 16.02 MB, FLOPs: 284,063,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1724 finished in 0m09s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 403)]\n",
      "Input: 0.077 MB, Params: 4,174,194 (15.923 MB), Total: 16.00 MB, FLOPs: 283,986,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1724 finished in 0m09s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 279)]\n",
      "Input: 0.077 MB, Params: 4,167,658 (15.898 MB), Total: 15.98 MB, FLOPs: 283,869,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1724 finished in 0m09s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 358)]\n",
      "Input: 0.077 MB, Params: 4,163,404 (15.882 MB), Total: 15.96 MB, FLOPs: 283,792,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1724 finished in 0m09s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 388)]\n",
      "Input: 0.077 MB, Params: 4,156,877 (15.857 MB), Total: 15.93 MB, FLOPs: 283,675,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1724 finished in 0m09s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 335)]\n",
      "Input: 0.077 MB, Params: 4,150,350 (15.832 MB), Total: 15.91 MB, FLOPs: 283,557,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1724 finished in 0m09s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 308)]\n",
      "Input: 0.077 MB, Params: 4,143,823 (15.807 MB), Total: 15.88 MB, FLOPs: 283,440,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1724 finished in 0m09s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.077 MB, Params: 4,139,596 (15.791 MB), Total: 15.87 MB, FLOPs: 283,364,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1724 finished in 0m09s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.077 MB, Params: 4,133,078 (15.766 MB), Total: 15.84 MB, FLOPs: 283,246,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1724 finished in 0m09s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.077 MB, Params: 4,126,560 (15.742 MB), Total: 15.82 MB, FLOPs: 283,129,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1724 finished in 0m09s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 174)]\n",
      "Input: 0.077 MB, Params: 4,123,201 (15.729 MB), Total: 15.81 MB, FLOPs: 282,847,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1724 finished in 0m09s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.077 MB, Params: 4,116,800 (15.704 MB), Total: 15.78 MB, FLOPs: 282,587,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1724 finished in 0m09s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 239)]\n",
      "Input: 0.077 MB, Params: 4,112,591 (15.688 MB), Total: 15.77 MB, FLOPs: 282,511,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1724 finished in 0m09s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 203)]\n",
      "Input: 0.077 MB, Params: 4,109,241 (15.676 MB), Total: 15.75 MB, FLOPs: 282,230,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1724 finished in 0m09s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.077 MB, Params: 4,102,741 (15.651 MB), Total: 15.73 MB, FLOPs: 282,113,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1724 finished in 0m09s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 213)]\n",
      "Input: 0.077 MB, Params: 4,098,541 (15.635 MB), Total: 15.71 MB, FLOPs: 282,037,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1724 finished in 0m09s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.077 MB, Params: 4,092,050 (15.610 MB), Total: 15.69 MB, FLOPs: 281,920,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1724 finished in 0m09s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 141)]\n",
      "Input: 0.077 MB, Params: 4,087,859 (15.594 MB), Total: 15.67 MB, FLOPs: 281,845,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1724 finished in 0m09s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 279)]\n",
      "Input: 0.077 MB, Params: 4,081,377 (15.569 MB), Total: 15.65 MB, FLOPs: 281,728,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1724 finished in 0m09s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 358)]\n",
      "Input: 0.077 MB, Params: 4,074,895 (15.544 MB), Total: 15.62 MB, FLOPs: 281,612,260\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1724 finished in 0m09s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 319)]\n",
      "Input: 0.077 MB, Params: 4,068,413 (15.520 MB), Total: 15.60 MB, FLOPs: 281,495,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1724 finished in 0m09s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.077 MB, Params: 4,064,249 (15.504 MB), Total: 15.58 MB, FLOPs: 281,420,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1724 finished in 0m09s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 441)]\n",
      "Input: 0.077 MB, Params: 4,057,776 (15.479 MB), Total: 15.56 MB, FLOPs: 281,304,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1724 finished in 0m09s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 319)]\n",
      "Input: 0.077 MB, Params: 4,053,621 (15.463 MB), Total: 15.54 MB, FLOPs: 281,229,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1724 finished in 0m09s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 131)]\n",
      "Input: 0.077 MB, Params: 4,050,271 (15.451 MB), Total: 15.53 MB, FLOPs: 280,948,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1724 finished in 0m09s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 379)]\n",
      "Input: 0.077 MB, Params: 4,043,807 (15.426 MB), Total: 15.50 MB, FLOPs: 280,831,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1724 finished in 0m09s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 64)]\n",
      "Input: 0.077 MB, Params: 4,040,547 (15.413 MB), Total: 15.49 MB, FLOPs: 280,270,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1724 finished in 0m09s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.077 MB, Params: 4,034,083 (15.389 MB), Total: 15.47 MB, FLOPs: 280,153,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1724 finished in 0m09s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 310)]\n",
      "Input: 0.077 MB, Params: 4,029,946 (15.373 MB), Total: 15.45 MB, FLOPs: 280,079,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1724 finished in 0m09s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.077 MB, Params: 4,023,491 (15.348 MB), Total: 15.43 MB, FLOPs: 279,963,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1724 finished in 0m09s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.077 MB, Params: 4,020,150 (15.336 MB), Total: 15.41 MB, FLOPs: 279,682,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1724 finished in 0m09s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 359)]\n",
      "Input: 0.077 MB, Params: 4,013,695 (15.311 MB), Total: 15.39 MB, FLOPs: 279,566,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1724 finished in 0m09s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 133)]\n",
      "Input: 0.077 MB, Params: 4,009,576 (15.295 MB), Total: 15.37 MB, FLOPs: 279,492,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1724 finished in 0m09s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 354)]\n",
      "Input: 0.077 MB, Params: 4,005,457 (15.280 MB), Total: 15.36 MB, FLOPs: 279,418,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1724 finished in 0m09s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 301)]\n",
      "Input: 0.077 MB, Params: 3,999,020 (15.255 MB), Total: 15.33 MB, FLOPs: 279,302,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1724 finished in 0m09s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.077 MB, Params: 3,995,769 (15.243 MB), Total: 15.32 MB, FLOPs: 278,741,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1724 finished in 0m09s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.077 MB, Params: 3,989,332 (15.218 MB), Total: 15.29 MB, FLOPs: 278,625,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1724 finished in 0m09s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 132)]\n",
      "Input: 0.077 MB, Params: 3,985,231 (15.202 MB), Total: 15.28 MB, FLOPs: 278,552,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1724 finished in 0m09s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 329)]\n",
      "Input: 0.077 MB, Params: 3,978,803 (15.178 MB), Total: 15.25 MB, FLOPs: 278,436,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1724 finished in 0m09s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.077 MB, Params: 3,972,375 (15.153 MB), Total: 15.23 MB, FLOPs: 278,320,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1724 finished in 0m09s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 425)]\n",
      "Input: 0.077 MB, Params: 3,968,292 (15.138 MB), Total: 15.21 MB, FLOPs: 278,247,288\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1724 finished in 0m09s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.077 MB, Params: 3,961,873 (15.113 MB), Total: 15.19 MB, FLOPs: 278,131,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1724 finished in 0m09s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.077 MB, Params: 3,957,799 (15.098 MB), Total: 15.17 MB, FLOPs: 278,058,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1724 finished in 0m09s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 336)]\n",
      "Input: 0.077 MB, Params: 3,953,725 (15.082 MB), Total: 15.16 MB, FLOPs: 277,985,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1724 finished in 0m09s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.077 MB, Params: 3,947,486 (15.058 MB), Total: 15.14 MB, FLOPs: 277,729,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1724 finished in 0m09s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.077 MB, Params: 3,944,163 (15.046 MB), Total: 15.12 MB, FLOPs: 277,450,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1724 finished in 0m09s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 430)]\n",
      "Input: 0.077 MB, Params: 3,937,771 (15.021 MB), Total: 15.10 MB, FLOPs: 277,335,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1724 finished in 0m09s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.077 MB, Params: 3,931,550 (14.998 MB), Total: 15.07 MB, FLOPs: 277,080,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1724 finished in 0m09s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 13)]\n",
      "Input: 0.077 MB, Params: 3,930,963 (14.995 MB), Total: 15.07 MB, FLOPs: 276,211,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1724 finished in 0m09s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 111)]\n",
      "Input: 0.077 MB, Params: 3,924,742 (14.972 MB), Total: 15.05 MB, FLOPs: 275,957,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1724 finished in 0m09s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 111)]\n",
      "Input: 0.077 MB, Params: 3,923,093 (14.965 MB), Total: 15.04 MB, FLOPs: 275,380,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1724 finished in 0m09s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 188)]\n",
      "Input: 0.077 MB, Params: 3,916,872 (14.942 MB), Total: 15.02 MB, FLOPs: 275,125,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1724 finished in 0m09s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 98)]\n",
      "Input: 0.077 MB, Params: 3,910,507 (14.917 MB), Total: 14.99 MB, FLOPs: 275,011,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1724 finished in 0m09s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 188)]\n",
      "Input: 0.077 MB, Params: 3,904,142 (14.893 MB), Total: 14.97 MB, FLOPs: 274,896,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1724 finished in 0m09s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.077 MB, Params: 3,897,777 (14.869 MB), Total: 14.95 MB, FLOPs: 274,782,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1724 finished in 0m09s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 208)]\n",
      "Input: 0.077 MB, Params: 3,893,739 (14.853 MB), Total: 14.93 MB, FLOPs: 274,709,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1724 finished in 0m09s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 355)]\n",
      "Input: 0.077 MB, Params: 3,887,383 (14.829 MB), Total: 14.91 MB, FLOPs: 274,595,132\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1724 finished in 0m09s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 9)]\n",
      "Input: 0.077 MB, Params: 3,886,796 (14.827 MB), Total: 14.90 MB, FLOPs: 273,726,132\n",
      "Current Testing Performance - Val: Loss -0.468  Acc(top1) 25.137%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1724 finished in 0m09s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.077 MB, Params: 3,880,440 (14.803 MB), Total: 14.88 MB, FLOPs: 273,611,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1724 finished in 0m09s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 201)]\n",
      "Input: 0.077 MB, Params: 3,874,264 (14.779 MB), Total: 14.86 MB, FLOPs: 273,357,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1724 finished in 0m09s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 235)]\n",
      "Input: 0.077 MB, Params: 3,870,977 (14.767 MB), Total: 14.84 MB, FLOPs: 273,081,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1724 finished in 0m09s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 244)]\n",
      "Input: 0.077 MB, Params: 3,864,810 (14.743 MB), Total: 14.82 MB, FLOPs: 272,828,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1724 finished in 0m09s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.077 MB, Params: 3,860,790 (14.728 MB), Total: 14.80 MB, FLOPs: 272,756,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1724 finished in 0m09s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.077 MB, Params: 3,854,461 (14.704 MB), Total: 14.78 MB, FLOPs: 272,642,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1724 finished in 0m09s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 148)]\n",
      "Input: 0.077 MB, Params: 3,848,303 (14.680 MB), Total: 14.76 MB, FLOPs: 272,389,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1724 finished in 0m09s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.077 MB, Params: 3,844,292 (14.665 MB), Total: 14.74 MB, FLOPs: 272,317,518\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1724 finished in 0m09s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.077 MB, Params: 3,838,134 (14.641 MB), Total: 14.72 MB, FLOPs: 272,064,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1724 finished in 0m09s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 191)]\n",
      "Input: 0.077 MB, Params: 3,831,976 (14.618 MB), Total: 14.69 MB, FLOPs: 271,811,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1724 finished in 0m09s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 358)]\n",
      "Input: 0.077 MB, Params: 3,825,683 (14.594 MB), Total: 14.67 MB, FLOPs: 271,698,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1724 finished in 0m09s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.077 MB, Params: 3,821,681 (14.579 MB), Total: 14.66 MB, FLOPs: 271,626,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1724 finished in 0m09s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.077 MB, Params: 3,815,397 (14.555 MB), Total: 14.63 MB, FLOPs: 271,513,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1724 finished in 0m09s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.077 MB, Params: 3,809,113 (14.531 MB), Total: 14.61 MB, FLOPs: 271,400,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1724 finished in 0m09s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.077 MB, Params: 3,805,129 (14.515 MB), Total: 14.59 MB, FLOPs: 271,328,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1724 finished in 0m09s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 372)]\n",
      "Input: 0.077 MB, Params: 3,798,854 (14.491 MB), Total: 14.57 MB, FLOPs: 271,215,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1724 finished in 0m09s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 442)]\n",
      "Input: 0.077 MB, Params: 3,794,879 (14.476 MB), Total: 14.55 MB, FLOPs: 271,144,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1724 finished in 0m09s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.077 MB, Params: 3,791,628 (14.464 MB), Total: 14.54 MB, FLOPs: 270,871,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1724 finished in 0m09s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 421)]\n",
      "Input: 0.077 MB, Params: 3,787,653 (14.449 MB), Total: 14.53 MB, FLOPs: 270,799,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1724 finished in 0m09s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 453)]\n",
      "Input: 0.077 MB, Params: 3,783,678 (14.434 MB), Total: 14.51 MB, FLOPs: 270,728,214\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1724 finished in 0m09s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.077 MB, Params: 3,777,430 (14.410 MB), Total: 14.49 MB, FLOPs: 270,615,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1724 finished in 0m09s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.077 MB, Params: 3,771,182 (14.386 MB), Total: 14.46 MB, FLOPs: 270,503,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1724 finished in 0m09s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 443)]\n",
      "Input: 0.077 MB, Params: 3,767,225 (14.371 MB), Total: 14.45 MB, FLOPs: 270,432,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1724 finished in 0m09s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 3,760,986 (14.347 MB), Total: 14.42 MB, FLOPs: 270,319,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1724 finished in 0m09s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 377)]\n",
      "Input: 0.077 MB, Params: 3,754,747 (14.323 MB), Total: 14.40 MB, FLOPs: 270,207,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1724 finished in 0m09s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 56)]\n",
      "Input: 0.077 MB, Params: 3,753,098 (14.317 MB), Total: 14.39 MB, FLOPs: 269,630,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1724 finished in 0m09s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 3,746,859 (14.293 MB), Total: 14.37 MB, FLOPs: 269,518,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1724 finished in 0m09s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 49)]\n",
      "Input: 0.077 MB, Params: 3,743,608 (14.281 MB), Total: 14.36 MB, FLOPs: 269,245,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1724 finished in 0m09s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 204)]\n",
      "Input: 0.077 MB, Params: 3,737,369 (14.257 MB), Total: 14.33 MB, FLOPs: 269,133,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1724 finished in 0m09s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 213)]\n",
      "Input: 0.077 MB, Params: 3,731,130 (14.233 MB), Total: 14.31 MB, FLOPs: 269,020,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1724 finished in 0m09s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.077 MB, Params: 3,724,891 (14.209 MB), Total: 14.29 MB, FLOPs: 268,908,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1724 finished in 0m09s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.077 MB, Params: 3,721,640 (14.197 MB), Total: 14.27 MB, FLOPs: 268,635,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1724 finished in 0m09s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 5)]\n",
      "Input: 0.077 MB, Params: 3,720,000 (14.191 MB), Total: 14.27 MB, FLOPs: 267,454,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1724 finished in 0m09s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.077 MB, Params: 3,716,097 (14.176 MB), Total: 14.25 MB, FLOPs: 267,384,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1724 finished in 0m08s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.077 MB, Params: 3,712,194 (14.161 MB), Total: 14.24 MB, FLOPs: 267,314,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1724 finished in 0m09s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.077 MB, Params: 3,706,171 (14.138 MB), Total: 14.21 MB, FLOPs: 267,065,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1724 finished in 0m09s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 166)]\n",
      "Input: 0.077 MB, Params: 3,702,929 (14.126 MB), Total: 14.20 MB, FLOPs: 266,793,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1724 finished in 0m09s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.077 MB, Params: 3,699,026 (14.111 MB), Total: 14.19 MB, FLOPs: 266,723,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1724 finished in 0m09s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 136)]\n",
      "Input: 0.077 MB, Params: 3,695,784 (14.098 MB), Total: 14.18 MB, FLOPs: 266,450,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1724 finished in 0m09s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.077 MB, Params: 3,691,881 (14.083 MB), Total: 14.16 MB, FLOPs: 266,380,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1724 finished in 0m09s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 424)]\n",
      "Input: 0.077 MB, Params: 3,687,978 (14.069 MB), Total: 14.15 MB, FLOPs: 266,310,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1724 finished in 0m09s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.077 MB, Params: 3,684,075 (14.054 MB), Total: 14.13 MB, FLOPs: 266,240,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1724 finished in 0m09s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 287)]\n",
      "Input: 0.077 MB, Params: 3,677,899 (14.030 MB), Total: 14.11 MB, FLOPs: 266,129,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1724 finished in 0m09s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 162)]\n",
      "Input: 0.077 MB, Params: 3,674,657 (14.018 MB), Total: 14.09 MB, FLOPs: 265,857,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1724 finished in 0m09s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 3,668,481 (13.994 MB), Total: 14.07 MB, FLOPs: 265,745,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1724 finished in 0m09s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 193)]\n",
      "Input: 0.077 MB, Params: 3,662,503 (13.971 MB), Total: 14.05 MB, FLOPs: 265,499,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1724 finished in 0m09s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 7)]\n",
      "Input: 0.077 MB, Params: 3,662,461 (13.971 MB), Total: 14.05 MB, FLOPs: 265,261,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1724 finished in 0m09s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 213)]\n",
      "Input: 0.077 MB, Params: 3,656,294 (13.948 MB), Total: 14.02 MB, FLOPs: 265,150,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1724 finished in 0m09s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.077 MB, Params: 3,650,127 (13.924 MB), Total: 14.00 MB, FLOPs: 265,039,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1724 finished in 0m09s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 284)]\n",
      "Input: 0.077 MB, Params: 3,646,260 (13.909 MB), Total: 13.99 MB, FLOPs: 264,969,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1724 finished in 0m09s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.077 MB, Params: 3,640,300 (13.887 MB), Total: 13.96 MB, FLOPs: 264,724,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1724 finished in 0m09s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 440)]\n",
      "Input: 0.077 MB, Params: 3,636,433 (13.872 MB), Total: 13.95 MB, FLOPs: 264,654,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1724 finished in 0m09s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.077 MB, Params: 3,630,293 (13.848 MB), Total: 13.93 MB, FLOPs: 264,544,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1724 finished in 0m09s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.077 MB, Params: 3,626,435 (13.834 MB), Total: 13.91 MB, FLOPs: 264,474,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1724 finished in 0m09s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 370)]\n",
      "Input: 0.077 MB, Params: 3,622,577 (13.819 MB), Total: 13.90 MB, FLOPs: 264,405,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1724 finished in 0m09s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 401)]\n",
      "Input: 0.077 MB, Params: 3,618,719 (13.804 MB), Total: 13.88 MB, FLOPs: 264,335,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1724 finished in 0m09s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 64)]\n",
      "Input: 0.077 MB, Params: 3,617,079 (13.798 MB), Total: 13.87 MB, FLOPs: 263,762,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1724 finished in 0m09s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.077 MB, Params: 3,610,966 (13.775 MB), Total: 13.85 MB, FLOPs: 263,652,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1724 finished in 0m09s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.077 MB, Params: 3,604,853 (13.751 MB), Total: 13.83 MB, FLOPs: 263,542,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1724 finished in 0m09s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 58)]\n",
      "Input: 0.077 MB, Params: 3,601,701 (13.739 MB), Total: 13.82 MB, FLOPs: 262,996,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1724 finished in 0m09s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 433)]\n",
      "Input: 0.077 MB, Params: 3,597,861 (13.725 MB), Total: 13.80 MB, FLOPs: 262,927,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1724 finished in 0m09s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.077 MB, Params: 3,594,021 (13.710 MB), Total: 13.79 MB, FLOPs: 262,858,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1724 finished in 0m09s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 3,590,181 (13.695 MB), Total: 13.77 MB, FLOPs: 262,789,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1724 finished in 0m09s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.077 MB, Params: 3,586,341 (13.681 MB), Total: 13.76 MB, FLOPs: 262,720,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1724 finished in 0m09s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 288)]\n",
      "Input: 0.077 MB, Params: 3,582,501 (13.666 MB), Total: 13.74 MB, FLOPs: 262,651,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1724 finished in 0m09s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.077 MB, Params: 3,579,286 (13.654 MB), Total: 13.73 MB, FLOPs: 262,381,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1724 finished in 0m09s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.077 MB, Params: 3,573,218 (13.631 MB), Total: 13.71 MB, FLOPs: 262,272,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1724 finished in 0m09s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 300)]\n",
      "Input: 0.077 MB, Params: 3,567,150 (13.608 MB), Total: 13.68 MB, FLOPs: 262,163,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1724 finished in 0m09s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 3,563,935 (13.595 MB), Total: 13.67 MB, FLOPs: 261,893,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1724 finished in 0m09s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.077 MB, Params: 3,557,867 (13.572 MB), Total: 13.65 MB, FLOPs: 261,783,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1724 finished in 0m09s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 280)]\n",
      "Input: 0.077 MB, Params: 3,551,799 (13.549 MB), Total: 13.63 MB, FLOPs: 261,674,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1724 finished in 0m09s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 222)]\n",
      "Input: 0.077 MB, Params: 3,545,920 (13.527 MB), Total: 13.60 MB, FLOPs: 261,431,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1724 finished in 0m09s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 308)]\n",
      "Input: 0.077 MB, Params: 3,539,861 (13.503 MB), Total: 13.58 MB, FLOPs: 261,322,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1724 finished in 0m09s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 311)]\n",
      "Input: 0.077 MB, Params: 3,533,802 (13.480 MB), Total: 13.56 MB, FLOPs: 261,213,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1724 finished in 0m09s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 155)]\n",
      "Input: 0.077 MB, Params: 3,530,596 (13.468 MB), Total: 13.55 MB, FLOPs: 260,944,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1724 finished in 0m09s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 199)]\n",
      "Input: 0.077 MB, Params: 3,524,744 (13.446 MB), Total: 13.52 MB, FLOPs: 260,702,214\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1724 finished in 0m09s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.077 MB, Params: 3,518,694 (13.423 MB), Total: 13.50 MB, FLOPs: 260,593,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1724 finished in 0m09s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 422)]\n",
      "Input: 0.077 MB, Params: 3,514,917 (13.408 MB), Total: 13.49 MB, FLOPs: 260,525,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1724 finished in 0m09s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.077 MB, Params: 3,511,720 (13.396 MB), Total: 13.47 MB, FLOPs: 260,256,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1724 finished in 0m09s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 197)]\n",
      "Input: 0.077 MB, Params: 3,507,943 (13.382 MB), Total: 13.46 MB, FLOPs: 260,189,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1724 finished in 0m09s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 38)]\n",
      "Input: 0.077 MB, Params: 3,507,901 (13.382 MB), Total: 13.46 MB, FLOPs: 243,807,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1724 finished in 0m11s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.077 MB, Params: 3,504,124 (13.367 MB), Total: 13.44 MB, FLOPs: 243,739,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1724 finished in 0m09s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 381)]\n",
      "Input: 0.077 MB, Params: 3,498,101 (13.344 MB), Total: 13.42 MB, FLOPs: 243,631,341\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1724 finished in 0m09s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.077 MB, Params: 3,497,298 (13.341 MB), Total: 13.42 MB, FLOPs: 242,548,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1724 finished in 0m09s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.077 MB, Params: 3,491,473 (13.319 MB), Total: 13.40 MB, FLOPs: 242,332,389\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1724 finished in 0m09s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 26)]\n",
      "Input: 0.077 MB, Params: 3,491,431 (13.319 MB), Total: 13.40 MB, FLOPs: 242,093,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1724 finished in 0m09s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 236)]\n",
      "Input: 0.077 MB, Params: 3,485,417 (13.296 MB), Total: 13.37 MB, FLOPs: 241,985,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1724 finished in 0m09s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.077 MB, Params: 3,479,601 (13.274 MB), Total: 13.35 MB, FLOPs: 241,769,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1724 finished in 0m09s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 368)]\n",
      "Input: 0.077 MB, Params: 3,475,842 (13.259 MB), Total: 13.34 MB, FLOPs: 241,702,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1724 finished in 0m09s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.077 MB, Params: 3,469,846 (13.236 MB), Total: 13.31 MB, FLOPs: 241,594,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1724 finished in 0m09s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.077 MB, Params: 3,463,850 (13.214 MB), Total: 13.29 MB, FLOPs: 241,486,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1724 finished in 0m09s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.077 MB, Params: 3,457,854 (13.191 MB), Total: 13.27 MB, FLOPs: 241,378,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.158%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1724 finished in 0m09s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 272)]\n",
      "Input: 0.077 MB, Params: 3,454,122 (13.176 MB), Total: 13.25 MB, FLOPs: 241,311,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1724 finished in 0m09s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 186)]\n",
      "Input: 0.077 MB, Params: 3,450,943 (13.164 MB), Total: 13.24 MB, FLOPs: 241,082,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1724 finished in 0m09s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.077 MB, Params: 3,445,163 (13.142 MB), Total: 13.22 MB, FLOPs: 240,867,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.705%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1724 finished in 0m09s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 260)]\n",
      "Input: 0.077 MB, Params: 3,439,185 (13.119 MB), Total: 13.20 MB, FLOPs: 240,759,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1724 finished in 0m09s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 201)]\n",
      "Input: 0.077 MB, Params: 3,435,462 (13.105 MB), Total: 13.18 MB, FLOPs: 240,692,929\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1724 finished in 0m09s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 357)]\n",
      "Input: 0.077 MB, Params: 3,429,493 (13.082 MB), Total: 13.16 MB, FLOPs: 240,585,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1724 finished in 0m09s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 411)]\n",
      "Input: 0.077 MB, Params: 3,425,779 (13.068 MB), Total: 13.15 MB, FLOPs: 240,518,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1724 finished in 0m09s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.077 MB, Params: 3,422,065 (13.054 MB), Total: 13.13 MB, FLOPs: 240,451,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1724 finished in 0m09s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.077 MB, Params: 3,418,351 (13.040 MB), Total: 13.12 MB, FLOPs: 240,385,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1724 finished in 0m09s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 70)]\n",
      "Input: 0.077 MB, Params: 3,415,181 (13.028 MB), Total: 13.10 MB, FLOPs: 240,156,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1724 finished in 0m09s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 354)]\n",
      "Input: 0.077 MB, Params: 3,411,467 (13.014 MB), Total: 13.09 MB, FLOPs: 240,090,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1724 finished in 0m09s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.077 MB, Params: 3,407,753 (13.000 MB), Total: 13.08 MB, FLOPs: 240,023,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1724 finished in 0m09s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.077 MB, Params: 3,401,829 (12.977 MB), Total: 13.05 MB, FLOPs: 239,916,793\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1724 finished in 0m09s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.077 MB, Params: 3,398,659 (12.965 MB), Total: 13.04 MB, FLOPs: 239,688,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1724 finished in 0m09s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 233)]\n",
      "Input: 0.077 MB, Params: 3,392,735 (12.942 MB), Total: 13.02 MB, FLOPs: 239,582,011\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1724 finished in 0m09s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 102)]\n",
      "Input: 0.077 MB, Params: 3,389,646 (12.930 MB), Total: 13.01 MB, FLOPs: 239,092,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1724 finished in 0m09s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.077 MB, Params: 3,386,557 (12.919 MB), Total: 13.00 MB, FLOPs: 238,603,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1724 finished in 0m09s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 37)]\n",
      "Input: 0.077 MB, Params: 3,384,935 (12.913 MB), Total: 12.99 MB, FLOPs: 237,493,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1724 finished in 0m09s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 191)]\n",
      "Input: 0.077 MB, Params: 3,379,209 (12.891 MB), Total: 12.97 MB, FLOPs: 237,280,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1724 finished in 0m09s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 75)]\n",
      "Input: 0.077 MB, Params: 3,377,605 (12.885 MB), Total: 12.96 MB, FLOPs: 236,759,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1724 finished in 0m09s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 3,374,462 (12.873 MB), Total: 12.95 MB, FLOPs: 236,532,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1724 finished in 0m09s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.077 MB, Params: 3,368,547 (12.850 MB), Total: 12.93 MB, FLOPs: 236,426,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1724 finished in 0m09s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.077 MB, Params: 3,364,860 (12.836 MB), Total: 12.91 MB, FLOPs: 236,360,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1724 finished in 0m09s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 107)]\n",
      "Input: 0.077 MB, Params: 3,363,256 (12.830 MB), Total: 12.91 MB, FLOPs: 235,839,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1724 finished in 0m09s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.077 MB, Params: 3,359,569 (12.816 MB), Total: 12.89 MB, FLOPs: 235,772,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1724 finished in 0m09s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 128)]\n",
      "Input: 0.077 MB, Params: 3,356,426 (12.804 MB), Total: 12.88 MB, FLOPs: 235,546,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1724 finished in 0m09s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 275)]\n",
      "Input: 0.077 MB, Params: 3,352,739 (12.790 MB), Total: 12.87 MB, FLOPs: 235,480,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1724 finished in 0m09s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 15)]\n",
      "Input: 0.077 MB, Params: 3,352,697 (12.790 MB), Total: 12.87 MB, FLOPs: 232,735,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1724 finished in 0m10s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.077 MB, Params: 3,349,554 (12.778 MB), Total: 12.85 MB, FLOPs: 232,509,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1724 finished in 0m09s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.077 MB, Params: 3,343,864 (12.756 MB), Total: 12.83 MB, FLOPs: 232,298,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1724 finished in 0m09s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 64)]\n",
      "Input: 0.077 MB, Params: 3,340,177 (12.742 MB), Total: 12.82 MB, FLOPs: 232,232,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1724 finished in 0m09s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.077 MB, Params: 3,334,307 (12.719 MB), Total: 12.80 MB, FLOPs: 232,126,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1724 finished in 0m09s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 85)]\n",
      "Input: 0.077 MB, Params: 3,331,263 (12.708 MB), Total: 12.78 MB, FLOPs: 231,644,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1724 finished in 0m09s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 107)]\n",
      "Input: 0.077 MB, Params: 3,325,393 (12.685 MB), Total: 12.76 MB, FLOPs: 231,539,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1724 finished in 0m08s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.077 MB, Params: 3,322,268 (12.673 MB), Total: 12.75 MB, FLOPs: 231,314,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1724 finished in 0m09s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.077 MB, Params: 3,316,605 (12.652 MB), Total: 12.73 MB, FLOPs: 231,104,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1724 finished in 0m09s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 404)]\n",
      "Input: 0.077 MB, Params: 3,310,744 (12.629 MB), Total: 12.71 MB, FLOPs: 230,999,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1724 finished in 0m09s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.077 MB, Params: 3,307,084 (12.616 MB), Total: 12.69 MB, FLOPs: 230,933,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1724 finished in 0m09s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 247)]\n",
      "Input: 0.077 MB, Params: 3,303,424 (12.602 MB), Total: 12.68 MB, FLOPs: 230,867,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1724 finished in 0m09s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 223)]\n",
      "Input: 0.077 MB, Params: 3,297,770 (12.580 MB), Total: 12.66 MB, FLOPs: 230,657,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1724 finished in 0m09s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 116)]\n",
      "Input: 0.077 MB, Params: 3,294,663 (12.568 MB), Total: 12.65 MB, FLOPs: 230,433,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1724 finished in 0m09s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.077 MB, Params: 3,289,018 (12.547 MB), Total: 12.62 MB, FLOPs: 230,224,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1724 finished in 0m09s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.077 MB, Params: 3,285,358 (12.533 MB), Total: 12.61 MB, FLOPs: 230,159,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1724 finished in 0m09s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 216)]\n",
      "Input: 0.077 MB, Params: 3,282,260 (12.521 MB), Total: 12.60 MB, FLOPs: 229,936,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1724 finished in 0m09s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 115)]\n",
      "Input: 0.077 MB, Params: 3,279,243 (12.509 MB), Total: 12.59 MB, FLOPs: 229,456,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1724 finished in 0m09s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.077 MB, Params: 3,275,583 (12.495 MB), Total: 12.57 MB, FLOPs: 229,390,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.530%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1724 finished in 0m09s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 3,269,776 (12.473 MB), Total: 12.55 MB, FLOPs: 229,286,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1724 finished in 0m09s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 276)]\n",
      "Input: 0.077 MB, Params: 3,266,125 (12.459 MB), Total: 12.54 MB, FLOPs: 229,220,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1724 finished in 0m09s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 223)]\n",
      "Input: 0.077 MB, Params: 3,260,327 (12.437 MB), Total: 12.51 MB, FLOPs: 229,116,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1724 finished in 0m09s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.077 MB, Params: 3,254,709 (12.416 MB), Total: 12.49 MB, FLOPs: 228,908,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1724 finished in 0m09s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.077 MB, Params: 3,249,091 (12.394 MB), Total: 12.47 MB, FLOPs: 228,699,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1724 finished in 0m09s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.077 MB, Params: 3,243,311 (12.372 MB), Total: 12.45 MB, FLOPs: 228,595,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1724 finished in 0m09s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 363)]\n",
      "Input: 0.077 MB, Params: 3,237,531 (12.350 MB), Total: 12.43 MB, FLOPs: 228,491,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1724 finished in 0m09s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 198)]\n",
      "Input: 0.077 MB, Params: 3,231,931 (12.329 MB), Total: 12.41 MB, FLOPs: 228,284,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1724 finished in 0m09s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 383)]\n",
      "Input: 0.077 MB, Params: 3,228,307 (12.315 MB), Total: 12.39 MB, FLOPs: 228,218,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1724 finished in 0m09s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.077 MB, Params: 3,224,683 (12.301 MB), Total: 12.38 MB, FLOPs: 228,153,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1724 finished in 0m09s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 229)]\n",
      "Input: 0.077 MB, Params: 3,218,930 (12.279 MB), Total: 12.36 MB, FLOPs: 228,050,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1724 finished in 0m09s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 115)]\n",
      "Input: 0.077 MB, Params: 3,215,868 (12.268 MB), Total: 12.34 MB, FLOPs: 227,829,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1724 finished in 0m09s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 195)]\n",
      "Input: 0.077 MB, Params: 3,212,253 (12.254 MB), Total: 12.33 MB, FLOPs: 227,764,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1724 finished in 0m09s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 47)]\n",
      "Input: 0.077 MB, Params: 3,210,649 (12.248 MB), Total: 12.32 MB, FLOPs: 226,688,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1724 finished in 0m09s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 131)]\n",
      "Input: 0.077 MB, Params: 3,205,067 (12.226 MB), Total: 12.30 MB, FLOPs: 226,481,655\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1724 finished in 0m09s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 170)]\n",
      "Input: 0.077 MB, Params: 3,202,014 (12.215 MB), Total: 12.29 MB, FLOPs: 226,261,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1724 finished in 0m09s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.077 MB, Params: 3,198,399 (12.201 MB), Total: 12.28 MB, FLOPs: 226,196,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1724 finished in 0m09s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 3,192,673 (12.179 MB), Total: 12.26 MB, FLOPs: 226,093,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1724 finished in 0m09s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.077 MB, Params: 3,189,620 (12.167 MB), Total: 12.24 MB, FLOPs: 225,874,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1724 finished in 0m09s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 204)]\n",
      "Input: 0.077 MB, Params: 3,184,065 (12.146 MB), Total: 12.22 MB, FLOPs: 225,668,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1724 finished in 0m09s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.077 MB, Params: 3,180,459 (12.132 MB), Total: 12.21 MB, FLOPs: 225,603,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1724 finished in 0m09s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 204)]\n",
      "Input: 0.077 MB, Params: 3,174,904 (12.111 MB), Total: 12.19 MB, FLOPs: 225,398,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1724 finished in 0m09s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 30)]\n",
      "Input: 0.077 MB, Params: 3,173,327 (12.105 MB), Total: 12.18 MB, FLOPs: 224,885,951\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1724 finished in 0m09s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 20)]\n",
      "Input: 0.077 MB, Params: 3,173,285 (12.105 MB), Total: 12.18 MB, FLOPs: 224,647,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1724 finished in 0m09s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.077 MB, Params: 3,169,679 (12.091 MB), Total: 12.17 MB, FLOPs: 224,582,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1724 finished in 0m09s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 3,166,698 (12.080 MB), Total: 12.16 MB, FLOPs: 224,108,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1724 finished in 0m08s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.077 MB, Params: 3,163,092 (12.066 MB), Total: 12.14 MB, FLOPs: 224,043,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1724 finished in 0m09s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 337)]\n",
      "Input: 0.077 MB, Params: 3,157,411 (12.045 MB), Total: 12.12 MB, FLOPs: 223,940,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1724 finished in 0m09s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 360)]\n",
      "Input: 0.077 MB, Params: 3,153,814 (12.031 MB), Total: 12.11 MB, FLOPs: 223,876,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1724 finished in 0m09s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.077 MB, Params: 3,148,142 (12.009 MB), Total: 12.09 MB, FLOPs: 223,774,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1724 finished in 0m09s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.077 MB, Params: 3,144,554 (11.996 MB), Total: 12.07 MB, FLOPs: 223,709,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1724 finished in 0m09s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.077 MB, Params: 3,141,573 (11.984 MB), Total: 12.06 MB, FLOPs: 223,234,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1724 finished in 0m09s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.077 MB, Params: 3,137,985 (11.970 MB), Total: 12.05 MB, FLOPs: 223,170,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1724 finished in 0m09s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 212)]\n",
      "Input: 0.077 MB, Params: 3,132,448 (11.949 MB), Total: 12.03 MB, FLOPs: 222,965,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1724 finished in 0m08s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.077 MB, Params: 3,126,803 (11.928 MB), Total: 12.00 MB, FLOPs: 222,863,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1724 finished in 0m09s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 271)]\n",
      "Input: 0.077 MB, Params: 3,123,224 (11.914 MB), Total: 11.99 MB, FLOPs: 222,799,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1724 finished in 0m09s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 3,117,696 (11.893 MB), Total: 11.97 MB, FLOPs: 222,594,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1724 finished in 0m09s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 150)]\n",
      "Input: 0.077 MB, Params: 3,114,697 (11.882 MB), Total: 11.96 MB, FLOPs: 222,378,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1724 finished in 0m09s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 44)]\n",
      "Input: 0.077 MB, Params: 3,113,138 (11.876 MB), Total: 11.95 MB, FLOPs: 221,872,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1724 finished in 0m09s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 3,107,511 (11.854 MB), Total: 11.93 MB, FLOPs: 221,770,749\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1724 finished in 0m09s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.077 MB, Params: 3,104,512 (11.843 MB), Total: 11.92 MB, FLOPs: 221,554,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1724 finished in 0m09s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.077 MB, Params: 3,100,942 (11.829 MB), Total: 11.91 MB, FLOPs: 221,490,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1724 finished in 0m09s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 177)]\n",
      "Input: 0.077 MB, Params: 3,095,441 (11.808 MB), Total: 11.89 MB, FLOPs: 221,287,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1724 finished in 0m08s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.077 MB, Params: 3,089,832 (11.787 MB), Total: 11.86 MB, FLOPs: 221,186,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1724 finished in 0m09s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.077 MB, Params: 3,086,271 (11.773 MB), Total: 11.85 MB, FLOPs: 221,122,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1724 finished in 0m09s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.077 MB, Params: 3,082,710 (11.760 MB), Total: 11.84 MB, FLOPs: 221,058,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1724 finished in 0m08s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.077 MB, Params: 3,077,218 (11.739 MB), Total: 11.82 MB, FLOPs: 220,854,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1724 finished in 0m08s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 300)]\n",
      "Input: 0.077 MB, Params: 3,071,636 (11.717 MB), Total: 11.79 MB, FLOPs: 220,754,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1724 finished in 0m09s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.077 MB, Params: 3,068,084 (11.704 MB), Total: 11.78 MB, FLOPs: 220,690,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1724 finished in 0m09s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 3,062,511 (11.683 MB), Total: 11.76 MB, FLOPs: 220,589,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1724 finished in 0m09s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 162)]\n",
      "Input: 0.077 MB, Params: 3,057,037 (11.662 MB), Total: 11.74 MB, FLOPs: 220,386,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1724 finished in 0m09s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.077 MB, Params: 3,051,473 (11.640 MB), Total: 11.72 MB, FLOPs: 220,286,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1724 finished in 0m09s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.077 MB, Params: 3,047,939 (11.627 MB), Total: 11.70 MB, FLOPs: 220,223,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1724 finished in 0m09s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 3,042,384 (11.606 MB), Total: 11.68 MB, FLOPs: 220,123,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1724 finished in 0m09s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 330)]\n",
      "Input: 0.077 MB, Params: 3,036,829 (11.585 MB), Total: 11.66 MB, FLOPs: 220,023,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1724 finished in 0m09s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.077 MB, Params: 3,035,243 (11.579 MB), Total: 11.66 MB, FLOPs: 218,953,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.530%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1724 finished in 0m09s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.077 MB, Params: 3,029,688 (11.557 MB), Total: 11.63 MB, FLOPs: 218,853,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1724 finished in 0m09s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 269)]\n",
      "Input: 0.077 MB, Params: 3,024,133 (11.536 MB), Total: 11.61 MB, FLOPs: 218,753,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1724 finished in 0m09s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 283)]\n",
      "Input: 0.077 MB, Params: 3,018,578 (11.515 MB), Total: 11.59 MB, FLOPs: 218,653,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1724 finished in 0m09s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.077 MB, Params: 3,015,089 (11.502 MB), Total: 11.58 MB, FLOPs: 218,590,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1724 finished in 0m09s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 349)]\n",
      "Input: 0.077 MB, Params: 3,009,543 (11.480 MB), Total: 11.56 MB, FLOPs: 218,490,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1724 finished in 0m09s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 11)]\n",
      "Input: 0.077 MB, Params: 3,009,501 (11.480 MB), Total: 11.56 MB, FLOPs: 211,417,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1724 finished in 0m10s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 228)]\n",
      "Input: 0.077 MB, Params: 3,006,021 (11.467 MB), Total: 11.54 MB, FLOPs: 211,355,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1724 finished in 0m09s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.077 MB, Params: 3,000,484 (11.446 MB), Total: 11.52 MB, FLOPs: 211,255,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1724 finished in 0m09s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.077 MB, Params: 2,997,512 (11.435 MB), Total: 11.51 MB, FLOPs: 211,041,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1724 finished in 0m09s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.077 MB, Params: 2,994,041 (11.421 MB), Total: 11.50 MB, FLOPs: 210,979,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1724 finished in 0m09s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 214)]\n",
      "Input: 0.077 MB, Params: 2,988,648 (11.401 MB), Total: 11.48 MB, FLOPs: 210,778,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1724 finished in 0m08s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 192)]\n",
      "Input: 0.077 MB, Params: 2,985,685 (11.389 MB), Total: 11.47 MB, FLOPs: 210,564,916\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1724 finished in 0m09s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 110)]\n",
      "Input: 0.077 MB, Params: 2,982,722 (11.378 MB), Total: 11.46 MB, FLOPs: 210,351,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1724 finished in 0m09s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.077 MB, Params: 2,979,251 (11.365 MB), Total: 11.44 MB, FLOPs: 210,289,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1724 finished in 0m09s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 152)]\n",
      "Input: 0.077 MB, Params: 2,973,876 (11.344 MB), Total: 11.42 MB, FLOPs: 210,089,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1724 finished in 0m09s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 143)]\n",
      "Input: 0.077 MB, Params: 2,970,922 (11.333 MB), Total: 11.41 MB, FLOPs: 209,876,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1724 finished in 0m09s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.077 MB, Params: 2,965,421 (11.312 MB), Total: 11.39 MB, FLOPs: 209,777,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1724 finished in 0m09s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 2,959,920 (11.291 MB), Total: 11.37 MB, FLOPs: 209,678,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1724 finished in 0m09s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.077 MB, Params: 2,954,419 (11.270 MB), Total: 11.35 MB, FLOPs: 209,579,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1724 finished in 0m09s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.077 MB, Params: 2,948,918 (11.249 MB), Total: 11.33 MB, FLOPs: 209,480,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1724 finished in 0m09s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.077 MB, Params: 2,943,417 (11.228 MB), Total: 11.31 MB, FLOPs: 209,381,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1724 finished in 0m09s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 168)]\n",
      "Input: 0.077 MB, Params: 2,940,463 (11.217 MB), Total: 11.29 MB, FLOPs: 209,169,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1724 finished in 0m09s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 312)]\n",
      "Input: 0.077 MB, Params: 2,937,037 (11.204 MB), Total: 11.28 MB, FLOPs: 209,107,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1724 finished in 0m09s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 311)]\n",
      "Input: 0.077 MB, Params: 2,933,611 (11.191 MB), Total: 11.27 MB, FLOPs: 209,045,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1724 finished in 0m09s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 360)]\n",
      "Input: 0.077 MB, Params: 2,928,128 (11.170 MB), Total: 11.25 MB, FLOPs: 208,947,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1724 finished in 0m09s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.077 MB, Params: 2,922,645 (11.149 MB), Total: 11.23 MB, FLOPs: 208,848,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1724 finished in 0m09s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 2,917,162 (11.128 MB), Total: 11.20 MB, FLOPs: 208,749,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1724 finished in 0m09s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.077 MB, Params: 2,913,763 (11.115 MB), Total: 11.19 MB, FLOPs: 208,688,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1724 finished in 0m09s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 165)]\n",
      "Input: 0.077 MB, Params: 2,908,478 (11.095 MB), Total: 11.17 MB, FLOPs: 208,491,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1724 finished in 0m09s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.077 MB, Params: 2,905,569 (11.084 MB), Total: 11.16 MB, FLOPs: 208,049,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1724 finished in 0m09s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.077 MB, Params: 2,902,170 (11.071 MB), Total: 11.15 MB, FLOPs: 207,988,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1724 finished in 0m09s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 341)]\n",
      "Input: 0.077 MB, Params: 2,896,714 (11.050 MB), Total: 11.13 MB, FLOPs: 207,890,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1724 finished in 0m09s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 2,891,438 (11.030 MB), Total: 11.11 MB, FLOPs: 207,693,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1724 finished in 0m09s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 322)]\n",
      "Input: 0.077 MB, Params: 2,885,991 (11.009 MB), Total: 11.09 MB, FLOPs: 207,595,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1724 finished in 0m09s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.077 MB, Params: 2,880,544 (10.988 MB), Total: 11.07 MB, FLOPs: 207,497,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.082%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1724 finished in 0m09s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 230)]\n",
      "Input: 0.077 MB, Params: 2,875,097 (10.968 MB), Total: 11.04 MB, FLOPs: 207,399,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1724 finished in 0m09s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 78)]\n",
      "Input: 0.077 MB, Params: 2,872,188 (10.957 MB), Total: 11.03 MB, FLOPs: 206,957,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1724 finished in 0m09s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.077 MB, Params: 2,866,741 (10.936 MB), Total: 11.01 MB, FLOPs: 206,859,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1724 finished in 0m09s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 101)]\n",
      "Input: 0.077 MB, Params: 2,861,501 (10.916 MB), Total: 10.99 MB, FLOPs: 206,662,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1724 finished in 0m09s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.077 MB, Params: 2,858,147 (10.903 MB), Total: 10.98 MB, FLOPs: 206,602,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1724 finished in 0m09s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 129)]\n",
      "Input: 0.077 MB, Params: 2,852,907 (10.883 MB), Total: 10.96 MB, FLOPs: 206,406,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1724 finished in 0m09s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 2,847,487 (10.862 MB), Total: 10.94 MB, FLOPs: 206,308,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1724 finished in 0m09s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.077 MB, Params: 2,844,142 (10.850 MB), Total: 10.93 MB, FLOPs: 206,248,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1724 finished in 0m09s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.077 MB, Params: 2,840,797 (10.837 MB), Total: 10.91 MB, FLOPs: 206,188,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1724 finished in 0m09s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.077 MB, Params: 2,837,452 (10.824 MB), Total: 10.90 MB, FLOPs: 206,128,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1724 finished in 0m09s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 166)]\n",
      "Input: 0.077 MB, Params: 2,832,221 (10.804 MB), Total: 10.88 MB, FLOPs: 205,931,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1724 finished in 0m08s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 280)]\n",
      "Input: 0.077 MB, Params: 2,826,837 (10.784 MB), Total: 10.86 MB, FLOPs: 205,834,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1724 finished in 0m09s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 201)]\n",
      "Input: 0.077 MB, Params: 2,821,615 (10.764 MB), Total: 10.84 MB, FLOPs: 205,638,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1724 finished in 0m09s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.077 MB, Params: 2,818,279 (10.751 MB), Total: 10.83 MB, FLOPs: 205,578,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1724 finished in 0m09s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 6)]\n",
      "Input: 0.077 MB, Params: 2,817,701 (10.749 MB), Total: 10.83 MB, FLOPs: 204,814,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.612%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1724 finished in 0m09s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.077 MB, Params: 2,812,335 (10.728 MB), Total: 10.81 MB, FLOPs: 204,717,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1724 finished in 0m09s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.077 MB, Params: 2,809,453 (10.717 MB), Total: 10.79 MB, FLOPs: 204,510,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1724 finished in 0m09s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 113)]\n",
      "Input: 0.077 MB, Params: 2,806,126 (10.705 MB), Total: 10.78 MB, FLOPs: 204,450,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1724 finished in 0m09s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 234)]\n",
      "Input: 0.077 MB, Params: 2,802,799 (10.692 MB), Total: 10.77 MB, FLOPs: 204,390,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1724 finished in 0m09s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 2,797,451 (10.671 MB), Total: 10.75 MB, FLOPs: 204,294,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1724 finished in 0m09s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.077 MB, Params: 2,792,103 (10.651 MB), Total: 10.73 MB, FLOPs: 204,197,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1724 finished in 0m09s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 102)]\n",
      "Input: 0.077 MB, Params: 2,789,203 (10.640 MB), Total: 10.72 MB, FLOPs: 203,756,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1724 finished in 0m09s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.077 MB, Params: 2,783,855 (10.620 MB), Total: 10.70 MB, FLOPs: 203,660,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1724 finished in 0m09s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 132)]\n",
      "Input: 0.077 MB, Params: 2,780,555 (10.607 MB), Total: 10.68 MB, FLOPs: 203,601,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1724 finished in 0m09s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.077 MB, Params: 2,775,216 (10.587 MB), Total: 10.66 MB, FLOPs: 203,505,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1724 finished in 0m09s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 157)]\n",
      "Input: 0.077 MB, Params: 2,772,343 (10.576 MB), Total: 10.65 MB, FLOPs: 203,298,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1724 finished in 0m09s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.077 MB, Params: 2,769,470 (10.565 MB), Total: 10.64 MB, FLOPs: 203,091,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1724 finished in 0m09s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 194)]\n",
      "Input: 0.077 MB, Params: 2,764,131 (10.544 MB), Total: 10.62 MB, FLOPs: 202,995,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1724 finished in 0m09s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.077 MB, Params: 2,758,792 (10.524 MB), Total: 10.60 MB, FLOPs: 202,899,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1724 finished in 0m09s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 90)]\n",
      "Input: 0.077 MB, Params: 2,753,660 (10.504 MB), Total: 10.58 MB, FLOPs: 202,706,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1724 finished in 0m09s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.077 MB, Params: 2,748,330 (10.484 MB), Total: 10.56 MB, FLOPs: 202,610,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1724 finished in 0m09s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.077 MB, Params: 2,743,000 (10.464 MB), Total: 10.54 MB, FLOPs: 202,514,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1724 finished in 0m09s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 179)]\n",
      "Input: 0.077 MB, Params: 2,737,670 (10.443 MB), Total: 10.52 MB, FLOPs: 202,418,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1724 finished in 0m09s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 111)]\n",
      "Input: 0.077 MB, Params: 2,734,806 (10.432 MB), Total: 10.51 MB, FLOPs: 202,212,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1724 finished in 0m09s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.077 MB, Params: 2,729,476 (10.412 MB), Total: 10.49 MB, FLOPs: 202,116,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1724 finished in 0m09s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 353)]\n",
      "Input: 0.077 MB, Params: 2,724,146 (10.392 MB), Total: 10.47 MB, FLOPs: 202,020,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1724 finished in 0m09s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 272)]\n",
      "Input: 0.077 MB, Params: 2,718,816 (10.371 MB), Total: 10.45 MB, FLOPs: 201,924,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.443%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1724 finished in 0m09s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 2,713,747 (10.352 MB), Total: 10.43 MB, FLOPs: 201,733,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1724 finished in 0m09s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.077 MB, Params: 2,708,678 (10.333 MB), Total: 10.41 MB, FLOPs: 201,541,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1724 finished in 0m09s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.077 MB, Params: 2,703,366 (10.313 MB), Total: 10.39 MB, FLOPs: 201,446,072\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.350%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1724 finished in 0m09s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.077 MB, Params: 2,700,156 (10.300 MB), Total: 10.38 MB, FLOPs: 201,388,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1724 finished in 0m09s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 208)]\n",
      "Input: 0.077 MB, Params: 2,694,853 (10.280 MB), Total: 10.36 MB, FLOPs: 201,292,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1724 finished in 0m09s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 39)]\n",
      "Input: 0.077 MB, Params: 2,694,811 (10.280 MB), Total: 10.36 MB, FLOPs: 201,055,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.989%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1724 finished in 0m10s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.077 MB, Params: 2,689,508 (10.260 MB), Total: 10.34 MB, FLOPs: 200,960,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1724 finished in 0m09s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.077 MB, Params: 2,686,316 (10.247 MB), Total: 10.32 MB, FLOPs: 200,902,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1724 finished in 0m09s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 2,681,022 (10.227 MB), Total: 10.30 MB, FLOPs: 200,807,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1724 finished in 0m09s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.077 MB, Params: 2,680,444 (10.225 MB), Total: 10.30 MB, FLOPs: 200,043,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1724 finished in 0m09s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.077 MB, Params: 2,675,150 (10.205 MB), Total: 10.28 MB, FLOPs: 199,948,404\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1724 finished in 0m09s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.077 MB, Params: 2,669,856 (10.185 MB), Total: 10.26 MB, FLOPs: 199,853,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1724 finished in 0m09s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.077 MB, Params: 2,666,691 (10.173 MB), Total: 10.25 MB, FLOPs: 199,796,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1724 finished in 0m09s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.077 MB, Params: 2,663,526 (10.161 MB), Total: 10.24 MB, FLOPs: 199,739,322\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1724 finished in 0m09s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 75)]\n",
      "Input: 0.077 MB, Params: 2,660,653 (10.150 MB), Total: 10.23 MB, FLOPs: 199,300,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1724 finished in 0m09s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 293)]\n",
      "Input: 0.077 MB, Params: 2,657,488 (10.138 MB), Total: 10.21 MB, FLOPs: 199,243,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1724 finished in 0m09s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.077 MB, Params: 2,654,323 (10.125 MB), Total: 10.20 MB, FLOPs: 199,186,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1724 finished in 0m09s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 133)]\n",
      "Input: 0.077 MB, Params: 2,649,065 (10.105 MB), Total: 10.18 MB, FLOPs: 199,091,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1724 finished in 0m09s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 32)]\n",
      "Input: 0.077 MB, Params: 2,647,479 (10.099 MB), Total: 10.18 MB, FLOPs: 198,075,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1724 finished in 0m09s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.077 MB, Params: 2,642,221 (10.079 MB), Total: 10.16 MB, FLOPs: 197,980,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1724 finished in 0m09s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 134)]\n",
      "Input: 0.077 MB, Params: 2,639,384 (10.068 MB), Total: 10.15 MB, FLOPs: 197,776,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1724 finished in 0m09s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.077 MB, Params: 2,638,635 (10.066 MB), Total: 10.14 MB, FLOPs: 196,841,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1724 finished in 0m09s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.077 MB, Params: 2,635,488 (10.054 MB), Total: 10.13 MB, FLOPs: 196,785,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1724 finished in 0m09s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 83)]\n",
      "Input: 0.077 MB, Params: 2,630,500 (10.035 MB), Total: 10.11 MB, FLOPs: 196,595,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1724 finished in 0m09s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 166)]\n",
      "Input: 0.077 MB, Params: 2,625,512 (10.016 MB), Total: 10.09 MB, FLOPs: 196,405,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1724 finished in 0m09s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.077 MB, Params: 2,622,365 (10.004 MB), Total: 10.08 MB, FLOPs: 196,349,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1724 finished in 0m09s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 318)]\n",
      "Input: 0.077 MB, Params: 2,617,143 (9.984 MB), Total: 10.06 MB, FLOPs: 196,255,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.798%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1724 finished in 0m09s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.077 MB, Params: 2,614,005 (9.972 MB), Total: 10.05 MB, FLOPs: 196,198,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1724 finished in 0m09s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.077 MB, Params: 2,608,792 (9.952 MB), Total: 10.03 MB, FLOPs: 196,105,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1724 finished in 0m09s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.077 MB, Params: 2,603,579 (9.932 MB), Total: 10.01 MB, FLOPs: 196,011,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1724 finished in 0m09s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.077 MB, Params: 2,600,459 (9.920 MB), Total: 10.00 MB, FLOPs: 195,955,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1724 finished in 0m09s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 294)]\n",
      "Input: 0.077 MB, Params: 2,595,255 (9.900 MB), Total: 9.98 MB, FLOPs: 195,861,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1724 finished in 0m09s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 188)]\n",
      "Input: 0.077 MB, Params: 2,590,303 (9.881 MB), Total: 9.96 MB, FLOPs: 195,672,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1724 finished in 0m09s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 104)]\n",
      "Input: 0.077 MB, Params: 2,587,493 (9.871 MB), Total: 9.95 MB, FLOPs: 195,470,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1724 finished in 0m09s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 109)]\n",
      "Input: 0.077 MB, Params: 2,582,550 (9.852 MB), Total: 9.93 MB, FLOPs: 195,282,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1724 finished in 0m09s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 269)]\n",
      "Input: 0.077 MB, Params: 2,577,364 (9.832 MB), Total: 9.91 MB, FLOPs: 195,188,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1724 finished in 0m09s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.077 MB, Params: 2,572,178 (9.812 MB), Total: 9.89 MB, FLOPs: 195,095,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1724 finished in 0m09s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 304)]\n",
      "Input: 0.077 MB, Params: 2,569,085 (9.800 MB), Total: 9.88 MB, FLOPs: 195,039,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1724 finished in 0m09s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.077 MB, Params: 2,565,992 (9.788 MB), Total: 9.87 MB, FLOPs: 194,984,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1724 finished in 0m09s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 350)]\n",
      "Input: 0.077 MB, Params: 2,562,899 (9.777 MB), Total: 9.85 MB, FLOPs: 194,928,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1724 finished in 0m09s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 2,559,806 (9.765 MB), Total: 9.84 MB, FLOPs: 194,873,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1724 finished in 0m09s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.077 MB, Params: 2,554,656 (9.745 MB), Total: 9.82 MB, FLOPs: 194,780,492\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1724 finished in 0m09s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 112)]\n",
      "Input: 0.077 MB, Params: 2,553,151 (9.739 MB), Total: 9.82 MB, FLOPs: 194,329,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1724 finished in 0m09s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.077 MB, Params: 2,552,402 (9.737 MB), Total: 9.81 MB, FLOPs: 193,394,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.628%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1724 finished in 0m09s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.077 MB, Params: 2,549,318 (9.725 MB), Total: 9.80 MB, FLOPs: 193,338,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1724 finished in 0m09s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 288)]\n",
      "Input: 0.077 MB, Params: 2,544,177 (9.705 MB), Total: 9.78 MB, FLOPs: 193,246,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1724 finished in 0m09s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 185)]\n",
      "Input: 0.077 MB, Params: 2,539,036 (9.686 MB), Total: 9.76 MB, FLOPs: 193,153,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1724 finished in 0m09s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.077 MB, Params: 2,538,287 (9.683 MB), Total: 9.76 MB, FLOPs: 192,218,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1724 finished in 0m09s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 186)]\n",
      "Input: 0.077 MB, Params: 2,535,486 (9.672 MB), Total: 9.75 MB, FLOPs: 192,017,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.066%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1724 finished in 0m09s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 368)]\n",
      "Input: 0.077 MB, Params: 2,532,420 (9.660 MB), Total: 9.74 MB, FLOPs: 191,962,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.344%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1724 finished in 0m09s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 125)]\n",
      "Input: 0.077 MB, Params: 2,527,288 (9.641 MB), Total: 9.72 MB, FLOPs: 191,869,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1724 finished in 0m09s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 307)]\n",
      "Input: 0.077 MB, Params: 2,522,156 (9.621 MB), Total: 9.70 MB, FLOPs: 191,777,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1724 finished in 0m09s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.077 MB, Params: 2,519,355 (9.611 MB), Total: 9.69 MB, FLOPs: 191,575,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1724 finished in 0m09s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 131)]\n",
      "Input: 0.077 MB, Params: 2,516,554 (9.600 MB), Total: 9.68 MB, FLOPs: 191,374,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1724 finished in 0m09s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 291)]\n",
      "Input: 0.077 MB, Params: 2,511,422 (9.580 MB), Total: 9.66 MB, FLOPs: 191,281,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1724 finished in 0m09s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 351)]\n",
      "Input: 0.077 MB, Params: 2,508,383 (9.569 MB), Total: 9.65 MB, FLOPs: 191,227,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1724 finished in 0m09s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 208)]\n",
      "Input: 0.077 MB, Params: 2,505,344 (9.557 MB), Total: 9.63 MB, FLOPs: 191,172,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1724 finished in 0m09s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 116)]\n",
      "Input: 0.077 MB, Params: 2,502,543 (9.546 MB), Total: 9.62 MB, FLOPs: 190,970,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1724 finished in 0m09s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 326)]\n",
      "Input: 0.077 MB, Params: 2,499,504 (9.535 MB), Total: 9.61 MB, FLOPs: 190,916,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1724 finished in 0m09s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 185)]\n",
      "Input: 0.077 MB, Params: 2,494,669 (9.516 MB), Total: 9.59 MB, FLOPs: 190,731,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1724 finished in 0m09s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 277)]\n",
      "Input: 0.077 MB, Params: 2,489,573 (9.497 MB), Total: 9.57 MB, FLOPs: 190,640,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1724 finished in 0m09s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.077 MB, Params: 2,484,477 (9.478 MB), Total: 9.55 MB, FLOPs: 190,548,544\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1724 finished in 0m09s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.077 MB, Params: 2,482,972 (9.472 MB), Total: 9.55 MB, FLOPs: 190,097,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1724 finished in 0m09s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.077 MB, Params: 2,479,951 (9.460 MB), Total: 9.54 MB, FLOPs: 190,043,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1724 finished in 0m09s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 191)]\n",
      "Input: 0.077 MB, Params: 2,474,864 (9.441 MB), Total: 9.52 MB, FLOPs: 189,951,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1724 finished in 0m09s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.077 MB, Params: 2,473,359 (9.435 MB), Total: 9.51 MB, FLOPs: 189,500,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1724 finished in 0m09s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 75)]\n",
      "Input: 0.077 MB, Params: 2,468,551 (9.417 MB), Total: 9.49 MB, FLOPs: 189,316,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1724 finished in 0m09s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 31)]\n",
      "Input: 0.077 MB, Params: 2,465,759 (9.406 MB), Total: 9.48 MB, FLOPs: 188,889,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1724 finished in 0m09s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.077 MB, Params: 2,462,747 (9.395 MB), Total: 9.47 MB, FLOPs: 188,835,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.896%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1724 finished in 0m09s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.077 MB, Params: 2,457,678 (9.375 MB), Total: 9.45 MB, FLOPs: 188,743,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1724 finished in 0m09s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.077 MB, Params: 2,452,609 (9.356 MB), Total: 9.43 MB, FLOPs: 188,652,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1724 finished in 0m09s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 2,447,540 (9.337 MB), Total: 9.41 MB, FLOPs: 188,561,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1724 finished in 0m09s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.077 MB, Params: 2,442,471 (9.317 MB), Total: 9.39 MB, FLOPs: 188,470,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1724 finished in 0m09s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.077 MB, Params: 2,439,679 (9.307 MB), Total: 9.38 MB, FLOPs: 188,043,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1724 finished in 0m09s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 2,436,703 (9.295 MB), Total: 9.37 MB, FLOPs: 187,989,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1724 finished in 0m09s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 148)]\n",
      "Input: 0.077 MB, Params: 2,433,938 (9.285 MB), Total: 9.36 MB, FLOPs: 187,790,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1724 finished in 0m09s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.077 MB, Params: 2,428,878 (9.265 MB), Total: 9.34 MB, FLOPs: 187,699,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1724 finished in 0m09s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.077 MB, Params: 2,425,911 (9.254 MB), Total: 9.33 MB, FLOPs: 187,646,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1724 finished in 0m09s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.077 MB, Params: 2,424,379 (9.248 MB), Total: 9.33 MB, FLOPs: 186,671,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1724 finished in 0m09s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.077 MB, Params: 2,419,328 (9.229 MB), Total: 9.31 MB, FLOPs: 186,580,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1724 finished in 0m09s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.077 MB, Params: 2,414,277 (9.210 MB), Total: 9.29 MB, FLOPs: 186,489,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.344%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1724 finished in 0m09s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 27)]\n",
      "Input: 0.077 MB, Params: 2,413,537 (9.207 MB), Total: 9.28 MB, FLOPs: 185,566,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1724 finished in 0m09s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.077 MB, Params: 2,410,754 (9.196 MB), Total: 9.27 MB, FLOPs: 185,139,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1724 finished in 0m09s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 49)]\n",
      "Input: 0.077 MB, Params: 2,410,712 (9.196 MB), Total: 9.27 MB, FLOPs: 182,715,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1724 finished in 0m11s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.077 MB, Params: 2,405,661 (9.177 MB), Total: 9.25 MB, FLOPs: 182,624,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1724 finished in 0m09s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.077 MB, Params: 2,402,721 (9.166 MB), Total: 9.24 MB, FLOPs: 182,571,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1724 finished in 0m09s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 84)]\n",
      "Input: 0.077 MB, Params: 2,399,965 (9.155 MB), Total: 9.23 MB, FLOPs: 182,373,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1724 finished in 0m09s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 2,394,923 (9.136 MB), Total: 9.21 MB, FLOPs: 182,282,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1724 finished in 0m09s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 79)]\n",
      "Input: 0.077 MB, Params: 2,392,149 (9.125 MB), Total: 9.20 MB, FLOPs: 181,856,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1724 finished in 0m09s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.077 MB, Params: 2,389,218 (9.114 MB), Total: 9.19 MB, FLOPs: 181,803,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1724 finished in 0m09s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.077 MB, Params: 2,386,471 (9.104 MB), Total: 9.18 MB, FLOPs: 181,606,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1724 finished in 0m09s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.077 MB, Params: 2,385,731 (9.101 MB), Total: 9.18 MB, FLOPs: 180,719,316\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1724 finished in 0m09s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 219)]\n",
      "Input: 0.077 MB, Params: 2,380,698 (9.082 MB), Total: 9.16 MB, FLOPs: 180,628,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1724 finished in 0m09s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.077 MB, Params: 2,377,951 (9.071 MB), Total: 9.15 MB, FLOPs: 180,431,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1724 finished in 0m09s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.077 MB, Params: 2,375,029 (9.060 MB), Total: 9.14 MB, FLOPs: 180,378,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 31.694%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1724 finished in 0m09s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.077 MB, Params: 2,370,005 (9.041 MB), Total: 9.12 MB, FLOPs: 180,288,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1724 finished in 0m09s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.077 MB, Params: 2,367,258 (9.030 MB), Total: 9.11 MB, FLOPs: 180,090,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1724 finished in 0m09s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 148)]\n",
      "Input: 0.077 MB, Params: 2,364,511 (9.020 MB), Total: 9.10 MB, FLOPs: 179,892,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.158%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 31.148%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1724 finished in 0m09s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 44)]\n",
      "Input: 0.077 MB, Params: 2,363,051 (9.014 MB), Total: 9.09 MB, FLOPs: 179,454,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1724 finished in 0m09s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 241)]\n",
      "Input: 0.077 MB, Params: 2,358,027 (8.995 MB), Total: 9.07 MB, FLOPs: 179,364,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 35.519%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1724 finished in 0m09s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.077 MB, Params: 2,353,381 (8.977 MB), Total: 9.05 MB, FLOPs: 179,186,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.158%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1724 finished in 0m09s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.077 MB, Params: 2,350,643 (8.967 MB), Total: 9.04 MB, FLOPs: 178,989,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1724 finished in 0m09s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.077 MB, Params: 2,345,628 (8.948 MB), Total: 9.02 MB, FLOPs: 178,899,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1724 finished in 0m09s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 116)]\n",
      "Input: 0.077 MB, Params: 2,342,890 (8.937 MB), Total: 9.01 MB, FLOPs: 178,702,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1724 finished in 0m09s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 163)]\n",
      "Input: 0.077 MB, Params: 2,340,152 (8.927 MB), Total: 9.00 MB, FLOPs: 178,505,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1724 finished in 0m09s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 69)]\n",
      "Input: 0.077 MB, Params: 2,335,542 (8.909 MB), Total: 8.99 MB, FLOPs: 178,329,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1724 finished in 0m09s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 2,330,536 (8.890 MB), Total: 8.97 MB, FLOPs: 178,239,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.869%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1724 finished in 0m09s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 292)]\n",
      "Input: 0.077 MB, Params: 2,325,530 (8.871 MB), Total: 8.95 MB, FLOPs: 178,148,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1724 finished in 0m09s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 308)]\n",
      "Input: 0.077 MB, Params: 2,320,524 (8.852 MB), Total: 8.93 MB, FLOPs: 178,058,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.798%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1724 finished in 0m09s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.077 MB, Params: 2,317,656 (8.841 MB), Total: 8.92 MB, FLOPs: 178,007,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1724 finished in 0m09s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.077 MB, Params: 2,314,927 (8.831 MB), Total: 8.91 MB, FLOPs: 177,810,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1724 finished in 0m09s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.077 MB, Params: 2,309,930 (8.812 MB), Total: 8.89 MB, FLOPs: 177,720,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.803%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 31.148%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1724 finished in 0m09s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.077 MB, Params: 2,304,933 (8.793 MB), Total: 8.87 MB, FLOPs: 177,631,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1724 finished in 0m09s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.077 MB, Params: 2,299,936 (8.774 MB), Total: 8.85 MB, FLOPs: 177,541,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.984%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1724 finished in 0m09s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 312)]\n",
      "Input: 0.077 MB, Params: 2,294,939 (8.754 MB), Total: 8.83 MB, FLOPs: 177,451,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1724 finished in 0m09s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.077 MB, Params: 2,290,401 (8.737 MB), Total: 8.81 MB, FLOPs: 177,277,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1724 finished in 0m09s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 183)]\n",
      "Input: 0.077 MB, Params: 2,287,681 (8.727 MB), Total: 8.80 MB, FLOPs: 177,081,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1724 finished in 0m09s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.077 MB, Params: 2,282,693 (8.708 MB), Total: 8.78 MB, FLOPs: 176,991,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1724 finished in 0m09s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.077 MB, Params: 2,279,870 (8.697 MB), Total: 8.77 MB, FLOPs: 176,940,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1724 finished in 0m09s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.077 MB, Params: 2,274,891 (8.678 MB), Total: 8.75 MB, FLOPs: 176,851,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1724 finished in 0m09s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.077 MB, Params: 2,269,912 (8.659 MB), Total: 8.74 MB, FLOPs: 176,761,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 41.530%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.240%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1724 finished in 0m09s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.077 MB, Params: 2,267,107 (8.648 MB), Total: 8.73 MB, FLOPs: 176,711,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 28.415%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1724 finished in 0m09s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 60)]\n",
      "Input: 0.077 MB, Params: 2,264,387 (8.638 MB), Total: 8.71 MB, FLOPs: 176,515,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1724 finished in 0m09s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.077 MB, Params: 2,261,667 (8.628 MB), Total: 8.70 MB, FLOPs: 176,319,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1724 finished in 0m09s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.077 MB, Params: 2,256,697 (8.609 MB), Total: 8.69 MB, FLOPs: 176,230,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1724 finished in 0m09s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 143)]\n",
      "Input: 0.077 MB, Params: 2,253,977 (8.598 MB), Total: 8.68 MB, FLOPs: 176,034,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1724 finished in 0m09s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.077 MB, Params: 2,252,517 (8.593 MB), Total: 8.67 MB, FLOPs: 175,596,720\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.705%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1724 finished in 0m09s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 61)]\n",
      "Input: 0.077 MB, Params: 2,249,721 (8.582 MB), Total: 8.66 MB, FLOPs: 175,546,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1724 finished in 0m09s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.077 MB, Params: 2,246,925 (8.571 MB), Total: 8.65 MB, FLOPs: 175,496,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.508%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1724 finished in 0m09s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 312)]\n",
      "Input: 0.077 MB, Params: 2,244,129 (8.561 MB), Total: 8.64 MB, FLOPs: 175,445,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1724 finished in 0m09s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 87)]\n",
      "Input: 0.077 MB, Params: 2,242,669 (8.555 MB), Total: 8.63 MB, FLOPs: 175,008,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1724 finished in 0m09s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.077 MB, Params: 2,239,873 (8.544 MB), Total: 8.62 MB, FLOPs: 174,957,972\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.869%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.344%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1724 finished in 0m09s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.077 MB, Params: 2,234,939 (8.526 MB), Total: 8.60 MB, FLOPs: 174,869,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1724 finished in 0m09s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.077 MB, Params: 2,232,152 (8.515 MB), Total: 8.59 MB, FLOPs: 174,819,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1724 finished in 0m09s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 146)]\n",
      "Input: 0.077 MB, Params: 2,229,432 (8.505 MB), Total: 8.58 MB, FLOPs: 174,623,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.158%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1724 finished in 0m09s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.077 MB, Params: 2,226,645 (8.494 MB), Total: 8.57 MB, FLOPs: 174,573,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1724 finished in 0m09s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 2,221,729 (8.475 MB), Total: 8.55 MB, FLOPs: 174,484,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.426%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1724 finished in 0m09s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 91)]\n",
      "Input: 0.077 MB, Params: 2,220,269 (8.470 MB), Total: 8.55 MB, FLOPs: 174,047,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1724 finished in 0m09s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 78)]\n",
      "Input: 0.077 MB, Params: 2,217,648 (8.460 MB), Total: 8.54 MB, FLOPs: 173,640,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1724 finished in 0m09s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.077 MB, Params: 2,212,732 (8.441 MB), Total: 8.52 MB, FLOPs: 173,551,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1724 finished in 0m09s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.077 MB, Params: 2,209,963 (8.430 MB), Total: 8.51 MB, FLOPs: 173,502,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1724 finished in 0m09s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.077 MB, Params: 2,207,194 (8.420 MB), Total: 8.50 MB, FLOPs: 173,452,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.798%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1724 finished in 0m09s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 243)]\n",
      "Input: 0.077 MB, Params: 2,202,296 (8.401 MB), Total: 8.48 MB, FLOPs: 173,364,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1724 finished in 0m09s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 103)]\n",
      "Input: 0.077 MB, Params: 2,200,845 (8.396 MB), Total: 8.47 MB, FLOPs: 172,929,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1724 finished in 0m09s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 26)]\n",
      "Input: 0.077 MB, Params: 2,200,105 (8.393 MB), Total: 8.47 MB, FLOPs: 172,042,404\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1724 finished in 0m09s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 2,195,207 (8.374 MB), Total: 8.45 MB, FLOPs: 171,954,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1724 finished in 0m09s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 318)]\n",
      "Input: 0.077 MB, Params: 2,192,456 (8.364 MB), Total: 8.44 MB, FLOPs: 171,904,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.798%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1724 finished in 0m09s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.077 MB, Params: 2,189,844 (8.354 MB), Total: 8.43 MB, FLOPs: 171,500,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 28.415%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1724 finished in 0m09s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 70)]\n",
      "Input: 0.077 MB, Params: 2,188,402 (8.348 MB), Total: 8.42 MB, FLOPs: 171,068,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.984%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.230%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1724 finished in 0m09s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 19)]\n",
      "Input: 0.077 MB, Params: 2,186,960 (8.343 MB), Total: 8.42 MB, FLOPs: 170,636,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.240%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1724 finished in 0m09s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 196)]\n",
      "Input: 0.077 MB, Params: 2,182,071 (8.324 MB), Total: 8.40 MB, FLOPs: 170,548,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1724 finished in 0m09s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.077 MB, Params: 2,177,668 (8.307 MB), Total: 8.38 MB, FLOPs: 170,378,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1724 finished in 0m09s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 2,172,788 (8.289 MB), Total: 8.37 MB, FLOPs: 170,291,160\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.426%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1724 finished in 0m09s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 162)]\n",
      "Input: 0.077 MB, Params: 2,170,095 (8.278 MB), Total: 8.36 MB, FLOPs: 170,097,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1724 finished in 0m09s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.077 MB, Params: 2,168,653 (8.273 MB), Total: 8.35 MB, FLOPs: 169,665,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.344%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1724 finished in 0m09s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.077 MB, Params: 2,167,211 (8.267 MB), Total: 8.34 MB, FLOPs: 169,232,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.158%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.230%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1724 finished in 0m09s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.077 MB, Params: 2,164,518 (8.257 MB), Total: 8.33 MB, FLOPs: 169,038,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.984%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1724 finished in 0m09s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 148)]\n",
      "Input: 0.077 MB, Params: 2,161,825 (8.247 MB), Total: 8.32 MB, FLOPs: 168,845,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1724 finished in 0m09s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 2,156,945 (8.228 MB), Total: 8.30 MB, FLOPs: 168,757,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.066%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1724 finished in 0m09s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 184)]\n",
      "Input: 0.077 MB, Params: 2,152,587 (8.211 MB), Total: 8.29 MB, FLOPs: 168,590,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.240%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1724 finished in 0m09s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.077 MB, Params: 2,147,716 (8.193 MB), Total: 8.27 MB, FLOPs: 168,502,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.230%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.787%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1724 finished in 0m09s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.077 MB, Params: 2,143,367 (8.176 MB), Total: 8.25 MB, FLOPs: 168,335,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 31.694%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.705%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.973%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1724 finished in 0m09s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.077 MB, Params: 2,139,018 (8.160 MB), Total: 8.24 MB, FLOPs: 168,168,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.705%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.230%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1724 finished in 0m09s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 249)]\n",
      "Input: 0.077 MB, Params: 2,134,165 (8.141 MB), Total: 8.22 MB, FLOPs: 168,081,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1724 finished in 0m09s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.077 MB, Params: 2,129,312 (8.123 MB), Total: 8.20 MB, FLOPs: 167,994,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.240%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1724 finished in 0m10s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 79)]\n",
      "Input: 0.077 MB, Params: 2,127,870 (8.117 MB), Total: 8.19 MB, FLOPs: 167,561,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1724 finished in 0m09s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 2,123,017 (8.099 MB), Total: 8.18 MB, FLOPs: 167,474,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 27.869%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 28.415%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1724 finished in 0m09s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.077 MB, Params: 2,118,695 (8.082 MB), Total: 8.16 MB, FLOPs: 167,308,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 33.880%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1724 finished in 0m09s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.077 MB, Params: 2,113,851 (8.064 MB), Total: 8.14 MB, FLOPs: 167,221,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1724 finished in 0m09s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.077 MB, Params: 2,112,436 (8.058 MB), Total: 8.14 MB, FLOPs: 166,333,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1724 finished in 0m09s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 89)]\n",
      "Input: 0.077 MB, Params: 2,111,003 (8.053 MB), Total: 8.13 MB, FLOPs: 165,903,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 35.519%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.426%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.973%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1724 finished in 0m09s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 33)]\n",
      "Input: 0.077 MB, Params: 2,108,472 (8.043 MB), Total: 8.12 MB, FLOPs: 165,517,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.426%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1724 finished in 0m09s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.077 MB, Params: 2,104,159 (8.027 MB), Total: 8.10 MB, FLOPs: 165,351,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1724 finished in 0m09s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 251)]\n",
      "Input: 0.077 MB, Params: 2,099,324 (8.008 MB), Total: 8.09 MB, FLOPs: 165,264,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 32.787%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 40.437%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1724 finished in 0m09s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.077 MB, Params: 2,095,020 (7.992 MB), Total: 8.07 MB, FLOPs: 165,098,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1724 finished in 0m09s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.077 MB, Params: 2,092,350 (7.982 MB), Total: 8.06 MB, FLOPs: 165,050,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1724 finished in 0m09s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 262)]\n",
      "Input: 0.077 MB, Params: 2,087,533 (7.963 MB), Total: 8.04 MB, FLOPs: 164,963,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1724 finished in 0m09s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 246)]\n",
      "Input: 0.077 MB, Params: 2,082,716 (7.945 MB), Total: 8.02 MB, FLOPs: 164,877,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1724 finished in 0m09s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.077 MB, Params: 2,080,064 (7.935 MB), Total: 8.01 MB, FLOPs: 164,829,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1724 finished in 0m09s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 52)]\n",
      "Input: 0.077 MB, Params: 2,075,778 (7.918 MB), Total: 8.00 MB, FLOPs: 164,663,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1724 finished in 0m09s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.077 MB, Params: 2,073,126 (7.908 MB), Total: 7.99 MB, FLOPs: 164,616,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 34.973%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1724 finished in 0m09s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 288)]\n",
      "Input: 0.077 MB, Params: 2,068,336 (7.890 MB), Total: 7.97 MB, FLOPs: 164,529,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 37.705%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1724 finished in 0m09s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 210)]\n",
      "Input: 0.077 MB, Params: 2,065,693 (7.880 MB), Total: 7.96 MB, FLOPs: 164,482,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1724 finished in 0m09s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 31)]\n",
      "Input: 0.077 MB, Params: 2,065,651 (7.880 MB), Total: 7.96 MB, FLOPs: 164,245,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1724 finished in 0m10s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.077 MB, Params: 2,064,920 (7.877 MB), Total: 7.95 MB, FLOPs: 163,369,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1724 finished in 0m09s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.077 MB, Params: 2,062,277 (7.867 MB), Total: 7.94 MB, FLOPs: 163,322,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1724 finished in 0m09s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.077 MB, Params: 2,057,505 (7.849 MB), Total: 7.93 MB, FLOPs: 163,236,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1724 finished in 0m09s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 162)]\n",
      "Input: 0.077 MB, Params: 2,052,733 (7.831 MB), Total: 7.91 MB, FLOPs: 163,150,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1724 finished in 0m09s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 135)]\n",
      "Input: 0.077 MB, Params: 2,050,112 (7.821 MB), Total: 7.90 MB, FLOPs: 162,961,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1724 finished in 0m09s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.077 MB, Params: 2,045,340 (7.802 MB), Total: 7.88 MB, FLOPs: 162,876,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1724 finished in 0m09s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.077 MB, Params: 2,040,568 (7.784 MB), Total: 7.86 MB, FLOPs: 162,790,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1724 finished in 0m09s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.077 MB, Params: 2,037,961 (7.774 MB), Total: 7.85 MB, FLOPs: 162,743,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1724 finished in 0m09s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 145)]\n",
      "Input: 0.077 MB, Params: 2,035,354 (7.764 MB), Total: 7.84 MB, FLOPs: 162,696,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1724 finished in 0m09s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.077 MB, Params: 2,032,733 (7.754 MB), Total: 7.83 MB, FLOPs: 162,507,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1724 finished in 0m09s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.077 MB, Params: 2,031,309 (7.749 MB), Total: 7.83 MB, FLOPs: 162,080,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1724 finished in 0m10s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 156)]\n",
      "Input: 0.077 MB, Params: 2,026,555 (7.731 MB), Total: 7.81 MB, FLOPs: 161,995,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1724 finished in 0m09s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 116)]\n",
      "Input: 0.077 MB, Params: 2,022,341 (7.715 MB), Total: 7.79 MB, FLOPs: 161,831,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1724 finished in 0m09s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 53)]\n",
      "Input: 0.077 MB, Params: 2,019,729 (7.705 MB), Total: 7.78 MB, FLOPs: 161,643,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1724 finished in 0m09s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 10)]\n",
      "Input: 0.077 MB, Params: 2,019,687 (7.704 MB), Total: 7.78 MB, FLOPs: 142,041,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1724 finished in 0m15s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 303)]\n",
      "Input: 0.077 MB, Params: 2,017,089 (7.695 MB), Total: 7.77 MB, FLOPs: 142,010,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1724 finished in 0m10s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 107)]\n",
      "Input: 0.077 MB, Params: 2,012,353 (7.677 MB), Total: 7.75 MB, FLOPs: 141,953,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1724 finished in 0m09s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.077 MB, Params: 2,008,157 (7.661 MB), Total: 7.74 MB, FLOPs: 141,825,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1724 finished in 0m09s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.077 MB, Params: 2,003,430 (7.642 MB), Total: 7.72 MB, FLOPs: 141,769,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1724 finished in 0m09s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 42)]\n",
      "Input: 0.077 MB, Params: 2,000,850 (7.633 MB), Total: 7.71 MB, FLOPs: 141,738,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1724 finished in 0m09s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 98)]\n",
      "Input: 0.077 MB, Params: 1,998,355 (7.623 MB), Total: 7.70 MB, FLOPs: 141,398,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1724 finished in 0m09s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 1,993,637 (7.605 MB), Total: 7.68 MB, FLOPs: 141,341,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1724 finished in 0m09s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 27)]\n",
      "Input: 0.077 MB, Params: 1,993,595 (7.605 MB), Total: 7.68 MB, FLOPs: 141,105,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1724 finished in 0m10s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.077 MB, Params: 1,988,877 (7.587 MB), Total: 7.66 MB, FLOPs: 141,048,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1724 finished in 0m09s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.077 MB, Params: 1,986,382 (7.577 MB), Total: 7.65 MB, FLOPs: 140,709,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1724 finished in 0m09s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 113)]\n",
      "Input: 0.077 MB, Params: 1,982,213 (7.562 MB), Total: 7.64 MB, FLOPs: 140,581,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1724 finished in 0m09s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.077 MB, Params: 1,977,504 (7.544 MB), Total: 7.62 MB, FLOPs: 140,525,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.169%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1724 finished in 0m09s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.077 MB, Params: 1,974,951 (7.534 MB), Total: 7.61 MB, FLOPs: 140,494,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1724 finished in 0m09s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 188)]\n",
      "Input: 0.077 MB, Params: 1,972,398 (7.524 MB), Total: 7.60 MB, FLOPs: 140,463,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.601%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1724 finished in 0m09s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.077 MB, Params: 1,969,845 (7.514 MB), Total: 7.59 MB, FLOPs: 140,433,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1724 finished in 0m09s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.077 MB, Params: 1,965,685 (7.498 MB), Total: 7.58 MB, FLOPs: 140,306,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1724 finished in 0m09s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 306)]\n",
      "Input: 0.077 MB, Params: 1,963,132 (7.489 MB), Total: 7.57 MB, FLOPs: 140,275,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1724 finished in 0m09s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.077 MB, Params: 1,958,972 (7.473 MB), Total: 7.55 MB, FLOPs: 140,148,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1724 finished in 0m09s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 156)]\n",
      "Input: 0.077 MB, Params: 1,956,414 (7.463 MB), Total: 7.54 MB, FLOPs: 139,994,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1724 finished in 0m09s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 1,951,759 (7.445 MB), Total: 7.52 MB, FLOPs: 139,938,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1724 finished in 0m09s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 42)]\n",
      "Input: 0.077 MB, Params: 1,950,371 (7.440 MB), Total: 7.52 MB, FLOPs: 139,114,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1724 finished in 0m09s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.077 MB, Params: 1,947,827 (7.430 MB), Total: 7.51 MB, FLOPs: 139,083,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1724 finished in 0m09s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 126)]\n",
      "Input: 0.077 MB, Params: 1,945,269 (7.421 MB), Total: 7.50 MB, FLOPs: 138,930,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1724 finished in 0m09s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.077 MB, Params: 1,940,623 (7.403 MB), Total: 7.48 MB, FLOPs: 138,874,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1724 finished in 0m09s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 164)]\n",
      "Input: 0.077 MB, Params: 1,938,065 (7.393 MB), Total: 7.47 MB, FLOPs: 138,721,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1724 finished in 0m10s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 262)]\n",
      "Input: 0.077 MB, Params: 1,933,419 (7.375 MB), Total: 7.45 MB, FLOPs: 138,665,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1724 finished in 0m09s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 51)]\n",
      "Input: 0.077 MB, Params: 1,932,697 (7.373 MB), Total: 7.45 MB, FLOPs: 137,836,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1724 finished in 0m09s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 84)]\n",
      "Input: 0.077 MB, Params: 1,930,139 (7.363 MB), Total: 7.44 MB, FLOPs: 137,683,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1724 finished in 0m09s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.077 MB, Params: 1,926,042 (7.347 MB), Total: 7.42 MB, FLOPs: 137,558,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1724 finished in 0m09s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 245)]\n",
      "Input: 0.077 MB, Params: 1,921,405 (7.330 MB), Total: 7.41 MB, FLOPs: 137,502,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1724 finished in 0m09s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 197)]\n",
      "Input: 0.077 MB, Params: 1,916,768 (7.312 MB), Total: 7.39 MB, FLOPs: 137,446,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1724 finished in 0m10s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 184)]\n",
      "Input: 0.077 MB, Params: 1,912,131 (7.294 MB), Total: 7.37 MB, FLOPs: 137,391,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1724 finished in 0m09s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 169)]\n",
      "Input: 0.077 MB, Params: 1,908,061 (7.279 MB), Total: 7.36 MB, FLOPs: 137,266,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1724 finished in 0m09s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 154)]\n",
      "Input: 0.077 MB, Params: 1,903,433 (7.261 MB), Total: 7.34 MB, FLOPs: 137,211,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1724 finished in 0m09s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.077 MB, Params: 1,898,805 (7.243 MB), Total: 7.32 MB, FLOPs: 137,155,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1724 finished in 0m09s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.077 MB, Params: 1,894,177 (7.226 MB), Total: 7.30 MB, FLOPs: 137,100,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1724 finished in 0m09s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.077 MB, Params: 1,889,549 (7.208 MB), Total: 7.28 MB, FLOPs: 137,044,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1724 finished in 0m09s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 90)]\n",
      "Input: 0.077 MB, Params: 1,887,090 (7.199 MB), Total: 7.28 MB, FLOPs: 136,707,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1724 finished in 0m09s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.077 MB, Params: 1,884,559 (7.189 MB), Total: 7.27 MB, FLOPs: 136,555,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1724 finished in 0m09s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.077 MB, Params: 1,880,534 (7.174 MB), Total: 7.25 MB, FLOPs: 136,431,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1724 finished in 0m09s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.077 MB, Params: 1,876,509 (7.158 MB), Total: 7.24 MB, FLOPs: 136,308,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1724 finished in 0m09s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 42)]\n",
      "Input: 0.077 MB, Params: 1,875,787 (7.156 MB), Total: 7.23 MB, FLOPs: 135,479,093\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1724 finished in 0m09s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.077 MB, Params: 1,873,324 (7.146 MB), Total: 7.22 MB, FLOPs: 135,449,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1724 finished in 0m09s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 316)]\n",
      "Input: 0.077 MB, Params: 1,870,861 (7.137 MB), Total: 7.21 MB, FLOPs: 135,420,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1724 finished in 0m09s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 152)]\n",
      "Input: 0.077 MB, Params: 1,868,348 (7.127 MB), Total: 7.20 MB, FLOPs: 135,269,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1724 finished in 0m09s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.077 MB, Params: 1,865,835 (7.118 MB), Total: 7.19 MB, FLOPs: 135,118,613\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1724 finished in 0m10s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 1,863,372 (7.108 MB), Total: 7.19 MB, FLOPs: 135,089,093\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1724 finished in 0m10s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.077 MB, Params: 1,858,789 (7.091 MB), Total: 7.17 MB, FLOPs: 135,034,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1724 finished in 0m09s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 1,854,206 (7.073 MB), Total: 7.15 MB, FLOPs: 134,979,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1724 finished in 0m09s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 213)]\n",
      "Input: 0.077 MB, Params: 1,849,623 (7.056 MB), Total: 7.13 MB, FLOPs: 134,924,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1724 finished in 0m09s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.077 MB, Params: 1,847,110 (7.046 MB), Total: 7.12 MB, FLOPs: 134,773,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1724 finished in 0m10s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.077 MB, Params: 1,843,139 (7.031 MB), Total: 7.11 MB, FLOPs: 134,651,813\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1724 finished in 0m09s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 19)]\n",
      "Input: 0.077 MB, Params: 1,843,097 (7.031 MB), Total: 7.11 MB, FLOPs: 132,460,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1724 finished in 0m11s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 98)]\n",
      "Input: 0.077 MB, Params: 1,840,674 (7.022 MB), Total: 7.10 MB, FLOPs: 132,125,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1724 finished in 0m09s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 244)]\n",
      "Input: 0.077 MB, Params: 1,836,100 (7.004 MB), Total: 7.08 MB, FLOPs: 132,070,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1724 finished in 0m09s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 3)]\n",
      "Input: 0.077 MB, Params: 1,835,864 (7.003 MB), Total: 7.08 MB, FLOPs: 130,837,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1724 finished in 0m10s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 46)]\n",
      "Input: 0.077 MB, Params: 1,835,142 (7.001 MB), Total: 7.08 MB, FLOPs: 130,044,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1724 finished in 0m10s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 46)]\n",
      "Input: 0.077 MB, Params: 1,833,781 (6.995 MB), Total: 7.07 MB, FLOPs: 129,274,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1724 finished in 0m09s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.077 MB, Params: 1,829,207 (6.978 MB), Total: 7.05 MB, FLOPs: 129,219,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1724 finished in 0m09s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 23)]\n",
      "Input: 0.077 MB, Params: 1,829,170 (6.978 MB), Total: 7.05 MB, FLOPs: 129,008,678\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1724 finished in 0m10s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.077 MB, Params: 1,827,800 (6.973 MB), Total: 7.05 MB, FLOPs: 128,632,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1724 finished in 0m10s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 133)]\n",
      "Input: 0.077 MB, Params: 1,823,847 (6.957 MB), Total: 7.03 MB, FLOPs: 128,510,811\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1724 finished in 0m09s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 1,819,894 (6.942 MB), Total: 7.02 MB, FLOPs: 128,389,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1724 finished in 0m09s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 87)]\n",
      "Input: 0.077 MB, Params: 1,817,417 (6.933 MB), Total: 7.01 MB, FLOPs: 128,240,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1724 finished in 0m09s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.077 MB, Params: 1,812,861 (6.916 MB), Total: 6.99 MB, FLOPs: 128,186,199\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1724 finished in 0m10s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.077 MB, Params: 1,810,452 (6.906 MB), Total: 6.98 MB, FLOPs: 128,157,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1724 finished in 0m10s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.077 MB, Params: 1,805,905 (6.889 MB), Total: 6.97 MB, FLOPs: 128,102,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1724 finished in 0m09s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.077 MB, Params: 1,801,979 (6.874 MB), Total: 6.95 MB, FLOPs: 127,982,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1724 finished in 0m09s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 261)]\n",
      "Input: 0.077 MB, Params: 1,797,441 (6.857 MB), Total: 6.93 MB, FLOPs: 127,927,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1724 finished in 0m09s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.077 MB, Params: 1,796,071 (6.851 MB), Total: 6.93 MB, FLOPs: 127,551,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1724 finished in 0m10s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 1,792,154 (6.837 MB), Total: 6.91 MB, FLOPs: 127,430,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1724 finished in 0m09s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 64)]\n",
      "Input: 0.077 MB, Params: 1,788,237 (6.822 MB), Total: 6.90 MB, FLOPs: 127,310,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1724 finished in 0m09s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 140)]\n",
      "Input: 0.077 MB, Params: 1,784,320 (6.807 MB), Total: 6.88 MB, FLOPs: 127,189,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1724 finished in 0m09s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.077 MB, Params: 1,779,809 (6.789 MB), Total: 6.87 MB, FLOPs: 127,135,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1724 finished in 0m09s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 226)]\n",
      "Input: 0.077 MB, Params: 1,777,427 (6.780 MB), Total: 6.86 MB, FLOPs: 127,106,968\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1724 finished in 0m10s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 44)]\n",
      "Input: 0.077 MB, Params: 1,776,057 (6.775 MB), Total: 6.85 MB, FLOPs: 126,730,493\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1724 finished in 0m09s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 302)]\n",
      "Input: 0.077 MB, Params: 1,773,675 (6.766 MB), Total: 6.84 MB, FLOPs: 126,701,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1724 finished in 0m10s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.077 MB, Params: 1,771,293 (6.757 MB), Total: 6.83 MB, FLOPs: 126,673,397\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1724 finished in 0m09s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.077 MB, Params: 1,766,809 (6.740 MB), Total: 6.82 MB, FLOPs: 126,619,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1724 finished in 0m09s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 1,762,910 (6.725 MB), Total: 6.80 MB, FLOPs: 126,499,289\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1724 finished in 0m09s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.077 MB, Params: 1,759,011 (6.710 MB), Total: 6.79 MB, FLOPs: 126,378,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1724 finished in 0m09s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 188)]\n",
      "Input: 0.077 MB, Params: 1,756,638 (6.701 MB), Total: 6.78 MB, FLOPs: 126,350,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1724 finished in 0m09s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 1,752,181 (6.684 MB), Total: 6.76 MB, FLOPs: 126,297,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1724 finished in 0m09s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.077 MB, Params: 1,747,724 (6.667 MB), Total: 6.74 MB, FLOPs: 126,243,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1724 finished in 0m10s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 81)]\n",
      "Input: 0.077 MB, Params: 1,746,354 (6.662 MB), Total: 6.74 MB, FLOPs: 125,867,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1724 finished in 0m10s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 124)]\n",
      "Input: 0.077 MB, Params: 1,742,473 (6.647 MB), Total: 6.72 MB, FLOPs: 125,747,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1724 finished in 0m09s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 93)]\n",
      "Input: 0.077 MB, Params: 1,738,592 (6.632 MB), Total: 6.71 MB, FLOPs: 125,626,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1724 finished in 0m09s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.077 MB, Params: 1,736,187 (6.623 MB), Total: 6.70 MB, FLOPs: 125,482,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1724 finished in 0m09s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.077 MB, Params: 1,734,817 (6.618 MB), Total: 6.69 MB, FLOPs: 125,106,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1724 finished in 0m10s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 0)]\n",
      "Input: 0.077 MB, Params: 1,734,329 (6.616 MB), Total: 6.69 MB, FLOPs: 124,533,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 39.891%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1724 finished in 0m10s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 160)]\n",
      "Input: 0.077 MB, Params: 1,731,924 (6.607 MB), Total: 6.68 MB, FLOPs: 124,388,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1724 finished in 0m09s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.077 MB, Params: 1,729,569 (6.598 MB), Total: 6.67 MB, FLOPs: 124,360,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1724 finished in 0m10s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.077 MB, Params: 1,725,706 (6.583 MB), Total: 6.66 MB, FLOPs: 124,241,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1724 finished in 0m09s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.077 MB, Params: 1,723,351 (6.574 MB), Total: 6.65 MB, FLOPs: 124,213,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1724 finished in 0m09s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.077 MB, Params: 1,719,488 (6.559 MB), Total: 6.64 MB, FLOPs: 124,094,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1724 finished in 0m09s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.077 MB, Params: 1,717,137 (6.550 MB), Total: 6.63 MB, FLOPs: 123,772,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1724 finished in 0m09s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 1,712,734 (6.534 MB), Total: 6.61 MB, FLOPs: 123,720,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1724 finished in 0m09s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.077 MB, Params: 1,710,388 (6.525 MB), Total: 6.60 MB, FLOPs: 123,692,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1724 finished in 0m10s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.077 MB, Params: 1,708,010 (6.516 MB), Total: 6.59 MB, FLOPs: 123,549,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1724 finished in 0m09s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 129)]\n",
      "Input: 0.077 MB, Params: 1,704,165 (6.501 MB), Total: 6.58 MB, FLOPs: 123,431,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1724 finished in 0m10s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.077 MB, Params: 1,702,804 (6.496 MB), Total: 6.57 MB, FLOPs: 123,057,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1724 finished in 0m10s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.077 MB, Params: 1,698,419 (6.479 MB), Total: 6.56 MB, FLOPs: 123,004,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1724 finished in 0m10s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 1,694,034 (6.462 MB), Total: 6.54 MB, FLOPs: 122,951,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1724 finished in 0m10s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 9)]\n",
      "Input: 0.077 MB, Params: 1,693,997 (6.462 MB), Total: 6.54 MB, FLOPs: 117,735,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1724 finished in 0m13s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 245)]\n",
      "Input: 0.077 MB, Params: 1,691,669 (6.453 MB), Total: 6.53 MB, FLOPs: 117,707,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1724 finished in 0m10s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.077 MB, Params: 1,687,293 (6.437 MB), Total: 6.51 MB, FLOPs: 117,654,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1724 finished in 0m09s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 9)]\n",
      "Input: 0.077 MB, Params: 1,682,917 (6.420 MB), Total: 6.50 MB, FLOPs: 117,602,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1724 finished in 0m10s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 161)]\n",
      "Input: 0.077 MB, Params: 1,680,548 (6.411 MB), Total: 6.49 MB, FLOPs: 117,460,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1724 finished in 0m09s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 98)]\n",
      "Input: 0.077 MB, Params: 1,676,172 (6.394 MB), Total: 6.47 MB, FLOPs: 117,407,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1724 finished in 0m09s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.077 MB, Params: 1,671,796 (6.377 MB), Total: 6.45 MB, FLOPs: 117,355,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1724 finished in 0m09s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 62)]\n",
      "Input: 0.077 MB, Params: 1,668,014 (6.363 MB), Total: 6.44 MB, FLOPs: 117,238,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.710%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1724 finished in 0m10s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 1,666,653 (6.358 MB), Total: 6.43 MB, FLOPs: 116,898,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1724 finished in 0m10s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 111)]\n",
      "Input: 0.077 MB, Params: 1,662,871 (6.343 MB), Total: 6.42 MB, FLOPs: 116,780,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1724 finished in 0m10s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.077 MB, Params: 1,658,513 (6.327 MB), Total: 6.40 MB, FLOPs: 116,728,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1724 finished in 0m10s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 4)]\n",
      "Input: 0.077 MB, Params: 1,658,476 (6.327 MB), Total: 6.40 MB, FLOPs: 116,518,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1724 finished in 0m10s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 122)]\n",
      "Input: 0.077 MB, Params: 1,656,125 (6.318 MB), Total: 6.39 MB, FLOPs: 116,377,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1724 finished in 0m09s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.077 MB, Params: 1,653,842 (6.309 MB), Total: 6.39 MB, FLOPs: 116,350,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1724 finished in 0m10s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 1,651,491 (6.300 MB), Total: 6.38 MB, FLOPs: 116,209,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1724 finished in 0m09s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.077 MB, Params: 1,649,140 (6.291 MB), Total: 6.37 MB, FLOPs: 116,068,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1724 finished in 0m09s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.077 MB, Params: 1,646,857 (6.282 MB), Total: 6.36 MB, FLOPs: 116,040,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1724 finished in 0m10s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.077 MB, Params: 1,642,517 (6.266 MB), Total: 6.34 MB, FLOPs: 115,988,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1724 finished in 0m09s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.077 MB, Params: 1,640,243 (6.257 MB), Total: 6.33 MB, FLOPs: 115,961,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1724 finished in 0m10s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.077 MB, Params: 1,639,539 (6.254 MB), Total: 6.33 MB, FLOPs: 115,223,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1724 finished in 0m09s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 142)]\n",
      "Input: 0.077 MB, Params: 1,635,802 (6.240 MB), Total: 6.32 MB, FLOPs: 115,107,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1724 finished in 0m09s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.077 MB, Params: 1,633,528 (6.231 MB), Total: 6.31 MB, FLOPs: 115,080,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1724 finished in 0m10s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 46)]\n",
      "Input: 0.077 MB, Params: 1,631,240 (6.223 MB), Total: 6.30 MB, FLOPs: 114,787,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1724 finished in 0m10s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.077 MB, Params: 1,628,966 (6.214 MB), Total: 6.29 MB, FLOPs: 114,760,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1724 finished in 0m10s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.077 MB, Params: 1,626,633 (6.205 MB), Total: 6.28 MB, FLOPs: 114,620,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1724 finished in 0m09s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 95)]\n",
      "Input: 0.077 MB, Params: 1,622,905 (6.191 MB), Total: 6.27 MB, FLOPs: 114,505,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1724 finished in 0m09s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 38)]\n",
      "Input: 0.077 MB, Params: 1,621,616 (6.186 MB), Total: 6.26 MB, FLOPs: 113,807,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1724 finished in 0m09s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 1,617,321 (6.170 MB), Total: 6.25 MB, FLOPs: 113,755,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1724 finished in 0m09s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 1,613,026 (6.153 MB), Total: 6.23 MB, FLOPs: 113,704,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1724 finished in 0m09s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.077 MB, Params: 1,610,702 (6.144 MB), Total: 6.22 MB, FLOPs: 113,564,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1724 finished in 0m09s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 34)]\n",
      "Input: 0.077 MB, Params: 1,609,359 (6.139 MB), Total: 6.22 MB, FLOPs: 113,229,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1724 finished in 0m10s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.077 MB, Params: 1,607,098 (6.131 MB), Total: 6.21 MB, FLOPs: 112,939,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1724 finished in 0m10s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.077 MB, Params: 1,604,842 (6.122 MB), Total: 6.20 MB, FLOPs: 112,912,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1724 finished in 0m10s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.077 MB, Params: 1,602,527 (6.113 MB), Total: 6.19 MB, FLOPs: 112,773,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1724 finished in 0m10s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.077 MB, Params: 1,600,212 (6.104 MB), Total: 6.18 MB, FLOPs: 112,634,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1724 finished in 0m10s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.077 MB, Params: 1,597,956 (6.096 MB), Total: 6.17 MB, FLOPs: 112,607,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 777/1724 finished in 0m10s\n",
      "Total channels prunned so far: 777\n",
      "\n",
      "Iteration 778 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.077 MB, Params: 1,595,700 (6.087 MB), Total: 6.16 MB, FLOPs: 112,580,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 778/1724 finished in 0m10s\n",
      "Total channels prunned so far: 778\n",
      "\n",
      "Iteration 779 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.077 MB, Params: 1,591,432 (6.071 MB), Total: 6.15 MB, FLOPs: 112,529,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 779/1724 finished in 0m09s\n",
      "Total channels prunned so far: 779\n",
      "\n",
      "Iteration 780 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.077 MB, Params: 1,587,164 (6.055 MB), Total: 6.13 MB, FLOPs: 112,478,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 780/1724 finished in 0m09s\n",
      "Total channels prunned so far: 780\n",
      "\n",
      "Iteration 781 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.077 MB, Params: 1,584,926 (6.046 MB), Total: 6.12 MB, FLOPs: 112,451,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 781/1724 finished in 0m10s\n",
      "Total channels prunned so far: 781\n",
      "\n",
      "Iteration 782 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.077 MB, Params: 1,583,592 (6.041 MB), Total: 6.12 MB, FLOPs: 112,118,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 782/1724 finished in 0m10s\n",
      "Total channels prunned so far: 782\n",
      "\n",
      "Iteration 783 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.077 MB, Params: 1,579,333 (6.025 MB), Total: 6.10 MB, FLOPs: 112,067,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 783/1724 finished in 0m10s\n",
      "Total channels prunned so far: 783\n",
      "\n",
      "Iteration 784 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 1,577,018 (6.016 MB), Total: 6.09 MB, FLOPs: 111,928,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 784/1724 finished in 0m10s\n",
      "Total channels prunned so far: 784\n",
      "\n",
      "Iteration 785 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.077 MB, Params: 1,572,759 (6.000 MB), Total: 6.08 MB, FLOPs: 111,877,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 785/1724 finished in 0m10s\n",
      "Total channels prunned so far: 785\n",
      "\n",
      "Iteration 786 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 85)]\n",
      "Input: 0.077 MB, Params: 1,570,444 (5.991 MB), Total: 6.07 MB, FLOPs: 111,738,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 786/1724 finished in 0m10s\n",
      "Total channels prunned so far: 786\n",
      "\n",
      "Iteration 787 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 219)]\n",
      "Input: 0.077 MB, Params: 1,568,224 (5.982 MB), Total: 6.06 MB, FLOPs: 111,711,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 787/1724 finished in 0m10s\n",
      "Total channels prunned so far: 787\n",
      "\n",
      "Iteration 788 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.077 MB, Params: 1,563,974 (5.966 MB), Total: 6.04 MB, FLOPs: 111,660,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 788/1724 finished in 0m09s\n",
      "Total channels prunned so far: 788\n",
      "\n",
      "Iteration 789 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 278)]\n",
      "Input: 0.077 MB, Params: 1,561,763 (5.958 MB), Total: 6.03 MB, FLOPs: 111,634,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 789/1724 finished in 0m10s\n",
      "Total channels prunned so far: 789\n",
      "\n",
      "Iteration 790 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.077 MB, Params: 1,559,552 (5.949 MB), Total: 6.03 MB, FLOPs: 111,607,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 790/1724 finished in 0m10s\n",
      "Total channels prunned so far: 790\n",
      "\n",
      "Iteration 791 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 25)]\n",
      "Input: 0.077 MB, Params: 1,559,515 (5.949 MB), Total: 6.03 MB, FLOPs: 109,585,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 791/1724 finished in 0m12s\n",
      "Total channels prunned so far: 791\n",
      "\n",
      "Iteration 792 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.077 MB, Params: 1,557,200 (5.940 MB), Total: 6.02 MB, FLOPs: 109,446,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 792/1724 finished in 0m10s\n",
      "Total channels prunned so far: 792\n",
      "\n",
      "Iteration 793 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.077 MB, Params: 1,553,589 (5.926 MB), Total: 6.00 MB, FLOPs: 109,335,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 793/1724 finished in 0m10s\n",
      "Total channels prunned so far: 793\n",
      "\n",
      "Iteration 794 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.077 MB, Params: 1,549,366 (5.910 MB), Total: 5.99 MB, FLOPs: 109,285,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 794/1724 finished in 0m09s\n",
      "Total channels prunned so far: 794\n",
      "\n",
      "Iteration 795 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.077 MB, Params: 1,545,764 (5.897 MB), Total: 5.97 MB, FLOPs: 109,174,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 795/1724 finished in 0m09s\n",
      "Total channels prunned so far: 795\n",
      "\n",
      "Iteration 796 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.077 MB, Params: 1,543,562 (5.888 MB), Total: 5.97 MB, FLOPs: 109,148,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 796/1724 finished in 0m10s\n",
      "Total channels prunned so far: 796\n",
      "\n",
      "Iteration 797 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 244)]\n",
      "Input: 0.077 MB, Params: 1,541,360 (5.880 MB), Total: 5.96 MB, FLOPs: 109,121,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 797/1724 finished in 0m10s\n",
      "Total channels prunned so far: 797\n",
      "\n",
      "Iteration 798 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.077 MB, Params: 1,537,164 (5.864 MB), Total: 5.94 MB, FLOPs: 109,071,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 798/1724 finished in 0m10s\n",
      "Total channels prunned so far: 798\n",
      "\n",
      "Iteration 799 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 247)]\n",
      "Input: 0.077 MB, Params: 1,534,971 (5.855 MB), Total: 5.93 MB, FLOPs: 109,045,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 799/1724 finished in 0m10s\n",
      "Total channels prunned so far: 799\n",
      "\n",
      "Iteration 800 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 65)]\n",
      "Input: 0.077 MB, Params: 1,532,778 (5.847 MB), Total: 5.92 MB, FLOPs: 109,018,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 800/1724 finished in 0m10s\n",
      "Total channels prunned so far: 800\n",
      "\n",
      "Iteration 801 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 195)]\n",
      "Input: 0.077 MB, Params: 1,530,585 (5.839 MB), Total: 5.92 MB, FLOPs: 108,992,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 801/1724 finished in 0m10s\n",
      "Total channels prunned so far: 801\n",
      "\n",
      "Iteration 802 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.077 MB, Params: 1,526,416 (5.823 MB), Total: 5.90 MB, FLOPs: 108,942,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 802/1724 finished in 0m09s\n",
      "Total channels prunned so far: 802\n",
      "\n",
      "Iteration 803 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.077 MB, Params: 1,522,247 (5.807 MB), Total: 5.88 MB, FLOPs: 108,892,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 803/1724 finished in 0m10s\n",
      "Total channels prunned so far: 803\n",
      "\n",
      "Iteration 804 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 155)]\n",
      "Input: 0.077 MB, Params: 1,519,950 (5.798 MB), Total: 5.88 MB, FLOPs: 108,754,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 804/1724 finished in 0m10s\n",
      "Total channels prunned so far: 804\n",
      "\n",
      "Iteration 805 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.077 MB, Params: 1,515,781 (5.782 MB), Total: 5.86 MB, FLOPs: 108,704,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 805/1724 finished in 0m10s\n",
      "Total channels prunned so far: 805\n",
      "\n",
      "Iteration 806 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 149)]\n",
      "Input: 0.077 MB, Params: 1,512,224 (5.769 MB), Total: 5.85 MB, FLOPs: 108,595,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 806/1724 finished in 0m09s\n",
      "Total channels prunned so far: 806\n",
      "\n",
      "Iteration 807 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.077 MB, Params: 1,511,529 (5.766 MB), Total: 5.84 MB, FLOPs: 107,901,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 807/1724 finished in 0m09s\n",
      "Total channels prunned so far: 807\n",
      "\n",
      "Iteration 808 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.077 MB, Params: 1,509,241 (5.757 MB), Total: 5.83 MB, FLOPs: 107,763,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 808/1724 finished in 0m10s\n",
      "Total channels prunned so far: 808\n",
      "\n",
      "Iteration 809 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 68)]\n",
      "Input: 0.077 MB, Params: 1,506,953 (5.749 MB), Total: 5.83 MB, FLOPs: 107,626,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 809/1724 finished in 0m10s\n",
      "Total channels prunned so far: 809\n",
      "\n",
      "Iteration 810 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.077 MB, Params: 1,504,787 (5.740 MB), Total: 5.82 MB, FLOPs: 107,600,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 810/1724 finished in 0m10s\n",
      "Total channels prunned so far: 810\n",
      "\n",
      "Iteration 811 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 1,501,248 (5.727 MB), Total: 5.80 MB, FLOPs: 107,492,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 811/1724 finished in 0m09s\n",
      "Total channels prunned so far: 811\n",
      "\n",
      "Iteration 812 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.077 MB, Params: 1,498,969 (5.718 MB), Total: 5.79 MB, FLOPs: 107,355,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 812/1724 finished in 0m10s\n",
      "Total channels prunned so far: 812\n",
      "\n",
      "Iteration 813 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 25)]\n",
      "Input: 0.077 MB, Params: 1,497,707 (5.713 MB), Total: 5.79 MB, FLOPs: 106,694,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 813/1724 finished in 0m10s\n",
      "Total channels prunned so far: 813\n",
      "\n",
      "Iteration 814 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 1,495,541 (5.705 MB), Total: 5.78 MB, FLOPs: 106,668,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 814/1724 finished in 0m10s\n",
      "Total channels prunned so far: 814\n",
      "\n",
      "Iteration 815 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 86)]\n",
      "Input: 0.077 MB, Params: 1,494,216 (5.700 MB), Total: 5.78 MB, FLOPs: 106,337,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 815/1724 finished in 0m10s\n",
      "Total channels prunned so far: 815\n",
      "\n",
      "Iteration 816 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 93)]\n",
      "Input: 0.077 MB, Params: 1,490,686 (5.687 MB), Total: 5.76 MB, FLOPs: 106,229,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Finished fine tuning.\n",
      "Iteration 816/1724 finished in 0m09s\n",
      "Total channels prunned so far: 816\n",
      "\n",
      "Iteration 817 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.077 MB, Params: 1,486,562 (5.671 MB), Total: 5.75 MB, FLOPs: 106,179,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 817/1724 finished in 0m10s\n",
      "Total channels prunned so far: 817\n",
      "\n",
      "Iteration 818 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.077 MB, Params: 1,485,876 (5.668 MB), Total: 5.75 MB, FLOPs: 105,494,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 818/1724 finished in 0m09s\n",
      "Total channels prunned so far: 818\n",
      "\n",
      "Iteration 819 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.077 MB, Params: 1,483,606 (5.660 MB), Total: 5.74 MB, FLOPs: 105,358,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 819/1724 finished in 0m09s\n",
      "Total channels prunned so far: 819\n",
      "\n",
      "Iteration 820 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.077 MB, Params: 1,480,094 (5.646 MB), Total: 5.72 MB, FLOPs: 105,250,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 820/1724 finished in 0m10s\n",
      "Total channels prunned so far: 820\n",
      "\n",
      "Iteration 821 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.077 MB, Params: 1,475,979 (5.630 MB), Total: 5.71 MB, FLOPs: 105,201,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 821/1724 finished in 0m09s\n",
      "Total channels prunned so far: 821\n",
      "\n",
      "Iteration 822 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 160)]\n",
      "Input: 0.077 MB, Params: 1,471,864 (5.615 MB), Total: 5.69 MB, FLOPs: 105,152,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 822/1724 finished in 0m09s\n",
      "Total channels prunned so far: 822\n",
      "\n",
      "Iteration 823 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.077 MB, Params: 1,468,370 (5.601 MB), Total: 5.68 MB, FLOPs: 105,045,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 823/1724 finished in 0m09s\n",
      "Total channels prunned so far: 823\n",
      "\n",
      "Iteration 824 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 45)]\n",
      "Input: 0.077 MB, Params: 1,467,684 (5.599 MB), Total: 5.68 MB, FLOPs: 104,360,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 824/1724 finished in 0m10s\n",
      "Total channels prunned so far: 824\n",
      "\n",
      "Iteration 825 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.077 MB, Params: 1,465,545 (5.591 MB), Total: 5.67 MB, FLOPs: 104,334,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 825/1724 finished in 0m10s\n",
      "Total channels prunned so far: 825\n",
      "\n",
      "Iteration 826 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.077 MB, Params: 1,463,392 (5.582 MB), Total: 5.66 MB, FLOPs: 104,054,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 826/1724 finished in 0m10s\n",
      "Total channels prunned so far: 826\n",
      "\n",
      "Iteration 827 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.077 MB, Params: 1,459,295 (5.567 MB), Total: 5.64 MB, FLOPs: 104,005,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 827/1724 finished in 0m09s\n",
      "Total channels prunned so far: 827\n",
      "\n",
      "Iteration 828 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.077 MB, Params: 1,455,198 (5.551 MB), Total: 5.63 MB, FLOPs: 103,956,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 828/1724 finished in 0m10s\n",
      "Total channels prunned so far: 828\n",
      "\n",
      "Iteration 829 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.077 MB, Params: 1,453,882 (5.546 MB), Total: 5.62 MB, FLOPs: 103,627,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 829/1724 finished in 0m10s\n",
      "Total channels prunned so far: 829\n",
      "\n",
      "Iteration 830 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 16)]\n",
      "Input: 0.077 MB, Params: 1,453,430 (5.544 MB), Total: 5.62 MB, FLOPs: 103,141,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.257%\n",
      "Finished fine tuning.\n",
      "Iteration 830/1724 finished in 0m10s\n",
      "Total channels prunned so far: 830\n",
      "\n",
      "Iteration 831 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 185)]\n",
      "Input: 0.077 MB, Params: 1,449,333 (5.529 MB), Total: 5.61 MB, FLOPs: 103,092,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 831/1724 finished in 0m10s\n",
      "Total channels prunned so far: 831\n",
      "\n",
      "Iteration 832 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 1,447,090 (5.520 MB), Total: 5.60 MB, FLOPs: 102,957,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 832/1724 finished in 0m10s\n",
      "Total channels prunned so far: 832\n",
      "\n",
      "Iteration 833 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 262)]\n",
      "Input: 0.077 MB, Params: 1,444,978 (5.512 MB), Total: 5.59 MB, FLOPs: 102,932,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 833/1724 finished in 0m10s\n",
      "Total channels prunned so far: 833\n",
      "\n",
      "Iteration 834 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 1,440,890 (5.497 MB), Total: 5.57 MB, FLOPs: 102,883,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 834/1724 finished in 0m09s\n",
      "Total channels prunned so far: 834\n",
      "\n",
      "Iteration 835 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.077 MB, Params: 1,436,802 (5.481 MB), Total: 5.56 MB, FLOPs: 102,834,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 835/1724 finished in 0m10s\n",
      "Total channels prunned so far: 835\n",
      "\n",
      "Iteration 836 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.077 MB, Params: 1,432,714 (5.465 MB), Total: 5.54 MB, FLOPs: 102,785,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 836/1724 finished in 0m09s\n",
      "Total channels prunned so far: 836\n",
      "\n",
      "Iteration 837 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 1,428,626 (5.450 MB), Total: 5.53 MB, FLOPs: 102,736,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Finished fine tuning.\n",
      "Iteration 837/1724 finished in 0m09s\n",
      "Total channels prunned so far: 837\n",
      "\n",
      "Iteration 838 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.077 MB, Params: 1,426,550 (5.442 MB), Total: 5.52 MB, FLOPs: 102,711,260\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 838/1724 finished in 0m10s\n",
      "Total channels prunned so far: 838\n",
      "\n",
      "Iteration 839 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 2)]\n",
      "Input: 0.077 MB, Params: 1,426,513 (5.442 MB), Total: 5.52 MB, FLOPs: 102,502,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 839/1724 finished in 0m10s\n",
      "Total channels prunned so far: 839\n",
      "\n",
      "Iteration 840 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 149)]\n",
      "Input: 0.077 MB, Params: 1,424,270 (5.433 MB), Total: 5.51 MB, FLOPs: 102,367,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 840/1724 finished in 0m10s\n",
      "Total channels prunned so far: 840\n",
      "\n",
      "Iteration 841 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 1,420,857 (5.420 MB), Total: 5.50 MB, FLOPs: 102,262,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 841/1724 finished in 0m09s\n",
      "Total channels prunned so far: 841\n",
      "\n",
      "Iteration 842 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.077 MB, Params: 1,417,444 (5.407 MB), Total: 5.48 MB, FLOPs: 102,156,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 842/1724 finished in 0m09s\n",
      "Total channels prunned so far: 842\n",
      "\n",
      "Iteration 843 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 26)]\n",
      "Input: 0.077 MB, Params: 1,414,031 (5.394 MB), Total: 5.47 MB, FLOPs: 102,051,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 843/1724 finished in 0m09s\n",
      "Total channels prunned so far: 843\n",
      "\n",
      "Iteration 844 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.077 MB, Params: 1,411,955 (5.386 MB), Total: 5.46 MB, FLOPs: 102,026,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 844/1724 finished in 0m10s\n",
      "Total channels prunned so far: 844\n",
      "\n",
      "Iteration 845 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 188)]\n",
      "Input: 0.077 MB, Params: 1,407,912 (5.371 MB), Total: 5.45 MB, FLOPs: 101,977,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 845/1724 finished in 0m09s\n",
      "Total channels prunned so far: 845\n",
      "\n",
      "Iteration 846 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 1,404,508 (5.358 MB), Total: 5.43 MB, FLOPs: 101,872,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 846/1724 finished in 0m09s\n",
      "Total channels prunned so far: 846\n",
      "\n",
      "Iteration 847 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.077 MB, Params: 1,400,474 (5.342 MB), Total: 5.42 MB, FLOPs: 101,824,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 847/1724 finished in 0m10s\n",
      "Total channels prunned so far: 847\n",
      "\n",
      "Iteration 848 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 19)]\n",
      "Input: 0.077 MB, Params: 1,399,158 (5.337 MB), Total: 5.41 MB, FLOPs: 101,495,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 848/1724 finished in 0m10s\n",
      "Total channels prunned so far: 848\n",
      "\n",
      "Iteration 849 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.077 MB, Params: 1,397,842 (5.332 MB), Total: 5.41 MB, FLOPs: 101,166,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 849/1724 finished in 0m10s\n",
      "Total channels prunned so far: 849\n",
      "\n",
      "Iteration 850 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 87)]\n",
      "Input: 0.077 MB, Params: 1,395,635 (5.324 MB), Total: 5.40 MB, FLOPs: 101,034,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 850/1724 finished in 0m10s\n",
      "Total channels prunned so far: 850\n",
      "\n",
      "Iteration 851 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 109)]\n",
      "Input: 0.077 MB, Params: 1,392,249 (5.311 MB), Total: 5.39 MB, FLOPs: 100,929,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 851/1724 finished in 0m10s\n",
      "Total channels prunned so far: 851\n",
      "\n",
      "Iteration 852 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.077 MB, Params: 1,388,863 (5.298 MB), Total: 5.37 MB, FLOPs: 100,825,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 852/1724 finished in 0m09s\n",
      "Total channels prunned so far: 852\n",
      "\n",
      "Iteration 853 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.077 MB, Params: 1,386,805 (5.290 MB), Total: 5.37 MB, FLOPs: 100,800,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Finished fine tuning.\n",
      "Iteration 853/1724 finished in 0m10s\n",
      "Total channels prunned so far: 853\n",
      "\n",
      "Iteration 854 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.077 MB, Params: 1,384,706 (5.282 MB), Total: 5.36 MB, FLOPs: 100,528,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 854/1724 finished in 0m10s\n",
      "Total channels prunned so far: 854\n",
      "\n",
      "Iteration 855 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.077 MB, Params: 1,380,699 (5.267 MB), Total: 5.34 MB, FLOPs: 100,480,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 855/1724 finished in 0m10s\n",
      "Total channels prunned so far: 855\n",
      "\n",
      "Iteration 856 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.077 MB, Params: 1,376,692 (5.252 MB), Total: 5.33 MB, FLOPs: 100,432,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.164%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 856/1724 finished in 0m10s\n",
      "Total channels prunned so far: 856\n",
      "\n",
      "Iteration 857 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 161)]\n",
      "Input: 0.077 MB, Params: 1,372,685 (5.236 MB), Total: 5.31 MB, FLOPs: 100,384,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 857/1724 finished in 0m10s\n",
      "Total channels prunned so far: 857\n",
      "\n",
      "Iteration 858 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.077 MB, Params: 1,370,654 (5.229 MB), Total: 5.31 MB, FLOPs: 100,360,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 858/1724 finished in 0m10s\n",
      "Total channels prunned so far: 858\n",
      "\n",
      "Iteration 859 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.077 MB, Params: 1,369,347 (5.224 MB), Total: 5.30 MB, FLOPs: 100,033,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 859/1724 finished in 0m10s\n",
      "Total channels prunned so far: 859\n",
      "\n",
      "Iteration 860 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.077 MB, Params: 1,365,988 (5.211 MB), Total: 5.29 MB, FLOPs: 99,929,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 860/1724 finished in 0m10s\n",
      "Total channels prunned so far: 860\n",
      "\n",
      "Iteration 861 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 45)]\n",
      "Input: 0.077 MB, Params: 1,363,957 (5.203 MB), Total: 5.28 MB, FLOPs: 99,905,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 861/1724 finished in 0m10s\n",
      "Total channels prunned so far: 861\n",
      "\n",
      "Iteration 862 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.077 MB, Params: 1,363,505 (5.201 MB), Total: 5.28 MB, FLOPs: 99,420,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Finished fine tuning.\n",
      "Iteration 862/1724 finished in 0m10s\n",
      "Total channels prunned so far: 862\n",
      "\n",
      "Iteration 863 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 38)]\n",
      "Input: 0.077 MB, Params: 1,362,306 (5.197 MB), Total: 5.27 MB, FLOPs: 98,788,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 863/1724 finished in 0m10s\n",
      "Total channels prunned so far: 863\n",
      "\n",
      "Iteration 864 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.077 MB, Params: 1,360,275 (5.189 MB), Total: 5.27 MB, FLOPs: 98,763,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 864/1724 finished in 0m10s\n",
      "Total channels prunned so far: 864\n",
      "\n",
      "Iteration 865 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.077 MB, Params: 1,356,304 (5.174 MB), Total: 5.25 MB, FLOPs: 98,716,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 865/1724 finished in 0m10s\n",
      "Total channels prunned so far: 865\n",
      "\n",
      "Iteration 866 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.077 MB, Params: 1,352,333 (5.159 MB), Total: 5.24 MB, FLOPs: 98,668,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.978%\n",
      "Finished fine tuning.\n",
      "Iteration 866/1724 finished in 0m10s\n",
      "Total channels prunned so far: 866\n",
      "\n",
      "Iteration 867 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 258)]\n",
      "Input: 0.077 MB, Params: 1,350,320 (5.151 MB), Total: 5.23 MB, FLOPs: 98,644,280\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 867/1724 finished in 0m10s\n",
      "Total channels prunned so far: 867\n",
      "\n",
      "Iteration 868 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.077 MB, Params: 1,349,022 (5.146 MB), Total: 5.22 MB, FLOPs: 98,320,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Finished fine tuning.\n",
      "Iteration 868/1724 finished in 0m10s\n",
      "Total channels prunned so far: 868\n",
      "\n",
      "Iteration 869 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.077 MB, Params: 1,345,681 (5.133 MB), Total: 5.21 MB, FLOPs: 98,215,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 869/1724 finished in 0m11s\n",
      "Total channels prunned so far: 869\n",
      "\n",
      "Iteration 870 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 122)]\n",
      "Input: 0.077 MB, Params: 1,343,519 (5.125 MB), Total: 5.20 MB, FLOPs: 98,086,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.071%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 870/1724 finished in 0m10s\n",
      "Total channels prunned so far: 870\n",
      "\n",
      "Iteration 871 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 18)]\n",
      "Input: 0.077 MB, Params: 1,342,329 (5.121 MB), Total: 5.20 MB, FLOPs: 97,456,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 871/1724 finished in 0m10s\n",
      "Total channels prunned so far: 871\n",
      "\n",
      "Iteration 872 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 1,340,316 (5.113 MB), Total: 5.19 MB, FLOPs: 97,432,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 872/1724 finished in 0m10s\n",
      "Total channels prunned so far: 872\n",
      "\n",
      "Iteration 873 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.077 MB, Params: 1,338,154 (5.105 MB), Total: 5.18 MB, FLOPs: 97,302,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 873/1724 finished in 0m10s\n",
      "Total channels prunned so far: 873\n",
      "\n",
      "Iteration 874 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 68)]\n",
      "Input: 0.077 MB, Params: 1,336,091 (5.097 MB), Total: 5.17 MB, FLOPs: 97,036,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.617%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 874/1724 finished in 0m10s\n",
      "Total channels prunned so far: 874\n",
      "\n",
      "Iteration 875 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 10)]\n",
      "Input: 0.077 MB, Params: 1,336,054 (5.097 MB), Total: 5.17 MB, FLOPs: 88,793,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 875/1724 finished in 0m17s\n",
      "Total channels prunned so far: 875\n",
      "\n",
      "Iteration 876 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.077 MB, Params: 1,334,041 (5.089 MB), Total: 5.17 MB, FLOPs: 88,769,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 876/1724 finished in 0m11s\n",
      "Total channels prunned so far: 876\n",
      "\n",
      "Iteration 877 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 1,331,888 (5.081 MB), Total: 5.16 MB, FLOPs: 88,666,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 877/1724 finished in 0m10s\n",
      "Total channels prunned so far: 877\n",
      "\n",
      "Iteration 878 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 63)]\n",
      "Input: 0.077 MB, Params: 1,329,834 (5.073 MB), Total: 5.15 MB, FLOPs: 88,435,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 878/1724 finished in 0m10s\n",
      "Total channels prunned so far: 878\n",
      "\n",
      "Iteration 879 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.077 MB, Params: 1,326,520 (5.060 MB), Total: 5.14 MB, FLOPs: 88,348,397\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 879/1724 finished in 0m10s\n",
      "Total channels prunned so far: 879\n",
      "\n",
      "Iteration 880 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.077 MB, Params: 1,323,206 (5.048 MB), Total: 5.12 MB, FLOPs: 88,261,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 880/1724 finished in 0m10s\n",
      "Total channels prunned so far: 880\n",
      "\n",
      "Iteration 881 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 83)]\n",
      "Input: 0.077 MB, Params: 1,321,152 (5.040 MB), Total: 5.12 MB, FLOPs: 88,030,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 881/1724 finished in 0m10s\n",
      "Total channels prunned so far: 881\n",
      "\n",
      "Iteration 882 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.077 MB, Params: 1,319,035 (5.032 MB), Total: 5.11 MB, FLOPs: 87,928,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 882/1724 finished in 0m10s\n",
      "Total channels prunned so far: 882\n",
      "\n",
      "Iteration 883 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.077 MB, Params: 1,317,022 (5.024 MB), Total: 5.10 MB, FLOPs: 87,904,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 883/1724 finished in 0m11s\n",
      "Total channels prunned so far: 883\n",
      "\n",
      "Iteration 884 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.077 MB, Params: 1,314,905 (5.016 MB), Total: 5.09 MB, FLOPs: 87,803,189\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 884/1724 finished in 0m10s\n",
      "Total channels prunned so far: 884\n",
      "\n",
      "Iteration 885 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.077 MB, Params: 1,310,997 (5.001 MB), Total: 5.08 MB, FLOPs: 87,756,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 885/1724 finished in 0m10s\n",
      "Total channels prunned so far: 885\n",
      "\n",
      "Iteration 886 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 74)]\n",
      "Input: 0.077 MB, Params: 1,307,710 (4.989 MB), Total: 5.07 MB, FLOPs: 87,670,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Finished fine tuning.\n",
      "Iteration 886/1724 finished in 0m10s\n",
      "Total channels prunned so far: 886\n",
      "\n",
      "Iteration 887 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.077 MB, Params: 1,303,811 (4.974 MB), Total: 5.05 MB, FLOPs: 87,623,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.885%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 887/1724 finished in 0m10s\n",
      "Total channels prunned so far: 887\n",
      "\n",
      "Iteration 888 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.077 MB, Params: 1,300,533 (4.961 MB), Total: 5.04 MB, FLOPs: 87,537,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 888/1724 finished in 0m09s\n",
      "Total channels prunned so far: 888\n",
      "\n",
      "Iteration 889 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.077 MB, Params: 1,298,538 (4.954 MB), Total: 5.03 MB, FLOPs: 87,514,037\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 889/1724 finished in 0m10s\n",
      "Total channels prunned so far: 889\n",
      "\n",
      "Iteration 890 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.077 MB, Params: 1,296,439 (4.946 MB), Total: 5.02 MB, FLOPs: 87,413,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 890/1724 finished in 0m10s\n",
      "Total channels prunned so far: 890\n",
      "\n",
      "Iteration 891 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.077 MB, Params: 1,292,558 (4.931 MB), Total: 5.01 MB, FLOPs: 87,366,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 891/1724 finished in 0m10s\n",
      "Total channels prunned so far: 891\n",
      "\n",
      "Iteration 892 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.077 MB, Params: 1,288,677 (4.916 MB), Total: 4.99 MB, FLOPs: 87,320,213\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 892/1724 finished in 0m10s\n",
      "Total channels prunned so far: 892\n",
      "\n",
      "Iteration 893 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 1,284,796 (4.901 MB), Total: 4.98 MB, FLOPs: 87,273,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 893/1724 finished in 0m10s\n",
      "Total channels prunned so far: 893\n",
      "\n",
      "Iteration 894 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 1,280,915 (4.886 MB), Total: 4.96 MB, FLOPs: 87,227,093\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 894/1724 finished in 0m10s\n",
      "Total channels prunned so far: 894\n",
      "\n",
      "Iteration 895 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.077 MB, Params: 1,278,816 (4.878 MB), Total: 4.96 MB, FLOPs: 87,126,389\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 895/1724 finished in 0m10s\n",
      "Total channels prunned so far: 895\n",
      "\n",
      "Iteration 896 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.077 MB, Params: 1,274,935 (4.863 MB), Total: 4.94 MB, FLOPs: 87,079,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 896/1724 finished in 0m10s\n",
      "Total channels prunned so far: 896\n",
      "\n",
      "Iteration 897 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 1,271,054 (4.849 MB), Total: 4.93 MB, FLOPs: 87,033,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 897/1724 finished in 0m10s\n",
      "Total channels prunned so far: 897\n",
      "\n",
      "Iteration 898 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.077 MB, Params: 1,267,173 (4.834 MB), Total: 4.91 MB, FLOPs: 86,986,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 898/1724 finished in 0m10s\n",
      "Total channels prunned so far: 898\n",
      "\n",
      "Iteration 899 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.077 MB, Params: 1,263,976 (4.822 MB), Total: 4.90 MB, FLOPs: 86,902,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 899/1724 finished in 0m10s\n",
      "Total channels prunned so far: 899\n",
      "\n",
      "Iteration 900 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.077 MB, Params: 1,262,714 (4.817 MB), Total: 4.89 MB, FLOPs: 86,618,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 900/1724 finished in 0m10s\n",
      "Total channels prunned so far: 900\n",
      "\n",
      "Iteration 901 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 11)]\n",
      "Input: 0.077 MB, Params: 1,262,064 (4.814 MB), Total: 4.89 MB, FLOPs: 86,002,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 901/1724 finished in 0m10s\n",
      "Total channels prunned so far: 901\n",
      "\n",
      "Iteration 902 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.077 MB, Params: 1,260,132 (4.807 MB), Total: 4.88 MB, FLOPs: 85,979,166\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 902/1724 finished in 0m10s\n",
      "Total channels prunned so far: 902\n",
      "\n",
      "Iteration 903 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.077 MB, Params: 1,258,200 (4.800 MB), Total: 4.88 MB, FLOPs: 85,956,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 903/1724 finished in 0m10s\n",
      "Total channels prunned so far: 903\n",
      "\n",
      "Iteration 904 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 34)]\n",
      "Input: 0.077 MB, Params: 1,256,191 (4.792 MB), Total: 4.87 MB, FLOPs: 85,728,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 904/1724 finished in 0m10s\n",
      "Total channels prunned so far: 904\n",
      "\n",
      "Iteration 905 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.077 MB, Params: 1,252,337 (4.777 MB), Total: 4.85 MB, FLOPs: 85,682,403\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 905/1724 finished in 0m10s\n",
      "Total channels prunned so far: 905\n",
      "\n",
      "Iteration 906 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.077 MB, Params: 1,250,414 (4.770 MB), Total: 4.85 MB, FLOPs: 85,659,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 906/1724 finished in 0m10s\n",
      "Total channels prunned so far: 906\n",
      "\n",
      "Iteration 907 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 1,246,569 (4.755 MB), Total: 4.83 MB, FLOPs: 85,613,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Finished fine tuning.\n",
      "Iteration 907/1724 finished in 0m10s\n",
      "Total channels prunned so far: 907\n",
      "\n",
      "Iteration 908 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.077 MB, Params: 1,245,919 (4.753 MB), Total: 4.83 MB, FLOPs: 84,996,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 908/1724 finished in 0m10s\n",
      "Total channels prunned so far: 908\n",
      "\n",
      "Iteration 909 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.077 MB, Params: 1,242,740 (4.741 MB), Total: 4.82 MB, FLOPs: 84,912,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 909/1724 finished in 0m10s\n",
      "Total channels prunned so far: 909\n",
      "\n",
      "Iteration 910 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.077 MB, Params: 1,239,561 (4.729 MB), Total: 4.81 MB, FLOPs: 84,828,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 910/1724 finished in 0m10s\n",
      "Total channels prunned so far: 910\n",
      "\n",
      "Iteration 911 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 136)]\n",
      "Input: 0.077 MB, Params: 1,236,382 (4.716 MB), Total: 4.79 MB, FLOPs: 84,744,973\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 911/1724 finished in 0m11s\n",
      "Total channels prunned so far: 911\n",
      "\n",
      "Iteration 912 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.077 MB, Params: 1,234,468 (4.709 MB), Total: 4.79 MB, FLOPs: 84,722,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 912/1724 finished in 0m10s\n",
      "Total channels prunned so far: 912\n",
      "\n",
      "Iteration 913 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 157)]\n",
      "Input: 0.077 MB, Params: 1,230,659 (4.695 MB), Total: 4.77 MB, FLOPs: 84,676,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 913/1724 finished in 0m10s\n",
      "Total channels prunned so far: 913\n",
      "\n",
      "Iteration 914 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.077 MB, Params: 1,226,850 (4.680 MB), Total: 4.76 MB, FLOPs: 84,630,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 914/1724 finished in 0m10s\n",
      "Total channels prunned so far: 914\n",
      "\n",
      "Iteration 915 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.077 MB, Params: 1,223,041 (4.666 MB), Total: 4.74 MB, FLOPs: 84,584,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 915/1724 finished in 0m10s\n",
      "Total channels prunned so far: 915\n",
      "\n",
      "Iteration 916 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.077 MB, Params: 1,221,154 (4.658 MB), Total: 4.74 MB, FLOPs: 84,562,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 916/1724 finished in 0m10s\n",
      "Total channels prunned so far: 916\n",
      "\n",
      "Iteration 917 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.077 MB, Params: 1,219,267 (4.651 MB), Total: 4.73 MB, FLOPs: 84,539,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 917/1724 finished in 0m10s\n",
      "Total channels prunned so far: 917\n",
      "\n",
      "Iteration 918 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 1,215,476 (4.637 MB), Total: 4.71 MB, FLOPs: 84,494,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 918/1724 finished in 0m10s\n",
      "Total channels prunned so far: 918\n",
      "\n",
      "Iteration 919 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 1,213,598 (4.630 MB), Total: 4.71 MB, FLOPs: 84,471,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 919/1724 finished in 0m10s\n",
      "Total channels prunned so far: 919\n",
      "\n",
      "Iteration 920 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.077 MB, Params: 1,210,455 (4.618 MB), Total: 4.69 MB, FLOPs: 84,388,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 920/1724 finished in 0m11s\n",
      "Total channels prunned so far: 920\n",
      "\n",
      "Iteration 921 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.077 MB, Params: 1,208,577 (4.610 MB), Total: 4.69 MB, FLOPs: 84,365,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 921/1724 finished in 0m10s\n",
      "Total channels prunned so far: 921\n",
      "\n",
      "Iteration 922 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.077 MB, Params: 1,204,813 (4.596 MB), Total: 4.67 MB, FLOPs: 84,320,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 922/1724 finished in 0m10s\n",
      "Total channels prunned so far: 922\n",
      "\n",
      "Iteration 923 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.077 MB, Params: 1,202,768 (4.588 MB), Total: 4.67 MB, FLOPs: 84,222,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 923/1724 finished in 0m09s\n",
      "Total channels prunned so far: 923\n",
      "\n",
      "Iteration 924 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.077 MB, Params: 1,201,515 (4.583 MB), Total: 4.66 MB, FLOPs: 83,940,817\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 924/1724 finished in 0m10s\n",
      "Total channels prunned so far: 924\n",
      "\n",
      "Iteration 925 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.077 MB, Params: 1,200,262 (4.579 MB), Total: 4.66 MB, FLOPs: 83,659,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 925/1724 finished in 0m11s\n",
      "Total channels prunned so far: 925\n",
      "\n",
      "Iteration 926 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 87)]\n",
      "Input: 0.077 MB, Params: 1,198,280 (4.571 MB), Total: 4.65 MB, FLOPs: 83,436,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 926/1724 finished in 0m11s\n",
      "Total channels prunned so far: 926\n",
      "\n",
      "Iteration 927 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.077 MB, Params: 1,194,516 (4.557 MB), Total: 4.63 MB, FLOPs: 83,391,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 927/1724 finished in 0m10s\n",
      "Total channels prunned so far: 927\n",
      "\n",
      "Iteration 928 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.077 MB, Params: 1,192,656 (4.550 MB), Total: 4.63 MB, FLOPs: 83,368,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 928/1724 finished in 0m10s\n",
      "Total channels prunned so far: 928\n",
      "\n",
      "Iteration 929 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.077 MB, Params: 1,188,901 (4.535 MB), Total: 4.61 MB, FLOPs: 83,323,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 929/1724 finished in 0m10s\n",
      "Total channels prunned so far: 929\n",
      "\n",
      "Iteration 930 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.077 MB, Params: 1,185,146 (4.521 MB), Total: 4.60 MB, FLOPs: 83,278,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 930/1724 finished in 0m10s\n",
      "Total channels prunned so far: 930\n",
      "\n",
      "Iteration 931 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 1,181,391 (4.507 MB), Total: 4.58 MB, FLOPs: 83,233,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 931/1724 finished in 0m10s\n",
      "Total channels prunned so far: 931\n",
      "\n",
      "Iteration 932 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.077 MB, Params: 1,179,558 (4.500 MB), Total: 4.58 MB, FLOPs: 83,211,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 932/1724 finished in 0m10s\n",
      "Total channels prunned so far: 932\n",
      "\n",
      "Iteration 933 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.077 MB, Params: 1,176,469 (4.488 MB), Total: 4.56 MB, FLOPs: 83,129,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 933/1724 finished in 0m10s\n",
      "Total channels prunned so far: 933\n",
      "\n",
      "Iteration 934 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.077 MB, Params: 1,174,442 (4.480 MB), Total: 4.56 MB, FLOPs: 83,031,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 934/1724 finished in 0m10s\n",
      "Total channels prunned so far: 934\n",
      "\n",
      "Iteration 935 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 137)]\n",
      "Input: 0.077 MB, Params: 1,172,415 (4.472 MB), Total: 4.55 MB, FLOPs: 82,934,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 935/1724 finished in 0m09s\n",
      "Total channels prunned so far: 935\n",
      "\n",
      "Iteration 936 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.077 MB, Params: 1,170,388 (4.465 MB), Total: 4.54 MB, FLOPs: 82,837,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 936/1724 finished in 0m10s\n",
      "Total channels prunned so far: 936\n",
      "\n",
      "Iteration 937 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 69)]\n",
      "Input: 0.077 MB, Params: 1,169,144 (4.460 MB), Total: 4.54 MB, FLOPs: 82,557,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 937/1724 finished in 0m10s\n",
      "Total channels prunned so far: 937\n",
      "\n",
      "Iteration 938 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.077 MB, Params: 1,165,407 (4.446 MB), Total: 4.52 MB, FLOPs: 82,512,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 938/1724 finished in 0m10s\n",
      "Total channels prunned so far: 938\n",
      "\n",
      "Iteration 939 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 1,162,354 (4.434 MB), Total: 4.51 MB, FLOPs: 82,431,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 939/1724 finished in 0m10s\n",
      "Total channels prunned so far: 939\n",
      "\n",
      "Iteration 940 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.077 MB, Params: 1,160,408 (4.427 MB), Total: 4.50 MB, FLOPs: 82,212,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 940/1724 finished in 0m11s\n",
      "Total channels prunned so far: 940\n",
      "\n",
      "Iteration 941 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.077 MB, Params: 1,157,355 (4.415 MB), Total: 4.49 MB, FLOPs: 82,131,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 941/1724 finished in 0m11s\n",
      "Total channels prunned so far: 941\n",
      "\n",
      "Iteration 942 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 113)]\n",
      "Input: 0.077 MB, Params: 1,154,302 (4.403 MB), Total: 4.48 MB, FLOPs: 82,050,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 942/1724 finished in 0m11s\n",
      "Total channels prunned so far: 942\n",
      "\n",
      "Iteration 943 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.077 MB, Params: 1,150,592 (4.389 MB), Total: 4.47 MB, FLOPs: 82,005,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 943/1724 finished in 0m10s\n",
      "Total channels prunned so far: 943\n",
      "\n",
      "Iteration 944 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.077 MB, Params: 1,147,548 (4.378 MB), Total: 4.45 MB, FLOPs: 81,924,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 944/1724 finished in 0m10s\n",
      "Total channels prunned so far: 944\n",
      "\n",
      "Iteration 945 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.077 MB, Params: 1,145,566 (4.370 MB), Total: 4.45 MB, FLOPs: 81,829,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 945/1724 finished in 0m10s\n",
      "Total channels prunned so far: 945\n",
      "\n",
      "Iteration 946 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.077 MB, Params: 1,141,865 (4.356 MB), Total: 4.43 MB, FLOPs: 81,785,077\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 946/1724 finished in 0m10s\n",
      "Total channels prunned so far: 946\n",
      "\n",
      "Iteration 947 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.077 MB, Params: 1,139,883 (4.348 MB), Total: 4.43 MB, FLOPs: 81,689,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 947/1724 finished in 0m09s\n",
      "Total channels prunned so far: 947\n",
      "\n",
      "Iteration 948 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.077 MB, Params: 1,136,182 (4.334 MB), Total: 4.41 MB, FLOPs: 81,645,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 948/1724 finished in 0m10s\n",
      "Total channels prunned so far: 948\n",
      "\n",
      "Iteration 949 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 79)]\n",
      "Input: 0.077 MB, Params: 1,134,200 (4.327 MB), Total: 4.40 MB, FLOPs: 81,550,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 949/1724 finished in 0m10s\n",
      "Total channels prunned so far: 949\n",
      "\n",
      "Iteration 950 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.077 MB, Params: 1,131,201 (4.315 MB), Total: 4.39 MB, FLOPs: 81,471,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 950/1724 finished in 0m10s\n",
      "Total channels prunned so far: 950\n",
      "\n",
      "Iteration 951 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 58)]\n",
      "Input: 0.077 MB, Params: 1,129,282 (4.308 MB), Total: 4.38 MB, FLOPs: 81,252,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 951/1724 finished in 0m10s\n",
      "Total channels prunned so far: 951\n",
      "\n",
      "Iteration 952 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.077 MB, Params: 1,126,283 (4.296 MB), Total: 4.37 MB, FLOPs: 81,173,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 952/1724 finished in 0m10s\n",
      "Total channels prunned so far: 952\n",
      "\n",
      "Iteration 953 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.077 MB, Params: 1,122,600 (4.282 MB), Total: 4.36 MB, FLOPs: 81,129,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 953/1724 finished in 0m10s\n",
      "Total channels prunned so far: 953\n",
      "\n",
      "Iteration 954 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 1,118,917 (4.268 MB), Total: 4.35 MB, FLOPs: 81,084,901\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 954/1724 finished in 0m10s\n",
      "Total channels prunned so far: 954\n",
      "\n",
      "Iteration 955 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.077 MB, Params: 1,117,138 (4.262 MB), Total: 4.34 MB, FLOPs: 81,063,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 955/1724 finished in 0m10s\n",
      "Total channels prunned so far: 955\n",
      "\n",
      "Iteration 956 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 8)]\n",
      "Input: 0.077 MB, Params: 1,116,002 (4.257 MB), Total: 4.33 MB, FLOPs: 80,499,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 956/1724 finished in 0m10s\n",
      "Total channels prunned so far: 956\n",
      "\n",
      "Iteration 957 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.077 MB, Params: 1,112,328 (4.243 MB), Total: 4.32 MB, FLOPs: 80,455,838\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 957/1724 finished in 0m10s\n",
      "Total channels prunned so far: 957\n",
      "\n",
      "Iteration 958 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.077 MB, Params: 1,110,558 (4.236 MB), Total: 4.31 MB, FLOPs: 80,434,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 958/1724 finished in 0m10s\n",
      "Total channels prunned so far: 958\n",
      "\n",
      "Iteration 959 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 217)]\n",
      "Input: 0.077 MB, Params: 1,108,788 (4.230 MB), Total: 4.31 MB, FLOPs: 80,413,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 959/1724 finished in 0m10s\n",
      "Total channels prunned so far: 959\n",
      "\n",
      "Iteration 960 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.077 MB, Params: 1,105,132 (4.216 MB), Total: 4.29 MB, FLOPs: 80,369,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 960/1724 finished in 0m10s\n",
      "Total channels prunned so far: 960\n",
      "\n",
      "Iteration 961 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 19)]\n",
      "Input: 0.077 MB, Params: 1,105,095 (4.216 MB), Total: 4.29 MB, FLOPs: 80,161,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 961/1724 finished in 0m11s\n",
      "Total channels prunned so far: 961\n",
      "\n",
      "Iteration 962 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.077 MB, Params: 1,103,334 (4.209 MB), Total: 4.29 MB, FLOPs: 80,140,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 962/1724 finished in 0m10s\n",
      "Total channels prunned so far: 962\n",
      "\n",
      "Iteration 963 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.077 MB, Params: 1,102,693 (4.206 MB), Total: 4.28 MB, FLOPs: 79,532,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 963/1724 finished in 0m10s\n",
      "Total channels prunned so far: 963\n",
      "\n",
      "Iteration 964 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.077 MB, Params: 1,100,738 (4.199 MB), Total: 4.28 MB, FLOPs: 79,438,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 964/1724 finished in 0m09s\n",
      "Total channels prunned so far: 964\n",
      "\n",
      "Iteration 965 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 60)]\n",
      "Input: 0.077 MB, Params: 1,098,783 (4.192 MB), Total: 4.27 MB, FLOPs: 79,344,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 965/1724 finished in 0m09s\n",
      "Total channels prunned so far: 965\n",
      "\n",
      "Iteration 966 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.077 MB, Params: 1,097,022 (4.185 MB), Total: 4.26 MB, FLOPs: 79,323,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 966/1724 finished in 0m10s\n",
      "Total channels prunned so far: 966\n",
      "\n",
      "Iteration 967 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.077 MB, Params: 1,093,384 (4.171 MB), Total: 4.25 MB, FLOPs: 79,279,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 967/1724 finished in 0m10s\n",
      "Total channels prunned so far: 967\n",
      "\n",
      "Iteration 968 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 68)]\n",
      "Input: 0.077 MB, Params: 1,091,483 (4.164 MB), Total: 4.24 MB, FLOPs: 79,062,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 968/1724 finished in 0m10s\n",
      "Total channels prunned so far: 968\n",
      "\n",
      "Iteration 969 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.077 MB, Params: 1,088,547 (4.152 MB), Total: 4.23 MB, FLOPs: 78,984,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 969/1724 finished in 0m10s\n",
      "Total channels prunned so far: 969\n",
      "\n",
      "Iteration 970 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.077 MB, Params: 1,086,610 (4.145 MB), Total: 4.22 MB, FLOPs: 78,891,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 970/1724 finished in 0m10s\n",
      "Total channels prunned so far: 970\n",
      "\n",
      "Iteration 971 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 128)]\n",
      "Input: 0.077 MB, Params: 1,084,673 (4.138 MB), Total: 4.21 MB, FLOPs: 78,798,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 971/1724 finished in 0m10s\n",
      "Total channels prunned so far: 971\n",
      "\n",
      "Iteration 972 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 1,082,736 (4.130 MB), Total: 4.21 MB, FLOPs: 78,705,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 972/1724 finished in 0m10s\n",
      "Total channels prunned so far: 972\n",
      "\n",
      "Iteration 973 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.077 MB, Params: 1,079,107 (4.116 MB), Total: 4.19 MB, FLOPs: 78,662,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 973/1724 finished in 0m10s\n",
      "Total channels prunned so far: 973\n",
      "\n",
      "Iteration 974 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 258)]\n",
      "Input: 0.077 MB, Params: 1,077,364 (4.110 MB), Total: 4.19 MB, FLOPs: 78,641,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 974/1724 finished in 0m10s\n",
      "Total channels prunned so far: 974\n",
      "\n",
      "Iteration 975 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.077 MB, Params: 1,073,744 (4.096 MB), Total: 4.17 MB, FLOPs: 78,597,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 975/1724 finished in 0m10s\n",
      "Total channels prunned so far: 975\n",
      "\n",
      "Iteration 976 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.077 MB, Params: 1,072,010 (4.089 MB), Total: 4.17 MB, FLOPs: 78,577,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 976/1724 finished in 0m10s\n",
      "Total channels prunned so far: 976\n",
      "\n",
      "Iteration 977 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.077 MB, Params: 1,070,136 (4.082 MB), Total: 4.16 MB, FLOPs: 78,360,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 977/1724 finished in 0m10s\n",
      "Total channels prunned so far: 977\n",
      "\n",
      "Iteration 978 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.077 MB, Params: 1,068,402 (4.076 MB), Total: 4.15 MB, FLOPs: 78,340,146\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 978/1724 finished in 0m10s\n",
      "Total channels prunned so far: 978\n",
      "\n",
      "Iteration 979 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 67)]\n",
      "Input: 0.077 MB, Params: 1,066,528 (4.068 MB), Total: 4.15 MB, FLOPs: 78,124,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 979/1724 finished in 0m10s\n",
      "Total channels prunned so far: 979\n",
      "\n",
      "Iteration 980 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.077 MB, Params: 1,065,338 (4.064 MB), Total: 4.14 MB, FLOPs: 77,856,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 980/1724 finished in 0m10s\n",
      "Total channels prunned so far: 980\n",
      "\n",
      "Iteration 981 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 126)]\n",
      "Input: 0.077 MB, Params: 1,063,419 (4.057 MB), Total: 4.13 MB, FLOPs: 77,764,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 981/1724 finished in 0m11s\n",
      "Total channels prunned so far: 981\n",
      "\n",
      "Iteration 982 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.077 MB, Params: 1,061,685 (4.050 MB), Total: 4.13 MB, FLOPs: 77,743,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 982/1724 finished in 0m10s\n",
      "Total channels prunned so far: 982\n",
      "\n",
      "Iteration 983 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 254)]\n",
      "Input: 0.077 MB, Params: 1,059,951 (4.043 MB), Total: 4.12 MB, FLOPs: 77,722,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 983/1724 finished in 0m10s\n",
      "Total channels prunned so far: 983\n",
      "\n",
      "Iteration 984 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.077 MB, Params: 1,058,217 (4.037 MB), Total: 4.11 MB, FLOPs: 77,702,121\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 984/1724 finished in 0m10s\n",
      "Total channels prunned so far: 984\n",
      "\n",
      "Iteration 985 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 1)]\n",
      "Input: 0.077 MB, Params: 1,056,361 (4.030 MB), Total: 4.11 MB, FLOPs: 77,488,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 985/1724 finished in 0m10s\n",
      "Total channels prunned so far: 985\n",
      "\n",
      "Iteration 986 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.077 MB, Params: 1,054,627 (4.023 MB), Total: 4.10 MB, FLOPs: 77,467,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 986/1724 finished in 0m10s\n",
      "Total channels prunned so far: 986\n",
      "\n",
      "Iteration 987 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.077 MB, Params: 1,051,061 (4.009 MB), Total: 4.09 MB, FLOPs: 77,424,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 987/1724 finished in 0m10s\n",
      "Total channels prunned so far: 987\n",
      "\n",
      "Iteration 988 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.077 MB, Params: 1,048,188 (3.999 MB), Total: 4.08 MB, FLOPs: 77,348,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 988/1724 finished in 0m10s\n",
      "Total channels prunned so far: 988\n",
      "\n",
      "Iteration 989 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 35)]\n",
      "Input: 0.077 MB, Params: 1,047,070 (3.994 MB), Total: 4.07 MB, FLOPs: 76,795,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 989/1724 finished in 0m10s\n",
      "Total channels prunned so far: 989\n",
      "\n",
      "Iteration 990 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.077 MB, Params: 1,046,438 (3.992 MB), Total: 4.07 MB, FLOPs: 76,196,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.432%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Finished fine tuning.\n",
      "Iteration 990/1724 finished in 0m10s\n",
      "Total channels prunned so far: 990\n",
      "\n",
      "Iteration 991 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.077 MB, Params: 1,042,881 (3.978 MB), Total: 4.06 MB, FLOPs: 76,153,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 991/1724 finished in 0m10s\n",
      "Total channels prunned so far: 991\n",
      "\n",
      "Iteration 992 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 246)]\n",
      "Input: 0.077 MB, Params: 1,041,165 (3.972 MB), Total: 4.05 MB, FLOPs: 76,133,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 992/1724 finished in 0m10s\n",
      "Total channels prunned so far: 992\n",
      "\n",
      "Iteration 993 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.077 MB, Params: 1,039,264 (3.964 MB), Total: 4.04 MB, FLOPs: 76,041,908\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Finished fine tuning.\n",
      "Iteration 993/1724 finished in 0m10s\n",
      "Total channels prunned so far: 993\n",
      "\n",
      "Iteration 994 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.077 MB, Params: 1,037,417 (3.957 MB), Total: 4.03 MB, FLOPs: 75,828,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 994/1724 finished in 0m10s\n",
      "Total channels prunned so far: 994\n",
      "\n",
      "Iteration 995 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 1,034,562 (3.947 MB), Total: 4.02 MB, FLOPs: 75,753,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 995/1724 finished in 0m10s\n",
      "Total channels prunned so far: 995\n",
      "\n",
      "Iteration 996 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 18)]\n",
      "Input: 0.077 MB, Params: 1,034,146 (3.945 MB), Total: 4.02 MB, FLOPs: 75,326,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 30.601%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 36.066%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 996/1724 finished in 0m11s\n",
      "Total channels prunned so far: 996\n",
      "\n",
      "Iteration 997 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 80)]\n",
      "Input: 0.077 MB, Params: 1,032,299 (3.938 MB), Total: 4.01 MB, FLOPs: 75,113,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 997/1724 finished in 0m10s\n",
      "Total channels prunned so far: 997\n",
      "\n",
      "Iteration 998 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 63)]\n",
      "Input: 0.077 MB, Params: 1,030,452 (3.931 MB), Total: 4.01 MB, FLOPs: 74,900,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 998/1724 finished in 0m10s\n",
      "Total channels prunned so far: 998\n",
      "\n",
      "Iteration 999 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.077 MB, Params: 1,028,605 (3.924 MB), Total: 4.00 MB, FLOPs: 74,686,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 999/1724 finished in 0m10s\n",
      "Total channels prunned so far: 999\n",
      "\n",
      "Iteration 1000 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 81)]\n",
      "Input: 0.077 MB, Params: 1,025,750 (3.913 MB), Total: 3.99 MB, FLOPs: 74,611,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1000/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1000\n",
      "\n",
      "Iteration 1001 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.077 MB, Params: 1,022,220 (3.899 MB), Total: 3.98 MB, FLOPs: 74,569,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1001/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1001\n",
      "\n",
      "Iteration 1002 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 1,018,690 (3.886 MB), Total: 3.96 MB, FLOPs: 74,526,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1002/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1002\n",
      "\n",
      "Iteration 1003 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.077 MB, Params: 1,016,843 (3.879 MB), Total: 3.96 MB, FLOPs: 74,438,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1003/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1003\n",
      "\n",
      "Iteration 1004 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.077 MB, Params: 1,015,145 (3.872 MB), Total: 3.95 MB, FLOPs: 74,417,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1004/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1004\n",
      "\n",
      "Iteration 1005 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.077 MB, Params: 1,013,298 (3.865 MB), Total: 3.94 MB, FLOPs: 74,329,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1005/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1005\n",
      "\n",
      "Iteration 1006 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.077 MB, Params: 1,011,600 (3.859 MB), Total: 3.94 MB, FLOPs: 74,308,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1006/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1006\n",
      "\n",
      "Iteration 1007 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 88)]\n",
      "Input: 0.077 MB, Params: 1,009,753 (3.852 MB), Total: 3.93 MB, FLOPs: 74,220,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1007/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1007\n",
      "\n",
      "Iteration 1008 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 1)]\n",
      "Input: 0.077 MB, Params: 1,009,337 (3.850 MB), Total: 3.93 MB, FLOPs: 73,793,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1008/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1008\n",
      "\n",
      "Iteration 1009 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 113)]\n",
      "Input: 0.077 MB, Params: 1,007,490 (3.843 MB), Total: 3.92 MB, FLOPs: 73,705,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1009/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1009\n",
      "\n",
      "Iteration 1010 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.077 MB, Params: 1,005,792 (3.837 MB), Total: 3.91 MB, FLOPs: 73,684,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1010/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1010\n",
      "\n",
      "Iteration 1011 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.077 MB, Params: 1,002,289 (3.823 MB), Total: 3.90 MB, FLOPs: 73,642,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1011/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1011\n",
      "\n",
      "Iteration 1012 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.077 MB, Params: 998,786 (3.810 MB), Total: 3.89 MB, FLOPs: 73,600,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1012/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1012\n",
      "\n",
      "Iteration 1013 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.077 MB, Params: 996,003 (3.799 MB), Total: 3.88 MB, FLOPs: 73,527,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1013/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1013\n",
      "\n",
      "Iteration 1014 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 994,323 (3.793 MB), Total: 3.87 MB, FLOPs: 73,507,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1014/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1014\n",
      "\n",
      "Iteration 1015 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 990,838 (3.780 MB), Total: 3.86 MB, FLOPs: 73,465,476\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1015/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1015\n",
      "\n",
      "Iteration 1016 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.077 MB, Params: 988,064 (3.769 MB), Total: 3.85 MB, FLOPs: 73,392,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1016/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1016\n",
      "\n",
      "Iteration 1017 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.077 MB, Params: 986,393 (3.763 MB), Total: 3.84 MB, FLOPs: 73,372,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1017/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1017\n",
      "\n",
      "Iteration 1018 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 116)]\n",
      "Input: 0.077 MB, Params: 983,619 (3.752 MB), Total: 3.83 MB, FLOPs: 73,299,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1018/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1018\n",
      "\n",
      "Iteration 1019 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 41)]\n",
      "Input: 0.077 MB, Params: 983,005 (3.750 MB), Total: 3.83 MB, FLOPs: 72,716,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1019/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1019\n",
      "\n",
      "Iteration 1020 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 171)]\n",
      "Input: 0.077 MB, Params: 981,334 (3.743 MB), Total: 3.82 MB, FLOPs: 72,696,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1020/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1020\n",
      "\n",
      "Iteration 1021 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 248)]\n",
      "Input: 0.077 MB, Params: 979,663 (3.737 MB), Total: 3.81 MB, FLOPs: 72,676,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1021/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1021\n",
      "\n",
      "Iteration 1022 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 976,223 (3.724 MB), Total: 3.80 MB, FLOPs: 72,635,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1022/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1022\n",
      "\n",
      "Iteration 1023 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.077 MB, Params: 974,561 (3.718 MB), Total: 3.79 MB, FLOPs: 72,615,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1023/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1023\n",
      "\n",
      "Iteration 1024 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.077 MB, Params: 972,899 (3.711 MB), Total: 3.79 MB, FLOPs: 72,595,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1024/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1024\n",
      "\n",
      "Iteration 1025 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.077 MB, Params: 971,079 (3.704 MB), Total: 3.78 MB, FLOPs: 72,508,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1025/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1025\n",
      "\n",
      "Iteration 1026 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.077 MB, Params: 968,323 (3.694 MB), Total: 3.77 MB, FLOPs: 72,435,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1026/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1026\n",
      "\n",
      "Iteration 1027 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.077 MB, Params: 966,512 (3.687 MB), Total: 3.76 MB, FLOPs: 72,348,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1027/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1027\n",
      "\n",
      "Iteration 1028 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.077 MB, Params: 963,765 (3.676 MB), Total: 3.75 MB, FLOPs: 72,276,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1028/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1028\n",
      "\n",
      "Iteration 1029 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 217)]\n",
      "Input: 0.077 MB, Params: 962,103 (3.670 MB), Total: 3.75 MB, FLOPs: 72,256,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1029/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1029\n",
      "\n",
      "Iteration 1030 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.077 MB, Params: 960,441 (3.664 MB), Total: 3.74 MB, FLOPs: 72,236,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1030/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1030\n",
      "\n",
      "Iteration 1031 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 234)]\n",
      "Input: 0.077 MB, Params: 958,779 (3.657 MB), Total: 3.73 MB, FLOPs: 72,216,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1031/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1031\n",
      "\n",
      "Iteration 1032 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.077 MB, Params: 958,165 (3.655 MB), Total: 3.73 MB, FLOPs: 71,634,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1032/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1032\n",
      "\n",
      "Iteration 1033 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.077 MB, Params: 956,363 (3.648 MB), Total: 3.73 MB, FLOPs: 71,547,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1033/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1033\n",
      "\n",
      "Iteration 1034 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.077 MB, Params: 954,561 (3.641 MB), Total: 3.72 MB, FLOPs: 71,461,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1034/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1034\n",
      "\n",
      "Iteration 1035 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 111)]\n",
      "Input: 0.077 MB, Params: 951,184 (3.628 MB), Total: 3.71 MB, FLOPs: 71,420,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1035/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1035\n",
      "\n",
      "Iteration 1036 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 949,382 (3.622 MB), Total: 3.70 MB, FLOPs: 71,334,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1036/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1036\n",
      "\n",
      "Iteration 1037 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.077 MB, Params: 947,580 (3.615 MB), Total: 3.69 MB, FLOPs: 71,248,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.792%\n",
      "Finished fine tuning.\n",
      "Iteration 1037/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1037\n",
      "\n",
      "Iteration 1038 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.077 MB, Params: 945,823 (3.608 MB), Total: 3.68 MB, FLOPs: 71,039,177\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1038/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1038\n",
      "\n",
      "Iteration 1039 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.077 MB, Params: 944,170 (3.602 MB), Total: 3.68 MB, FLOPs: 71,019,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1039/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1039\n",
      "\n",
      "Iteration 1040 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.077 MB, Params: 941,468 (3.591 MB), Total: 3.67 MB, FLOPs: 70,948,973\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1040/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1040\n",
      "\n",
      "Iteration 1041 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.077 MB, Params: 939,815 (3.585 MB), Total: 3.66 MB, FLOPs: 70,929,173\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1041/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1041\n",
      "\n",
      "Iteration 1042 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.077 MB, Params: 938,162 (3.579 MB), Total: 3.66 MB, FLOPs: 70,909,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1042/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1042\n",
      "\n",
      "Iteration 1043 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.077 MB, Params: 934,821 (3.566 MB), Total: 3.64 MB, FLOPs: 70,869,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1043/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1043\n",
      "\n",
      "Iteration 1044 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 76)]\n",
      "Input: 0.077 MB, Params: 933,694 (3.562 MB), Total: 3.64 MB, FLOPs: 70,615,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1044/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1044\n",
      "\n",
      "Iteration 1045 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.077 MB, Params: 930,353 (3.549 MB), Total: 3.63 MB, FLOPs: 70,575,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1045/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1045\n",
      "\n",
      "Iteration 1046 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.077 MB, Params: 928,718 (3.543 MB), Total: 3.62 MB, FLOPs: 70,556,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1046/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1046\n",
      "\n",
      "Iteration 1047 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.077 MB, Params: 925,386 (3.530 MB), Total: 3.61 MB, FLOPs: 70,516,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1047/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1047\n",
      "\n",
      "Iteration 1048 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 922,054 (3.517 MB), Total: 3.59 MB, FLOPs: 70,476,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1048/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1048\n",
      "\n",
      "Iteration 1049 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.077 MB, Params: 920,437 (3.511 MB), Total: 3.59 MB, FLOPs: 70,456,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1049/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1049\n",
      "\n",
      "Iteration 1050 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.077 MB, Params: 918,653 (3.504 MB), Total: 3.58 MB, FLOPs: 70,371,383\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1050/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1050\n",
      "\n",
      "Iteration 1051 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.077 MB, Params: 915,996 (3.494 MB), Total: 3.57 MB, FLOPs: 70,301,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1051/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1051\n",
      "\n",
      "Iteration 1052 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 79)]\n",
      "Input: 0.077 MB, Params: 914,221 (3.487 MB), Total: 3.56 MB, FLOPs: 70,216,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1052/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1052\n",
      "\n",
      "Iteration 1053 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.077 MB, Params: 912,604 (3.481 MB), Total: 3.56 MB, FLOPs: 70,197,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1053/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1053\n",
      "\n",
      "Iteration 1054 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 49)]\n",
      "Input: 0.077 MB, Params: 911,477 (3.477 MB), Total: 3.55 MB, FLOPs: 69,943,973\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1054/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1054\n",
      "\n",
      "Iteration 1055 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.077 MB, Params: 908,172 (3.464 MB), Total: 3.54 MB, FLOPs: 69,904,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1055/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1055\n",
      "\n",
      "Iteration 1056 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 217)]\n",
      "Input: 0.077 MB, Params: 906,564 (3.458 MB), Total: 3.54 MB, FLOPs: 69,885,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1056/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1056\n",
      "\n",
      "Iteration 1057 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 31)]\n",
      "Input: 0.077 MB, Params: 904,843 (3.452 MB), Total: 3.53 MB, FLOPs: 69,681,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1057/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1057\n",
      "\n",
      "Iteration 1058 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 31)]\n",
      "Input: 0.077 MB, Params: 904,229 (3.449 MB), Total: 3.53 MB, FLOPs: 69,098,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1058/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1058\n",
      "\n",
      "Iteration 1059 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.077 MB, Params: 903,111 (3.445 MB), Total: 3.52 MB, FLOPs: 68,847,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1059/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1059\n",
      "\n",
      "Iteration 1060 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.077 MB, Params: 900,472 (3.435 MB), Total: 3.51 MB, FLOPs: 68,778,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1060/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1060\n",
      "\n",
      "Iteration 1061 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.077 MB, Params: 898,864 (3.429 MB), Total: 3.51 MB, FLOPs: 68,759,133\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1061/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1061\n",
      "\n",
      "Iteration 1062 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 64)]\n",
      "Input: 0.077 MB, Params: 897,107 (3.422 MB), Total: 3.50 MB, FLOPs: 68,674,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1062/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1062\n",
      "\n",
      "Iteration 1063 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.077 MB, Params: 893,829 (3.410 MB), Total: 3.49 MB, FLOPs: 68,635,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1063/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1063\n",
      "\n",
      "Iteration 1064 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.077 MB, Params: 890,551 (3.397 MB), Total: 3.47 MB, FLOPs: 68,596,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1064/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1064\n",
      "\n",
      "Iteration 1065 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 36)]\n",
      "Input: 0.077 MB, Params: 889,937 (3.395 MB), Total: 3.47 MB, FLOPs: 68,013,847\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1065/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1065\n",
      "\n",
      "Iteration 1066 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.077 MB, Params: 886,659 (3.382 MB), Total: 3.46 MB, FLOPs: 67,974,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1066/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1066\n",
      "\n",
      "Iteration 1067 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.077 MB, Params: 883,381 (3.370 MB), Total: 3.45 MB, FLOPs: 67,935,199\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1067/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1067\n",
      "\n",
      "Iteration 1068 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.077 MB, Params: 881,809 (3.364 MB), Total: 3.44 MB, FLOPs: 67,916,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1068/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1068\n",
      "\n",
      "Iteration 1069 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.077 MB, Params: 878,540 (3.351 MB), Total: 3.43 MB, FLOPs: 67,877,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1069/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1069\n",
      "\n",
      "Iteration 1070 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 9)]\n",
      "Input: 0.077 MB, Params: 877,494 (3.347 MB), Total: 3.42 MB, FLOPs: 67,372,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1070/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1070\n",
      "\n",
      "Iteration 1071 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 874,225 (3.335 MB), Total: 3.41 MB, FLOPs: 67,333,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1071/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1071\n",
      "\n",
      "Iteration 1072 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.077 MB, Params: 870,956 (3.322 MB), Total: 3.40 MB, FLOPs: 67,294,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1072/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1072\n",
      "\n",
      "Iteration 1073 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.077 MB, Params: 869,411 (3.317 MB), Total: 3.39 MB, FLOPs: 67,275,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1073/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1073\n",
      "\n",
      "Iteration 1074 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.077 MB, Params: 867,866 (3.311 MB), Total: 3.39 MB, FLOPs: 67,257,440\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1074/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1074\n",
      "\n",
      "Iteration 1075 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.077 MB, Params: 866,321 (3.305 MB), Total: 3.38 MB, FLOPs: 67,238,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1075/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1075\n",
      "\n",
      "Iteration 1076 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 117)]\n",
      "Input: 0.077 MB, Params: 863,079 (3.292 MB), Total: 3.37 MB, FLOPs: 67,200,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1076/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1076\n",
      "\n",
      "Iteration 1077 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.077 MB, Params: 859,837 (3.280 MB), Total: 3.36 MB, FLOPs: 67,161,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1077/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1077\n",
      "\n",
      "Iteration 1078 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.077 MB, Params: 858,310 (3.274 MB), Total: 3.35 MB, FLOPs: 67,142,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1078/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1078\n",
      "\n",
      "Iteration 1079 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.077 MB, Params: 855,077 (3.262 MB), Total: 3.34 MB, FLOPs: 67,104,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1079/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1079\n",
      "\n",
      "Iteration 1080 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 851,844 (3.250 MB), Total: 3.33 MB, FLOPs: 67,065,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1080/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1080\n",
      "\n",
      "Iteration 1081 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 35)]\n",
      "Input: 0.077 MB, Params: 851,807 (3.249 MB), Total: 3.33 MB, FLOPs: 65,614,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1081/1724 finished in 0m13s\n",
      "Total channels prunned so far: 1081\n",
      "\n",
      "Iteration 1082 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 73)]\n",
      "Input: 0.077 MB, Params: 850,104 (3.243 MB), Total: 3.32 MB, FLOPs: 65,412,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1082/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1082\n",
      "\n",
      "Iteration 1083 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.077 MB, Params: 847,573 (3.233 MB), Total: 3.31 MB, FLOPs: 65,345,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1083/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1083\n",
      "\n",
      "Iteration 1084 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.077 MB, Params: 844,349 (3.221 MB), Total: 3.30 MB, FLOPs: 65,306,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1084/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1084\n",
      "\n",
      "Iteration 1085 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.077 MB, Params: 841,125 (3.209 MB), Total: 3.29 MB, FLOPs: 65,268,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1085/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1085\n",
      "\n",
      "Iteration 1086 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 49)]\n",
      "Input: 0.077 MB, Params: 840,025 (3.204 MB), Total: 3.28 MB, FLOPs: 65,020,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1086/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1086\n",
      "\n",
      "Iteration 1087 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.077 MB, Params: 836,801 (3.192 MB), Total: 3.27 MB, FLOPs: 64,982,299\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1087/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1087\n",
      "\n",
      "Iteration 1088 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 101)]\n",
      "Input: 0.077 MB, Params: 834,297 (3.183 MB), Total: 3.26 MB, FLOPs: 64,915,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1088/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1088\n",
      "\n",
      "Iteration 1089 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 831,082 (3.170 MB), Total: 3.25 MB, FLOPs: 64,876,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1089/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1089\n",
      "\n",
      "Iteration 1090 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.077 MB, Params: 828,587 (3.161 MB), Total: 3.24 MB, FLOPs: 64,809,727\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1090/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1090\n",
      "\n",
      "Iteration 1091 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 826,092 (3.151 MB), Total: 3.23 MB, FLOPs: 64,742,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1091/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1091\n",
      "\n",
      "Iteration 1092 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 48)]\n",
      "Input: 0.077 MB, Params: 824,992 (3.147 MB), Total: 3.22 MB, FLOPs: 64,495,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1092/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1092\n",
      "\n",
      "Iteration 1093 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.077 MB, Params: 823,280 (3.141 MB), Total: 3.22 MB, FLOPs: 64,413,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1093/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1093\n",
      "\n",
      "Iteration 1094 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 821,568 (3.134 MB), Total: 3.21 MB, FLOPs: 64,331,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1094/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1094\n",
      "\n",
      "Iteration 1095 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.077 MB, Params: 819,901 (3.128 MB), Total: 3.20 MB, FLOPs: 64,134,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1095/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1095\n",
      "\n",
      "Iteration 1096 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.077 MB, Params: 818,428 (3.122 MB), Total: 3.20 MB, FLOPs: 64,116,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1096/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1096\n",
      "\n",
      "Iteration 1097 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.077 MB, Params: 815,240 (3.110 MB), Total: 3.19 MB, FLOPs: 64,078,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1097/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1097\n",
      "\n",
      "Iteration 1098 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.077 MB, Params: 813,537 (3.103 MB), Total: 3.18 MB, FLOPs: 63,997,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1098/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1098\n",
      "\n",
      "Iteration 1099 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.077 MB, Params: 811,834 (3.097 MB), Total: 3.17 MB, FLOPs: 63,915,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1099/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1099\n",
      "\n",
      "Iteration 1100 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.077 MB, Params: 809,384 (3.088 MB), Total: 3.16 MB, FLOPs: 63,850,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1100/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1100\n",
      "\n",
      "Iteration 1101 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 64)]\n",
      "Input: 0.077 MB, Params: 807,735 (3.081 MB), Total: 3.16 MB, FLOPs: 63,654,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1101/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1101\n",
      "\n",
      "Iteration 1102 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.077 MB, Params: 807,130 (3.079 MB), Total: 3.16 MB, FLOPs: 63,110,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1102/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1102\n",
      "\n",
      "Iteration 1103 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 228)]\n",
      "Input: 0.077 MB, Params: 805,666 (3.073 MB), Total: 3.15 MB, FLOPs: 63,093,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1103/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1103\n",
      "\n",
      "Iteration 1104 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.077 MB, Params: 802,496 (3.061 MB), Total: 3.14 MB, FLOPs: 63,055,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1104/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1104\n",
      "\n",
      "Iteration 1105 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.077 MB, Params: 800,055 (3.052 MB), Total: 3.13 MB, FLOPs: 62,990,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1105/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1105\n",
      "\n",
      "Iteration 1106 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.077 MB, Params: 796,894 (3.040 MB), Total: 3.12 MB, FLOPs: 62,952,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1106/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1106\n",
      "\n",
      "Iteration 1107 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.077 MB, Params: 795,245 (3.034 MB), Total: 3.11 MB, FLOPs: 62,756,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1107/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1107\n",
      "\n",
      "Iteration 1108 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.077 MB, Params: 793,799 (3.028 MB), Total: 3.10 MB, FLOPs: 62,739,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1108/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1108\n",
      "\n",
      "Iteration 1109 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.077 MB, Params: 790,647 (3.016 MB), Total: 3.09 MB, FLOPs: 62,701,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1109/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1109\n",
      "\n",
      "Iteration 1110 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 222)]\n",
      "Input: 0.077 MB, Params: 789,210 (3.011 MB), Total: 3.09 MB, FLOPs: 62,684,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1110/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1110\n",
      "\n",
      "Iteration 1111 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 226)]\n",
      "Input: 0.077 MB, Params: 787,773 (3.005 MB), Total: 3.08 MB, FLOPs: 62,667,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1111/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1111\n",
      "\n",
      "Iteration 1112 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.077 MB, Params: 787,168 (3.003 MB), Total: 3.08 MB, FLOPs: 62,123,482\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1112/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1112\n",
      "\n",
      "Iteration 1113 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 64)]\n",
      "Input: 0.077 MB, Params: 785,731 (2.997 MB), Total: 3.07 MB, FLOPs: 62,106,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1113/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1113\n",
      "\n",
      "Iteration 1114 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.077 MB, Params: 784,294 (2.992 MB), Total: 3.07 MB, FLOPs: 62,089,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Finished fine tuning.\n",
      "Iteration 1114/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1114\n",
      "\n",
      "Iteration 1115 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 9)]\n",
      "Input: 0.077 MB, Params: 784,257 (2.992 MB), Total: 3.07 MB, FLOPs: 61,882,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1115/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1115\n",
      "\n",
      "Iteration 1116 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.077 MB, Params: 781,141 (2.980 MB), Total: 3.06 MB, FLOPs: 61,845,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1116/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1116\n",
      "\n",
      "Iteration 1117 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.077 MB, Params: 778,025 (2.968 MB), Total: 3.04 MB, FLOPs: 61,808,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1117/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1117\n",
      "\n",
      "Iteration 1118 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.077 MB, Params: 776,606 (2.963 MB), Total: 3.04 MB, FLOPs: 61,791,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1118/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1118\n",
      "\n",
      "Iteration 1119 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.077 MB, Params: 774,939 (2.956 MB), Total: 3.03 MB, FLOPs: 61,711,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1119/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1119\n",
      "\n",
      "Iteration 1120 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 74)]\n",
      "Input: 0.077 MB, Params: 772,543 (2.947 MB), Total: 3.02 MB, FLOPs: 61,646,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1120/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1120\n",
      "\n",
      "Iteration 1121 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.077 MB, Params: 770,885 (2.941 MB), Total: 3.02 MB, FLOPs: 61,567,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1121/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1121\n",
      "\n",
      "Iteration 1122 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.077 MB, Params: 769,227 (2.934 MB), Total: 3.01 MB, FLOPs: 61,487,910\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1122/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1122\n",
      "\n",
      "Iteration 1123 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.077 MB, Params: 766,849 (2.925 MB), Total: 3.00 MB, FLOPs: 61,424,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1123/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1123\n",
      "\n",
      "Iteration 1124 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 35)]\n",
      "Input: 0.077 MB, Params: 765,227 (2.919 MB), Total: 3.00 MB, FLOPs: 61,230,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1124/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1124\n",
      "\n",
      "Iteration 1125 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 106)]\n",
      "Input: 0.077 MB, Params: 763,587 (2.913 MB), Total: 2.99 MB, FLOPs: 61,151,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1125/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1125\n",
      "\n",
      "Iteration 1126 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 99)]\n",
      "Input: 0.077 MB, Params: 761,218 (2.904 MB), Total: 2.98 MB, FLOPs: 61,088,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1126/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1126\n",
      "\n",
      "Iteration 1127 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.077 MB, Params: 759,605 (2.898 MB), Total: 2.97 MB, FLOPs: 60,894,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1127/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1127\n",
      "\n",
      "Iteration 1128 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.077 MB, Params: 758,186 (2.892 MB), Total: 2.97 MB, FLOPs: 60,877,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1128/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1128\n",
      "\n",
      "Iteration 1129 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.077 MB, Params: 755,115 (2.881 MB), Total: 2.96 MB, FLOPs: 60,840,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1129/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1129\n",
      "\n",
      "Iteration 1130 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.077 MB, Params: 752,044 (2.869 MB), Total: 2.95 MB, FLOPs: 60,803,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1130/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1130\n",
      "\n",
      "Iteration 1131 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.077 MB, Params: 748,973 (2.857 MB), Total: 2.93 MB, FLOPs: 60,767,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1131/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1131\n",
      "\n",
      "Iteration 1132 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.077 MB, Params: 748,368 (2.855 MB), Total: 2.93 MB, FLOPs: 60,223,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1132/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1132\n",
      "\n",
      "Iteration 1133 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.077 MB, Params: 747,763 (2.852 MB), Total: 2.93 MB, FLOPs: 59,679,906\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1133/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1133\n",
      "\n",
      "Iteration 1134 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.077 MB, Params: 746,150 (2.846 MB), Total: 2.92 MB, FLOPs: 59,485,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1134/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1134\n",
      "\n",
      "Iteration 1135 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.077 MB, Params: 744,537 (2.840 MB), Total: 2.92 MB, FLOPs: 59,408,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1135/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1135\n",
      "\n",
      "Iteration 1136 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 2)]\n",
      "Input: 0.077 MB, Params: 742,924 (2.834 MB), Total: 2.91 MB, FLOPs: 59,331,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1136/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1136\n",
      "\n",
      "Iteration 1137 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 739,853 (2.822 MB), Total: 2.90 MB, FLOPs: 59,294,280\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1137/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1137\n",
      "\n",
      "Iteration 1138 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 9)]\n",
      "Input: 0.077 MB, Params: 739,816 (2.822 MB), Total: 2.90 MB, FLOPs: 56,050,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1138/1724 finished in 0m16s\n",
      "Total channels prunned so far: 1138\n",
      "\n",
      "Iteration 1139 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.077 MB, Params: 736,745 (2.810 MB), Total: 2.89 MB, FLOPs: 56,013,916\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1139/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1139\n",
      "\n",
      "Iteration 1140 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.077 MB, Params: 735,371 (2.805 MB), Total: 2.88 MB, FLOPs: 55,997,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1140/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1140\n",
      "\n",
      "Iteration 1141 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 27)]\n",
      "Input: 0.077 MB, Params: 734,325 (2.801 MB), Total: 2.88 MB, FLOPs: 55,788,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Finished fine tuning.\n",
      "Iteration 1141/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1141\n",
      "\n",
      "Iteration 1142 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.077 MB, Params: 732,951 (2.796 MB), Total: 2.87 MB, FLOPs: 55,772,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Finished fine tuning.\n",
      "Iteration 1142/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1142\n",
      "\n",
      "Iteration 1143 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.077 MB, Params: 731,338 (2.790 MB), Total: 2.87 MB, FLOPs: 55,694,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1143/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1143\n",
      "\n",
      "Iteration 1144 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.077 MB, Params: 729,041 (2.781 MB), Total: 2.86 MB, FLOPs: 55,633,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1144/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1144\n",
      "\n",
      "Iteration 1145 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.077 MB, Params: 726,744 (2.772 MB), Total: 2.85 MB, FLOPs: 55,572,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Finished fine tuning.\n",
      "Iteration 1145/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1145\n",
      "\n",
      "Iteration 1146 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.077 MB, Params: 723,709 (2.761 MB), Total: 2.84 MB, FLOPs: 55,536,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.514%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1146/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1146\n",
      "\n",
      "Iteration 1147 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.077 MB, Params: 720,674 (2.749 MB), Total: 2.83 MB, FLOPs: 55,499,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.699%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.246%\n",
      "Finished fine tuning.\n",
      "Iteration 1147/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1147\n",
      "\n",
      "Iteration 1148 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.077 MB, Params: 717,639 (2.738 MB), Total: 2.81 MB, FLOPs: 55,463,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1148/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1148\n",
      "\n",
      "Iteration 1149 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.077 MB, Params: 715,369 (2.729 MB), Total: 2.81 MB, FLOPs: 55,402,712\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1149/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1149\n",
      "\n",
      "Iteration 1150 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.077 MB, Params: 712,343 (2.717 MB), Total: 2.79 MB, FLOPs: 55,366,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1150/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1150\n",
      "\n",
      "Iteration 1151 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.077 MB, Params: 710,082 (2.709 MB), Total: 2.79 MB, FLOPs: 55,305,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1151/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1151\n",
      "\n",
      "Iteration 1152 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 15)]\n",
      "Input: 0.077 MB, Params: 710,045 (2.709 MB), Total: 2.79 MB, FLOPs: 55,099,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1152/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1152\n",
      "\n",
      "Iteration 1153 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 105)]\n",
      "Input: 0.077 MB, Params: 707,784 (2.700 MB), Total: 2.78 MB, FLOPs: 55,039,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1153/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1153\n",
      "\n",
      "Iteration 1154 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.077 MB, Params: 706,738 (2.696 MB), Total: 2.77 MB, FLOPs: 54,830,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1154/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1154\n",
      "\n",
      "Iteration 1155 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 38)]\n",
      "Input: 0.077 MB, Params: 705,170 (2.690 MB), Total: 2.77 MB, FLOPs: 54,754,820\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1155/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1155\n",
      "\n",
      "Iteration 1156 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 702,162 (2.679 MB), Total: 2.76 MB, FLOPs: 54,718,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1156/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1156\n",
      "\n",
      "Iteration 1157 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 700,603 (2.673 MB), Total: 2.75 MB, FLOPs: 54,546,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1157/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1157\n",
      "\n",
      "Iteration 1158 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 697,595 (2.661 MB), Total: 2.74 MB, FLOPs: 54,510,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1158/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1158\n",
      "\n",
      "Iteration 1159 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 11)]\n",
      "Input: 0.077 MB, Params: 697,558 (2.661 MB), Total: 2.74 MB, FLOPs: 53,180,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1159/1724 finished in 0m14s\n",
      "Total channels prunned so far: 1159\n",
      "\n",
      "Iteration 1160 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.077 MB, Params: 695,999 (2.655 MB), Total: 2.73 MB, FLOPs: 53,105,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1160/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1160\n",
      "\n",
      "Iteration 1161 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.077 MB, Params: 693,774 (2.647 MB), Total: 2.72 MB, FLOPs: 53,046,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1161/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1161\n",
      "\n",
      "Iteration 1162 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 691,549 (2.638 MB), Total: 2.71 MB, FLOPs: 52,986,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1162/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1162\n",
      "\n",
      "Iteration 1163 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.077 MB, Params: 688,559 (2.627 MB), Total: 2.70 MB, FLOPs: 52,950,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1163/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1163\n",
      "\n",
      "Iteration 1164 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.077 MB, Params: 687,522 (2.623 MB), Total: 2.70 MB, FLOPs: 52,743,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1164/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1164\n",
      "\n",
      "Iteration 1165 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.077 MB, Params: 686,211 (2.618 MB), Total: 2.69 MB, FLOPs: 52,727,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1165/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1165\n",
      "\n",
      "Iteration 1166 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 57)]\n",
      "Input: 0.077 MB, Params: 684,670 (2.612 MB), Total: 2.69 MB, FLOPs: 52,557,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1166/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1166\n",
      "\n",
      "Iteration 1167 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 96)]\n",
      "Input: 0.077 MB, Params: 682,454 (2.603 MB), Total: 2.68 MB, FLOPs: 52,498,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1167/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1167\n",
      "\n",
      "Iteration 1168 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.077 MB, Params: 679,482 (2.592 MB), Total: 2.67 MB, FLOPs: 52,462,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1168/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1168\n",
      "\n",
      "Iteration 1169 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.077 MB, Params: 678,180 (2.587 MB), Total: 2.66 MB, FLOPs: 52,447,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1169/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1169\n",
      "\n",
      "Iteration 1170 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.077 MB, Params: 675,973 (2.579 MB), Total: 2.66 MB, FLOPs: 52,387,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1170/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1170\n",
      "\n",
      "Iteration 1171 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 10)]\n",
      "Input: 0.077 MB, Params: 675,936 (2.578 MB), Total: 2.66 MB, FLOPs: 52,181,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1171/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1171\n",
      "\n",
      "Iteration 1172 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.077 MB, Params: 672,982 (2.567 MB), Total: 2.64 MB, FLOPs: 52,146,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1172/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1172\n",
      "\n",
      "Iteration 1173 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 670,784 (2.559 MB), Total: 2.64 MB, FLOPs: 52,087,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1173/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1173\n",
      "\n",
      "Iteration 1174 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.077 MB, Params: 667,839 (2.548 MB), Total: 2.62 MB, FLOPs: 52,051,790\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1174/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1174\n",
      "\n",
      "Iteration 1175 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.077 MB, Params: 664,894 (2.536 MB), Total: 2.61 MB, FLOPs: 52,016,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1175/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1175\n",
      "\n",
      "Iteration 1176 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.077 MB, Params: 664,289 (2.534 MB), Total: 2.61 MB, FLOPs: 51,533,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1176/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1176\n",
      "\n",
      "Iteration 1177 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.077 MB, Params: 662,784 (2.528 MB), Total: 2.61 MB, FLOPs: 51,461,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1177/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1177\n",
      "\n",
      "Iteration 1178 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 35)]\n",
      "Input: 0.077 MB, Params: 660,613 (2.520 MB), Total: 2.60 MB, FLOPs: 51,402,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1178/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1178\n",
      "\n",
      "Iteration 1179 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.077 MB, Params: 659,657 (2.516 MB), Total: 2.59 MB, FLOPs: 51,015,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1179/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1179\n",
      "\n",
      "Iteration 1180 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.077 MB, Params: 657,486 (2.508 MB), Total: 2.58 MB, FLOPs: 50,957,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1180/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1180\n",
      "\n",
      "Iteration 1181 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.077 MB, Params: 656,211 (2.503 MB), Total: 2.58 MB, FLOPs: 50,941,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1181/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1181\n",
      "\n",
      "Iteration 1182 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.077 MB, Params: 653,293 (2.492 MB), Total: 2.57 MB, FLOPs: 50,906,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.060%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1182/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1182\n",
      "\n",
      "Iteration 1183 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.077 MB, Params: 651,131 (2.484 MB), Total: 2.56 MB, FLOPs: 50,848,538\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1183/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1183\n",
      "\n",
      "Iteration 1184 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 648,222 (2.473 MB), Total: 2.55 MB, FLOPs: 50,813,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1184/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1184\n",
      "\n",
      "Iteration 1185 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.077 MB, Params: 645,313 (2.462 MB), Total: 2.54 MB, FLOPs: 50,778,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1185/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1185\n",
      "\n",
      "Iteration 1186 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 49)]\n",
      "Input: 0.077 MB, Params: 643,169 (2.453 MB), Total: 2.53 MB, FLOPs: 50,720,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1186/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1186\n",
      "\n",
      "Iteration 1187 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.077 MB, Params: 640,269 (2.442 MB), Total: 2.52 MB, FLOPs: 50,685,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1187/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1187\n",
      "\n",
      "Iteration 1188 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.077 MB, Params: 638,134 (2.434 MB), Total: 2.51 MB, FLOPs: 50,627,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1188/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1188\n",
      "\n",
      "Iteration 1189 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 59)]\n",
      "Input: 0.077 MB, Params: 637,115 (2.430 MB), Total: 2.51 MB, FLOPs: 50,424,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1189/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1189\n",
      "\n",
      "Iteration 1190 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.077 MB, Params: 634,224 (2.419 MB), Total: 2.50 MB, FLOPs: 50,389,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1190/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1190\n",
      "\n",
      "Iteration 1191 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.077 MB, Params: 632,994 (2.415 MB), Total: 2.49 MB, FLOPs: 50,374,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1191/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1191\n",
      "\n",
      "Iteration 1192 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.077 MB, Params: 631,975 (2.411 MB), Total: 2.49 MB, FLOPs: 50,171,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1192/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1192\n",
      "\n",
      "Iteration 1193 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 62)]\n",
      "Input: 0.077 MB, Params: 629,849 (2.403 MB), Total: 2.48 MB, FLOPs: 50,113,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1193/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1193\n",
      "\n",
      "Iteration 1194 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.077 MB, Params: 628,398 (2.397 MB), Total: 2.47 MB, FLOPs: 50,043,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1194/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1194\n",
      "\n",
      "Iteration 1195 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 625,525 (2.386 MB), Total: 2.46 MB, FLOPs: 50,009,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1195/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1195\n",
      "\n",
      "Iteration 1196 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.077 MB, Params: 624,074 (2.381 MB), Total: 2.46 MB, FLOPs: 49,939,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1196/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1196\n",
      "\n",
      "Iteration 1197 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.077 MB, Params: 622,578 (2.375 MB), Total: 2.45 MB, FLOPs: 49,774,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1197/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1197\n",
      "\n",
      "Iteration 1198 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 620,479 (2.367 MB), Total: 2.44 MB, FLOPs: 49,717,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1198/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1198\n",
      "\n",
      "Iteration 1199 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.077 MB, Params: 619,258 (2.362 MB), Total: 2.44 MB, FLOPs: 49,702,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1199/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1199\n",
      "\n",
      "Iteration 1200 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.077 MB, Params: 617,762 (2.357 MB), Total: 2.43 MB, FLOPs: 49,537,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1200/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1200\n",
      "\n",
      "Iteration 1201 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 2)]\n",
      "Input: 0.077 MB, Params: 617,591 (2.356 MB), Total: 2.43 MB, FLOPs: 48,631,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1201/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1201\n",
      "\n",
      "Iteration 1202 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.077 MB, Params: 616,370 (2.351 MB), Total: 2.43 MB, FLOPs: 48,616,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1202/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1202\n",
      "\n",
      "Iteration 1203 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.077 MB, Params: 613,524 (2.340 MB), Total: 2.42 MB, FLOPs: 48,582,624\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1203/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1203\n",
      "\n",
      "Iteration 1204 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 157)]\n",
      "Input: 0.077 MB, Params: 612,312 (2.336 MB), Total: 2.41 MB, FLOPs: 48,568,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1204/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1204\n",
      "\n",
      "Iteration 1205 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.077 MB, Params: 609,475 (2.325 MB), Total: 2.40 MB, FLOPs: 48,534,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1205/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1205\n",
      "\n",
      "Iteration 1206 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.077 MB, Params: 608,272 (2.320 MB), Total: 2.40 MB, FLOPs: 48,519,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1206/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1206\n",
      "\n",
      "Iteration 1207 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.077 MB, Params: 607,069 (2.316 MB), Total: 2.39 MB, FLOPs: 48,505,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1207/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1207\n",
      "\n",
      "Iteration 1208 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 54)]\n",
      "Input: 0.077 MB, Params: 606,068 (2.312 MB), Total: 2.39 MB, FLOPs: 48,305,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1208/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1208\n",
      "\n",
      "Iteration 1209 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 6)]\n",
      "Input: 0.077 MB, Params: 605,733 (2.311 MB), Total: 2.39 MB, FLOPs: 48,010,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1209/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1209\n",
      "\n",
      "Iteration 1210 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 67)]\n",
      "Input: 0.077 MB, Params: 604,309 (2.305 MB), Total: 2.38 MB, FLOPs: 47,942,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1210/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1210\n",
      "\n",
      "Iteration 1211 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.077 MB, Params: 601,490 (2.295 MB), Total: 2.37 MB, FLOPs: 47,908,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1211/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1211\n",
      "\n",
      "Iteration 1212 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.077 MB, Params: 600,066 (2.289 MB), Total: 2.37 MB, FLOPs: 47,840,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1212/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1212\n",
      "\n",
      "Iteration 1213 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.077 MB, Params: 598,642 (2.284 MB), Total: 2.36 MB, FLOPs: 47,772,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1213/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1213\n",
      "\n",
      "Iteration 1214 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 596,597 (2.276 MB), Total: 2.35 MB, FLOPs: 47,716,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1214/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1214\n",
      "\n",
      "Iteration 1215 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.077 MB, Params: 595,403 (2.271 MB), Total: 2.35 MB, FLOPs: 47,702,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1215/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1215\n",
      "\n",
      "Iteration 1216 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.077 MB, Params: 594,209 (2.267 MB), Total: 2.34 MB, FLOPs: 47,688,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1216/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1216\n",
      "\n",
      "Iteration 1217 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.077 MB, Params: 592,794 (2.261 MB), Total: 2.34 MB, FLOPs: 47,620,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1217/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1217\n",
      "\n",
      "Iteration 1218 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.077 MB, Params: 591,343 (2.256 MB), Total: 2.33 MB, FLOPs: 47,458,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1218/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1218\n",
      "\n",
      "Iteration 1219 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.077 MB, Params: 590,351 (2.252 MB), Total: 2.33 MB, FLOPs: 47,260,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1219/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1219\n",
      "\n",
      "Iteration 1220 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 587,559 (2.241 MB), Total: 2.32 MB, FLOPs: 47,227,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1220/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1220\n",
      "\n",
      "Iteration 1221 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 586,153 (2.236 MB), Total: 2.31 MB, FLOPs: 47,159,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1221/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1221\n",
      "\n",
      "Iteration 1222 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.077 MB, Params: 584,720 (2.231 MB), Total: 2.31 MB, FLOPs: 47,000,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1222/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1222\n",
      "\n",
      "Iteration 1223 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.077 MB, Params: 581,928 (2.220 MB), Total: 2.30 MB, FLOPs: 46,966,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1223/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1223\n",
      "\n",
      "Iteration 1224 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.077 MB, Params: 579,136 (2.209 MB), Total: 2.29 MB, FLOPs: 46,933,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1224/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1224\n",
      "\n",
      "Iteration 1225 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.077 MB, Params: 577,739 (2.204 MB), Total: 2.28 MB, FLOPs: 46,866,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1225/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1225\n",
      "\n",
      "Iteration 1226 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.077 MB, Params: 574,947 (2.193 MB), Total: 2.27 MB, FLOPs: 46,832,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1226/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1226\n",
      "\n",
      "Iteration 1227 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.077 MB, Params: 573,523 (2.188 MB), Total: 2.26 MB, FLOPs: 46,673,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1227/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1227\n",
      "\n",
      "Iteration 1228 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.077 MB, Params: 570,731 (2.177 MB), Total: 2.25 MB, FLOPs: 46,640,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1228/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1228\n",
      "\n",
      "Iteration 1229 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.077 MB, Params: 567,939 (2.167 MB), Total: 2.24 MB, FLOPs: 46,606,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1229/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1229\n",
      "\n",
      "Iteration 1230 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.077 MB, Params: 565,147 (2.156 MB), Total: 2.23 MB, FLOPs: 46,573,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1230/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1230\n",
      "\n",
      "Iteration 1231 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 47)]\n",
      "Input: 0.077 MB, Params: 563,192 (2.148 MB), Total: 2.23 MB, FLOPs: 46,519,972\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1231/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1231\n",
      "\n",
      "Iteration 1232 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 561,813 (2.143 MB), Total: 2.22 MB, FLOPs: 46,453,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1232/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1232\n",
      "\n",
      "Iteration 1233 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.077 MB, Params: 559,030 (2.133 MB), Total: 2.21 MB, FLOPs: 46,420,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1233/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1233\n",
      "\n",
      "Iteration 1234 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 88)]\n",
      "Input: 0.077 MB, Params: 557,651 (2.127 MB), Total: 2.20 MB, FLOPs: 46,354,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1234/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1234\n",
      "\n",
      "Iteration 1235 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.077 MB, Params: 555,723 (2.120 MB), Total: 2.20 MB, FLOPs: 46,301,932\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1235/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1235\n",
      "\n",
      "Iteration 1236 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.077 MB, Params: 554,601 (2.116 MB), Total: 2.19 MB, FLOPs: 46,288,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.607%\n",
      "Finished fine tuning.\n",
      "Iteration 1236/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1236\n",
      "\n",
      "Iteration 1237 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.077 MB, Params: 553,479 (2.111 MB), Total: 2.19 MB, FLOPs: 46,275,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1237/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1237\n",
      "\n",
      "Iteration 1238 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.077 MB, Params: 550,723 (2.101 MB), Total: 2.18 MB, FLOPs: 46,242,016\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1238/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1238\n",
      "\n",
      "Iteration 1239 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.077 MB, Params: 548,804 (2.094 MB), Total: 2.17 MB, FLOPs: 46,189,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1239/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1239\n",
      "\n",
      "Iteration 1240 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.077 MB, Params: 547,398 (2.088 MB), Total: 2.17 MB, FLOPs: 46,031,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1240/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1240\n",
      "\n",
      "Iteration 1241 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 12)]\n",
      "Input: 0.077 MB, Params: 547,063 (2.087 MB), Total: 2.16 MB, FLOPs: 45,737,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1241/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1241\n",
      "\n",
      "Iteration 1242 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.077 MB, Params: 545,711 (2.082 MB), Total: 2.16 MB, FLOPs: 45,672,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1242/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1242\n",
      "\n",
      "Iteration 1243 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.077 MB, Params: 544,791 (2.078 MB), Total: 2.16 MB, FLOPs: 45,292,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1243/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1243\n",
      "\n",
      "Iteration 1244 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.077 MB, Params: 543,439 (2.073 MB), Total: 2.15 MB, FLOPs: 45,227,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1244/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1244\n",
      "\n",
      "Iteration 1245 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.077 MB, Params: 542,326 (2.069 MB), Total: 2.15 MB, FLOPs: 45,214,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1245/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1245\n",
      "\n",
      "Iteration 1246 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 540,425 (2.062 MB), Total: 2.14 MB, FLOPs: 45,163,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1246/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1246\n",
      "\n",
      "Iteration 1247 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 537,696 (2.051 MB), Total: 2.13 MB, FLOPs: 45,130,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1247/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1247\n",
      "\n",
      "Iteration 1248 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 185)]\n",
      "Input: 0.077 MB, Params: 536,592 (2.047 MB), Total: 2.12 MB, FLOPs: 45,117,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1248/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1248\n",
      "\n",
      "Iteration 1249 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.077 MB, Params: 535,672 (2.043 MB), Total: 2.12 MB, FLOPs: 44,737,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1249/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1249\n",
      "\n",
      "Iteration 1250 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.077 MB, Params: 534,725 (2.040 MB), Total: 2.12 MB, FLOPs: 44,548,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1250/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1250\n",
      "\n",
      "Iteration 1251 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.077 MB, Params: 533,382 (2.035 MB), Total: 2.11 MB, FLOPs: 44,484,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1251/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1251\n",
      "\n",
      "Iteration 1252 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 17)]\n",
      "Input: 0.077 MB, Params: 533,047 (2.033 MB), Total: 2.11 MB, FLOPs: 44,189,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.076%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1252/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1252\n",
      "\n",
      "Iteration 1253 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.077 MB, Params: 531,943 (2.029 MB), Total: 2.11 MB, FLOPs: 44,176,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1253/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1253\n",
      "\n",
      "Iteration 1254 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.077 MB, Params: 529,232 (2.019 MB), Total: 2.10 MB, FLOPs: 44,143,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1254/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1254\n",
      "\n",
      "Iteration 1255 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.077 MB, Params: 526,521 (2.009 MB), Total: 2.09 MB, FLOPs: 44,111,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1255/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1255\n",
      "\n",
      "Iteration 1256 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.077 MB, Params: 525,435 (2.004 MB), Total: 2.08 MB, FLOPs: 44,098,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1256/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1256\n",
      "\n",
      "Iteration 1257 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.077 MB, Params: 524,524 (2.001 MB), Total: 2.08 MB, FLOPs: 43,720,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1257/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1257\n",
      "\n",
      "Iteration 1258 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 39)]\n",
      "Input: 0.077 MB, Params: 523,154 (1.996 MB), Total: 2.07 MB, FLOPs: 43,565,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1258/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1258\n",
      "\n",
      "Iteration 1259 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.077 MB, Params: 520,452 (1.985 MB), Total: 2.06 MB, FLOPs: 43,533,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1259/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1259\n",
      "\n",
      "Iteration 1260 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.077 MB, Params: 518,596 (1.978 MB), Total: 2.06 MB, FLOPs: 43,482,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1260/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1260\n",
      "\n",
      "Iteration 1261 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.077 MB, Params: 516,740 (1.971 MB), Total: 2.05 MB, FLOPs: 43,432,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1261/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1261\n",
      "\n",
      "Iteration 1262 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.077 MB, Params: 514,056 (1.961 MB), Total: 2.04 MB, FLOPs: 43,400,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1262/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1262\n",
      "\n",
      "Iteration 1263 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.077 MB, Params: 511,372 (1.951 MB), Total: 2.03 MB, FLOPs: 43,367,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1263/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1263\n",
      "\n",
      "Iteration 1264 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.077 MB, Params: 510,313 (1.947 MB), Total: 2.02 MB, FLOPs: 43,355,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1264/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1264\n",
      "\n",
      "Iteration 1265 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.077 MB, Params: 508,997 (1.942 MB), Total: 2.02 MB, FLOPs: 43,292,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1265/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1265\n",
      "\n",
      "Iteration 1266 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.077 MB, Params: 506,322 (1.931 MB), Total: 2.01 MB, FLOPs: 43,259,936\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1266/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1266\n",
      "\n",
      "Iteration 1267 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.077 MB, Params: 505,006 (1.926 MB), Total: 2.00 MB, FLOPs: 43,196,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1267/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1267\n",
      "\n",
      "Iteration 1268 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 503,956 (1.922 MB), Total: 2.00 MB, FLOPs: 43,184,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1268/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1268\n",
      "\n",
      "Iteration 1269 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.077 MB, Params: 503,027 (1.919 MB), Total: 2.00 MB, FLOPs: 42,998,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1269/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1269\n",
      "\n",
      "Iteration 1270 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.077 MB, Params: 501,216 (1.912 MB), Total: 1.99 MB, FLOPs: 42,949,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1270/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1270\n",
      "\n",
      "Iteration 1271 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 28)]\n",
      "Input: 0.077 MB, Params: 500,314 (1.909 MB), Total: 1.99 MB, FLOPs: 42,573,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1271/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1271\n",
      "\n",
      "Iteration 1272 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.077 MB, Params: 499,264 (1.905 MB), Total: 1.98 MB, FLOPs: 42,560,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1272/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1272\n",
      "\n",
      "Iteration 1273 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 498,214 (1.901 MB), Total: 1.98 MB, FLOPs: 42,548,180\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1273/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1273\n",
      "\n",
      "Iteration 1274 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 16)]\n",
      "Input: 0.077 MB, Params: 497,879 (1.899 MB), Total: 1.98 MB, FLOPs: 42,253,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 29.508%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1274/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1274\n",
      "\n",
      "Iteration 1275 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 38)]\n",
      "Input: 0.077 MB, Params: 496,977 (1.896 MB), Total: 1.97 MB, FLOPs: 41,877,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1275/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1275\n",
      "\n",
      "Iteration 1276 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.077 MB, Params: 495,670 (1.891 MB), Total: 1.97 MB, FLOPs: 41,815,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1276/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1276\n",
      "\n",
      "Iteration 1277 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 51)]\n",
      "Input: 0.077 MB, Params: 494,336 (1.886 MB), Total: 1.96 MB, FLOPs: 41,663,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1277/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1277\n",
      "\n",
      "Iteration 1278 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.077 MB, Params: 492,534 (1.879 MB), Total: 1.96 MB, FLOPs: 41,614,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1278/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1278\n",
      "\n",
      "Iteration 1279 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 51)]\n",
      "Input: 0.077 MB, Params: 491,484 (1.875 MB), Total: 1.95 MB, FLOPs: 41,601,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1279/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1279\n",
      "\n",
      "Iteration 1280 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 51)]\n",
      "Input: 0.077 MB, Params: 490,150 (1.870 MB), Total: 1.95 MB, FLOPs: 41,449,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1280/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1280\n",
      "\n",
      "Iteration 1281 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.077 MB, Params: 489,257 (1.866 MB), Total: 1.94 MB, FLOPs: 41,271,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1281/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1281\n",
      "\n",
      "Iteration 1282 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.077 MB, Params: 487,977 (1.861 MB), Total: 1.94 MB, FLOPs: 41,210,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1282/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1282\n",
      "\n",
      "Iteration 1283 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 25)]\n",
      "Input: 0.077 MB, Params: 487,084 (1.858 MB), Total: 1.93 MB, FLOPs: 40,835,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1283/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1283\n",
      "\n",
      "Iteration 1284 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 69)]\n",
      "Input: 0.077 MB, Params: 485,291 (1.851 MB), Total: 1.93 MB, FLOPs: 40,787,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1284/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1284\n",
      "\n",
      "Iteration 1285 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.077 MB, Params: 484,241 (1.847 MB), Total: 1.92 MB, FLOPs: 40,774,820\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1285/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1285\n",
      "\n",
      "Iteration 1286 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.077 MB, Params: 483,735 (1.845 MB), Total: 1.92 MB, FLOPs: 40,370,820\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1286/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1286\n",
      "\n",
      "Iteration 1287 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.077 MB, Params: 482,685 (1.841 MB), Total: 1.92 MB, FLOPs: 40,358,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1287/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1287\n",
      "\n",
      "Iteration 1288 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.077 MB, Params: 481,635 (1.837 MB), Total: 1.91 MB, FLOPs: 40,345,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1288/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1288\n",
      "\n",
      "Iteration 1289 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.077 MB, Params: 479,050 (1.827 MB), Total: 1.90 MB, FLOPs: 40,314,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1289/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1289\n",
      "\n",
      "Iteration 1290 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 58)]\n",
      "Input: 0.077 MB, Params: 477,266 (1.821 MB), Total: 1.90 MB, FLOPs: 40,266,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1290/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1290\n",
      "\n",
      "Iteration 1291 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 15)]\n",
      "Input: 0.077 MB, Params: 475,950 (1.816 MB), Total: 1.89 MB, FLOPs: 40,116,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1291/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1291\n",
      "\n",
      "Iteration 1292 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.077 MB, Params: 473,374 (1.806 MB), Total: 1.88 MB, FLOPs: 40,085,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1292/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1292\n",
      "\n",
      "Iteration 1293 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.077 MB, Params: 472,121 (1.801 MB), Total: 1.88 MB, FLOPs: 40,025,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1293/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1293\n",
      "\n",
      "Iteration 1294 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.077 MB, Params: 471,089 (1.797 MB), Total: 1.87 MB, FLOPs: 40,013,320\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1294/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1294\n",
      "\n",
      "Iteration 1295 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.077 MB, Params: 469,836 (1.792 MB), Total: 1.87 MB, FLOPs: 39,953,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1295/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1295\n",
      "\n",
      "Iteration 1296 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.077 MB, Params: 468,804 (1.788 MB), Total: 1.87 MB, FLOPs: 39,940,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1296/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1296\n",
      "\n",
      "Iteration 1297 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 37)]\n",
      "Input: 0.077 MB, Params: 467,506 (1.783 MB), Total: 1.86 MB, FLOPs: 39,792,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1297/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1297\n",
      "\n",
      "Iteration 1298 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.077 MB, Params: 465,749 (1.777 MB), Total: 1.85 MB, FLOPs: 39,744,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1298/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1298\n",
      "\n",
      "Iteration 1299 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.077 MB, Params: 463,992 (1.770 MB), Total: 1.85 MB, FLOPs: 39,697,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1299/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1299\n",
      "\n",
      "Iteration 1300 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 462,235 (1.763 MB), Total: 1.84 MB, FLOPs: 39,649,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1300/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1300\n",
      "\n",
      "Iteration 1301 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 37)]\n",
      "Input: 0.077 MB, Params: 460,937 (1.758 MB), Total: 1.84 MB, FLOPs: 39,501,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1301/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1301\n",
      "\n",
      "Iteration 1302 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.077 MB, Params: 459,905 (1.754 MB), Total: 1.83 MB, FLOPs: 39,488,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1302/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1302\n",
      "\n",
      "Iteration 1303 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.077 MB, Params: 457,383 (1.745 MB), Total: 1.82 MB, FLOPs: 39,458,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1303/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1303\n",
      "\n",
      "Iteration 1304 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.077 MB, Params: 456,526 (1.742 MB), Total: 1.82 MB, FLOPs: 39,287,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1304/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1304\n",
      "\n",
      "Iteration 1305 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.077 MB, Params: 454,004 (1.732 MB), Total: 1.81 MB, FLOPs: 39,257,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1305/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1305\n",
      "\n",
      "Iteration 1306 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 452,265 (1.725 MB), Total: 1.80 MB, FLOPs: 39,209,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1306/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1306\n",
      "\n",
      "Iteration 1307 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.077 MB, Params: 450,526 (1.719 MB), Total: 1.80 MB, FLOPs: 39,162,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1307/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1307\n",
      "\n",
      "Iteration 1308 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.077 MB, Params: 449,512 (1.715 MB), Total: 1.79 MB, FLOPs: 39,150,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1308/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1308\n",
      "\n",
      "Iteration 1309 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 10)]\n",
      "Input: 0.077 MB, Params: 449,186 (1.714 MB), Total: 1.79 MB, FLOPs: 38,863,356\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1309/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1309\n",
      "\n",
      "Iteration 1310 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.077 MB, Params: 447,996 (1.709 MB), Total: 1.79 MB, FLOPs: 38,806,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1310/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1310\n",
      "\n",
      "Iteration 1311 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 33)]\n",
      "Input: 0.077 MB, Params: 446,716 (1.704 MB), Total: 1.78 MB, FLOPs: 38,659,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Finished fine tuning.\n",
      "Iteration 1311/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1311\n",
      "\n",
      "Iteration 1312 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.077 MB, Params: 444,221 (1.695 MB), Total: 1.77 MB, FLOPs: 38,629,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1312/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1312\n",
      "\n",
      "Iteration 1313 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.077 MB, Params: 443,216 (1.691 MB), Total: 1.77 MB, FLOPs: 38,617,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1313/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1313\n",
      "\n",
      "Iteration 1314 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 14)]\n",
      "Input: 0.077 MB, Params: 442,341 (1.687 MB), Total: 1.76 MB, FLOPs: 38,252,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1314/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1314\n",
      "\n",
      "Iteration 1315 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.077 MB, Params: 441,336 (1.684 MB), Total: 1.76 MB, FLOPs: 38,240,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1315/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1315\n",
      "\n",
      "Iteration 1316 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.077 MB, Params: 440,331 (1.680 MB), Total: 1.76 MB, FLOPs: 38,228,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1316/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1316\n",
      "\n",
      "Iteration 1317 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 72)]\n",
      "Input: 0.077 MB, Params: 439,150 (1.675 MB), Total: 1.75 MB, FLOPs: 38,171,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1317/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1317\n",
      "\n",
      "Iteration 1318 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 6)]\n",
      "Input: 0.077 MB, Params: 438,662 (1.673 MB), Total: 1.75 MB, FLOPs: 37,782,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1318/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1318\n",
      "\n",
      "Iteration 1319 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.077 MB, Params: 436,194 (1.664 MB), Total: 1.74 MB, FLOPs: 37,752,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1319/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1319\n",
      "\n",
      "Iteration 1320 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.077 MB, Params: 435,198 (1.660 MB), Total: 1.74 MB, FLOPs: 37,740,772\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1320/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1320\n",
      "\n",
      "Iteration 1321 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.077 MB, Params: 434,359 (1.657 MB), Total: 1.73 MB, FLOPs: 37,573,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1321/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1321\n",
      "\n",
      "Iteration 1322 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 92)]\n",
      "Input: 0.077 MB, Params: 431,900 (1.648 MB), Total: 1.72 MB, FLOPs: 37,543,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1322/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1322\n",
      "\n",
      "Iteration 1323 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.077 MB, Params: 430,913 (1.644 MB), Total: 1.72 MB, FLOPs: 37,531,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1323/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1323\n",
      "\n",
      "Iteration 1324 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 191)]\n",
      "Input: 0.077 MB, Params: 429,926 (1.640 MB), Total: 1.72 MB, FLOPs: 37,520,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1324/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1324\n",
      "\n",
      "Iteration 1325 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.077 MB, Params: 427,485 (1.631 MB), Total: 1.71 MB, FLOPs: 37,490,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1325/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1325\n",
      "\n",
      "Iteration 1326 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 40)]\n",
      "Input: 0.077 MB, Params: 426,223 (1.626 MB), Total: 1.70 MB, FLOPs: 37,346,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1326/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1326\n",
      "\n",
      "Iteration 1327 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.077 MB, Params: 425,245 (1.622 MB), Total: 1.70 MB, FLOPs: 37,334,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Finished fine tuning.\n",
      "Iteration 1327/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1327\n",
      "\n",
      "Iteration 1328 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.077 MB, Params: 422,813 (1.613 MB), Total: 1.69 MB, FLOPs: 37,305,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.967%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.421%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1328/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1328\n",
      "\n",
      "Iteration 1329 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.077 MB, Params: 420,381 (1.604 MB), Total: 1.68 MB, FLOPs: 37,276,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1329/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1329\n",
      "\n",
      "Iteration 1330 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.077 MB, Params: 419,209 (1.599 MB), Total: 1.68 MB, FLOPs: 37,220,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1330/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1330\n",
      "\n",
      "Iteration 1331 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 417,956 (1.594 MB), Total: 1.67 MB, FLOPs: 37,076,320\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1331/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1331\n",
      "\n",
      "Iteration 1332 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 48)]\n",
      "Input: 0.077 MB, Params: 416,703 (1.590 MB), Total: 1.67 MB, FLOPs: 36,932,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1332/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1332\n",
      "\n",
      "Iteration 1333 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.077 MB, Params: 415,045 (1.583 MB), Total: 1.66 MB, FLOPs: 36,887,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1333/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1333\n",
      "\n",
      "Iteration 1334 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.077 MB, Params: 412,622 (1.574 MB), Total: 1.65 MB, FLOPs: 36,858,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1334/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1334\n",
      "\n",
      "Iteration 1335 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.077 MB, Params: 411,671 (1.570 MB), Total: 1.65 MB, FLOPs: 36,846,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1335/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1335\n",
      "\n",
      "Iteration 1336 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 410,720 (1.567 MB), Total: 1.64 MB, FLOPs: 36,835,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Finished fine tuning.\n",
      "Iteration 1336/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1336\n",
      "\n",
      "Iteration 1337 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.077 MB, Params: 409,769 (1.563 MB), Total: 1.64 MB, FLOPs: 36,824,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1337/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1337\n",
      "\n",
      "Iteration 1338 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.077 MB, Params: 408,957 (1.560 MB), Total: 1.64 MB, FLOPs: 36,661,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1338/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1338\n",
      "\n",
      "Iteration 1339 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.077 MB, Params: 408,006 (1.556 MB), Total: 1.63 MB, FLOPs: 36,650,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.874%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1339/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1339\n",
      "\n",
      "Iteration 1340 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.077 MB, Params: 407,689 (1.555 MB), Total: 1.63 MB, FLOPs: 36,370,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 26.230%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1340/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1340\n",
      "\n",
      "Iteration 1341 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.077 MB, Params: 406,738 (1.552 MB), Total: 1.63 MB, FLOPs: 36,359,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.328%\n",
      "Finished fine tuning.\n",
      "Iteration 1341/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1341\n",
      "\n",
      "Iteration 1342 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.077 MB, Params: 405,494 (1.547 MB), Total: 1.62 MB, FLOPs: 36,216,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1342/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1342\n",
      "\n",
      "Iteration 1343 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.077 MB, Params: 404,543 (1.543 MB), Total: 1.62 MB, FLOPs: 36,205,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1343/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1343\n",
      "\n",
      "Iteration 1344 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.077 MB, Params: 403,592 (1.540 MB), Total: 1.62 MB, FLOPs: 36,194,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Finished fine tuning.\n",
      "Iteration 1344/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1344\n",
      "\n",
      "Iteration 1345 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 68)]\n",
      "Input: 0.077 MB, Params: 401,943 (1.533 MB), Total: 1.61 MB, FLOPs: 36,149,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Finished fine tuning.\n",
      "Iteration 1345/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1345\n",
      "\n",
      "Iteration 1346 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.077 MB, Params: 400,992 (1.530 MB), Total: 1.61 MB, FLOPs: 36,137,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1346/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1346\n",
      "\n",
      "Iteration 1347 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.077 MB, Params: 400,513 (1.528 MB), Total: 1.60 MB, FLOPs: 35,755,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1347/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1347\n",
      "\n",
      "Iteration 1348 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.077 MB, Params: 399,269 (1.523 MB), Total: 1.60 MB, FLOPs: 35,613,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1348/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1348\n",
      "\n",
      "Iteration 1349 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.077 MB, Params: 396,927 (1.514 MB), Total: 1.59 MB, FLOPs: 35,585,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1349/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1349\n",
      "\n",
      "Iteration 1350 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.077 MB, Params: 395,809 (1.510 MB), Total: 1.59 MB, FLOPs: 35,531,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1350/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1350\n",
      "\n",
      "Iteration 1351 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.077 MB, Params: 394,867 (1.506 MB), Total: 1.58 MB, FLOPs: 35,520,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1351/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1351\n",
      "\n",
      "Iteration 1352 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 19)]\n",
      "Input: 0.077 MB, Params: 393,632 (1.502 MB), Total: 1.58 MB, FLOPs: 35,378,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1352/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1352\n",
      "\n",
      "Iteration 1353 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.077 MB, Params: 391,299 (1.493 MB), Total: 1.57 MB, FLOPs: 35,350,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1353/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1353\n",
      "\n",
      "Iteration 1354 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 390,190 (1.488 MB), Total: 1.57 MB, FLOPs: 35,297,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.235%\n",
      "Finished fine tuning.\n",
      "Iteration 1354/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1354\n",
      "\n",
      "Iteration 1355 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.077 MB, Params: 387,857 (1.480 MB), Total: 1.56 MB, FLOPs: 35,269,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.781%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Finished fine tuning.\n",
      "Iteration 1355/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1355\n",
      "\n",
      "Iteration 1356 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.077 MB, Params: 387,378 (1.478 MB), Total: 1.55 MB, FLOPs: 34,887,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.049%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1356/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1356\n",
      "\n",
      "Iteration 1357 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.077 MB, Params: 385,774 (1.472 MB), Total: 1.55 MB, FLOPs: 34,843,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.596%\n",
      "Finished fine tuning.\n",
      "Iteration 1357/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1357\n",
      "\n",
      "Iteration 1358 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.077 MB, Params: 384,850 (1.468 MB), Total: 1.54 MB, FLOPs: 34,832,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.142%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.689%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1358/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1358\n",
      "\n",
      "Iteration 1359 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 23)]\n",
      "Input: 0.077 MB, Params: 384,371 (1.466 MB), Total: 1.54 MB, FLOPs: 34,449,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1359/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1359\n",
      "\n",
      "Iteration 1360 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 58)]\n",
      "Input: 0.077 MB, Params: 383,586 (1.463 MB), Total: 1.54 MB, FLOPs: 34,292,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1360/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1360\n",
      "\n",
      "Iteration 1361 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.077 MB, Params: 382,774 (1.460 MB), Total: 1.54 MB, FLOPs: 33,961,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1361/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1361\n",
      "\n",
      "Iteration 1362 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.077 MB, Params: 381,850 (1.457 MB), Total: 1.53 MB, FLOPs: 33,950,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1362/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1362\n",
      "\n",
      "Iteration 1363 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.077 MB, Params: 380,926 (1.453 MB), Total: 1.53 MB, FLOPs: 33,939,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1363/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1363\n",
      "\n",
      "Iteration 1364 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.077 MB, Params: 378,629 (1.444 MB), Total: 1.52 MB, FLOPs: 33,912,176\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1364/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1364\n",
      "\n",
      "Iteration 1365 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 97)]\n",
      "Input: 0.077 MB, Params: 376,332 (1.436 MB), Total: 1.51 MB, FLOPs: 33,884,624\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1365/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1365\n",
      "\n",
      "Iteration 1366 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.077 MB, Params: 375,426 (1.432 MB), Total: 1.51 MB, FLOPs: 33,873,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1366/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1366\n",
      "\n",
      "Iteration 1367 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.077 MB, Params: 373,840 (1.426 MB), Total: 1.50 MB, FLOPs: 33,830,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1367/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1367\n",
      "\n",
      "Iteration 1368 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.077 MB, Params: 372,254 (1.420 MB), Total: 1.50 MB, FLOPs: 33,786,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1368/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1368\n",
      "\n",
      "Iteration 1369 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.077 MB, Params: 370,668 (1.414 MB), Total: 1.49 MB, FLOPs: 33,742,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1369/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1369\n",
      "\n",
      "Iteration 1370 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.077 MB, Params: 369,595 (1.410 MB), Total: 1.49 MB, FLOPs: 33,691,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1370/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1370\n",
      "\n",
      "Iteration 1371 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.077 MB, Params: 367,334 (1.401 MB), Total: 1.48 MB, FLOPs: 33,664,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1371/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1371\n",
      "\n",
      "Iteration 1372 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.077 MB, Params: 365,766 (1.395 MB), Total: 1.47 MB, FLOPs: 33,620,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1372/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1372\n",
      "\n",
      "Iteration 1373 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 19)]\n",
      "Input: 0.077 MB, Params: 364,990 (1.392 MB), Total: 1.47 MB, FLOPs: 33,465,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1373/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1373\n",
      "\n",
      "Iteration 1374 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 89)]\n",
      "Input: 0.077 MB, Params: 362,738 (1.384 MB), Total: 1.46 MB, FLOPs: 33,438,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1374/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1374\n",
      "\n",
      "Iteration 1375 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.077 MB, Params: 361,674 (1.380 MB), Total: 1.46 MB, FLOPs: 33,387,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1375/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1375\n",
      "\n",
      "Iteration 1376 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.077 MB, Params: 359,422 (1.371 MB), Total: 1.45 MB, FLOPs: 33,360,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1376/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1376\n",
      "\n",
      "Iteration 1377 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 32)]\n",
      "Input: 0.077 MB, Params: 358,619 (1.368 MB), Total: 1.44 MB, FLOPs: 33,031,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.410%\n",
      "Finished fine tuning.\n",
      "Iteration 1377/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1377\n",
      "\n",
      "Iteration 1378 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.077 MB, Params: 357,555 (1.364 MB), Total: 1.44 MB, FLOPs: 32,980,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1378/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1378\n",
      "\n",
      "Iteration 1379 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.077 MB, Params: 356,676 (1.361 MB), Total: 1.44 MB, FLOPs: 32,970,056\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1379/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1379\n",
      "\n",
      "Iteration 1380 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 0)]\n",
      "Input: 0.077 MB, Params: 355,495 (1.356 MB), Total: 1.43 MB, FLOPs: 32,833,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1380/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1380\n",
      "\n",
      "Iteration 1381 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.077 MB, Params: 354,440 (1.352 MB), Total: 1.43 MB, FLOPs: 32,783,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1381/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1381\n",
      "\n",
      "Iteration 1382 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 352,917 (1.346 MB), Total: 1.42 MB, FLOPs: 32,741,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Finished fine tuning.\n",
      "Iteration 1382/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1382\n",
      "\n",
      "Iteration 1383 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.077 MB, Params: 351,871 (1.342 MB), Total: 1.42 MB, FLOPs: 32,691,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1383/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1383\n",
      "\n",
      "Iteration 1384 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.077 MB, Params: 349,637 (1.334 MB), Total: 1.41 MB, FLOPs: 32,664,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1384/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1384\n",
      "\n",
      "Iteration 1385 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 347,403 (1.325 MB), Total: 1.40 MB, FLOPs: 32,637,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Finished fine tuning.\n",
      "Iteration 1385/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1385\n",
      "\n",
      "Iteration 1386 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 167)]\n",
      "Input: 0.077 MB, Params: 346,542 (1.322 MB), Total: 1.40 MB, FLOPs: 32,627,412\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.503%\n",
      "Finished fine tuning.\n",
      "Iteration 1386/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1386\n",
      "\n",
      "Iteration 1387 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.077 MB, Params: 344,317 (1.313 MB), Total: 1.39 MB, FLOPs: 32,600,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1387/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1387\n",
      "\n",
      "Iteration 1388 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.077 MB, Params: 343,271 (1.309 MB), Total: 1.39 MB, FLOPs: 32,550,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1388/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1388\n",
      "\n",
      "Iteration 1389 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 341,793 (1.304 MB), Total: 1.38 MB, FLOPs: 32,510,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.863%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1389/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1389\n",
      "\n",
      "Iteration 1390 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 12)]\n",
      "Input: 0.077 MB, Params: 341,332 (1.302 MB), Total: 1.38 MB, FLOPs: 32,142,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1390/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1390\n",
      "\n",
      "Iteration 1391 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.077 MB, Params: 339,854 (1.296 MB), Total: 1.37 MB, FLOPs: 32,101,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1391/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1391\n",
      "\n",
      "Iteration 1392 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.077 MB, Params: 339,002 (1.293 MB), Total: 1.37 MB, FLOPs: 32,091,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1392/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1392\n",
      "\n",
      "Iteration 1393 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.077 MB, Params: 336,804 (1.285 MB), Total: 1.36 MB, FLOPs: 32,065,036\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1393/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1393\n",
      "\n",
      "Iteration 1394 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 47)]\n",
      "Input: 0.077 MB, Params: 336,046 (1.282 MB), Total: 1.36 MB, FLOPs: 31,913,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.956%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1394/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1394\n",
      "\n",
      "Iteration 1395 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 64)]\n",
      "Input: 0.077 MB, Params: 334,577 (1.276 MB), Total: 1.35 MB, FLOPs: 31,873,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1395/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1395\n",
      "\n",
      "Iteration 1396 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.077 MB, Params: 333,819 (1.273 MB), Total: 1.35 MB, FLOPs: 31,721,856\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1396/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1396\n",
      "\n",
      "Iteration 1397 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 331,630 (1.265 MB), Total: 1.34 MB, FLOPs: 31,695,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1397/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1397\n",
      "\n",
      "Iteration 1398 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 330,170 (1.259 MB), Total: 1.34 MB, FLOPs: 31,655,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1398/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1398\n",
      "\n",
      "Iteration 1399 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 25)]\n",
      "Input: 0.077 MB, Params: 329,160 (1.256 MB), Total: 1.33 MB, FLOPs: 31,606,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1399/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1399\n",
      "\n",
      "Iteration 1400 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.077 MB, Params: 328,326 (1.252 MB), Total: 1.33 MB, FLOPs: 31,596,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1400/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1400\n",
      "\n",
      "Iteration 1401 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.077 MB, Params: 327,492 (1.249 MB), Total: 1.33 MB, FLOPs: 31,586,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1401/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1401\n",
      "\n",
      "Iteration 1402 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.077 MB, Params: 325,330 (1.241 MB), Total: 1.32 MB, FLOPs: 31,561,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1402/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1402\n",
      "\n",
      "Iteration 1403 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.077 MB, Params: 324,505 (1.238 MB), Total: 1.31 MB, FLOPs: 31,551,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1403/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1403\n",
      "\n",
      "Iteration 1404 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 52)]\n",
      "Input: 0.077 MB, Params: 323,747 (1.235 MB), Total: 1.31 MB, FLOPs: 31,399,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1404/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1404\n",
      "\n",
      "Iteration 1405 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.077 MB, Params: 322,737 (1.231 MB), Total: 1.31 MB, FLOPs: 31,351,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1405/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1405\n",
      "\n",
      "Iteration 1406 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.077 MB, Params: 321,912 (1.228 MB), Total: 1.30 MB, FLOPs: 31,341,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1406/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1406\n",
      "\n",
      "Iteration 1407 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 38)]\n",
      "Input: 0.077 MB, Params: 320,803 (1.224 MB), Total: 1.30 MB, FLOPs: 31,212,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1407/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1407\n",
      "\n",
      "Iteration 1408 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.077 MB, Params: 319,978 (1.221 MB), Total: 1.30 MB, FLOPs: 31,202,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1408/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1408\n",
      "\n",
      "Iteration 1409 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 318,545 (1.215 MB), Total: 1.29 MB, FLOPs: 31,163,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1409/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1409\n",
      "\n",
      "Iteration 1410 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.077 MB, Params: 316,419 (1.207 MB), Total: 1.28 MB, FLOPs: 31,138,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1410/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1410\n",
      "\n",
      "Iteration 1411 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.077 MB, Params: 314,995 (1.202 MB), Total: 1.28 MB, FLOPs: 31,098,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Finished fine tuning.\n",
      "Iteration 1411/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1411\n",
      "\n",
      "Iteration 1412 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.077 MB, Params: 313,571 (1.196 MB), Total: 1.27 MB, FLOPs: 31,059,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1412/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1412\n",
      "\n",
      "Iteration 1413 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.077 MB, Params: 312,804 (1.193 MB), Total: 1.27 MB, FLOPs: 30,743,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1413/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1413\n",
      "\n",
      "Iteration 1414 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.077 MB, Params: 311,380 (1.188 MB), Total: 1.26 MB, FLOPs: 30,703,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Finished fine tuning.\n",
      "Iteration 1414/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1414\n",
      "\n",
      "Iteration 1415 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.077 MB, Params: 309,281 (1.180 MB), Total: 1.26 MB, FLOPs: 30,678,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1415/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1415\n",
      "\n",
      "Iteration 1416 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.077 MB, Params: 308,829 (1.178 MB), Total: 1.25 MB, FLOPs: 30,317,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1416/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1416\n",
      "\n",
      "Iteration 1417 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.077 MB, Params: 308,022 (1.175 MB), Total: 1.25 MB, FLOPs: 30,308,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1417/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1417\n",
      "\n",
      "Iteration 1418 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.077 MB, Params: 307,057 (1.171 MB), Total: 1.25 MB, FLOPs: 30,261,956\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Finished fine tuning.\n",
      "Iteration 1418/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1418\n",
      "\n",
      "Iteration 1419 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 50)]\n",
      "Input: 0.077 MB, Params: 305,651 (1.166 MB), Total: 1.24 MB, FLOPs: 30,223,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1419/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1419\n",
      "\n",
      "Iteration 1420 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 3)]\n",
      "Input: 0.077 MB, Params: 304,695 (1.162 MB), Total: 1.24 MB, FLOPs: 30,177,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1420/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1420\n",
      "\n",
      "Iteration 1421 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.077 MB, Params: 303,739 (1.159 MB), Total: 1.24 MB, FLOPs: 30,131,624\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1421/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1421\n",
      "\n",
      "Iteration 1422 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.077 MB, Params: 302,783 (1.155 MB), Total: 1.23 MB, FLOPs: 30,085,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1422/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1422\n",
      "\n",
      "Iteration 1423 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.077 MB, Params: 301,404 (1.150 MB), Total: 1.23 MB, FLOPs: 30,048,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.224%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1423/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1423\n",
      "\n",
      "Iteration 1424 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.077 MB, Params: 300,646 (1.147 MB), Total: 1.22 MB, FLOPs: 29,739,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1424/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1424\n",
      "\n",
      "Iteration 1425 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.077 MB, Params: 299,915 (1.144 MB), Total: 1.22 MB, FLOPs: 29,593,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1425/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1425\n",
      "\n",
      "Iteration 1426 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 2)]\n",
      "Input: 0.077 MB, Params: 299,184 (1.141 MB), Total: 1.22 MB, FLOPs: 29,447,028\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1426/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1426\n",
      "\n",
      "Iteration 1427 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.077 MB, Params: 297,805 (1.136 MB), Total: 1.21 MB, FLOPs: 29,409,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1427/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1427\n",
      "\n",
      "Iteration 1428 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 296,867 (1.132 MB), Total: 1.21 MB, FLOPs: 29,364,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1428/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1428\n",
      "\n",
      "Iteration 1429 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 296,136 (1.130 MB), Total: 1.21 MB, FLOPs: 29,218,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1429/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1429\n",
      "\n",
      "Iteration 1430 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 294,073 (1.122 MB), Total: 1.20 MB, FLOPs: 29,193,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1430/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1430\n",
      "\n",
      "Iteration 1431 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.077 MB, Params: 293,036 (1.118 MB), Total: 1.19 MB, FLOPs: 29,072,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1431/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1431\n",
      "\n",
      "Iteration 1432 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 291,999 (1.114 MB), Total: 1.19 MB, FLOPs: 28,951,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1432/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1432\n",
      "\n",
      "Iteration 1433 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 289,936 (1.106 MB), Total: 1.18 MB, FLOPs: 28,926,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.317%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1433/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1433\n",
      "\n",
      "Iteration 1434 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.077 MB, Params: 288,899 (1.102 MB), Total: 1.18 MB, FLOPs: 28,805,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.770%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1434/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1434\n",
      "\n",
      "Iteration 1435 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.077 MB, Params: 287,988 (1.099 MB), Total: 1.18 MB, FLOPs: 28,761,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Finished fine tuning.\n",
      "Iteration 1435/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1435\n",
      "\n",
      "Iteration 1436 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.077 MB, Params: 286,960 (1.095 MB), Total: 1.17 MB, FLOPs: 28,641,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1436/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1436\n",
      "\n",
      "Iteration 1437 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.077 MB, Params: 286,058 (1.091 MB), Total: 1.17 MB, FLOPs: 28,597,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1437/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1437\n",
      "\n",
      "Iteration 1438 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.077 MB, Params: 285,363 (1.089 MB), Total: 1.17 MB, FLOPs: 28,459,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1438/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1438\n",
      "\n",
      "Iteration 1439 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.077 MB, Params: 284,574 (1.086 MB), Total: 1.16 MB, FLOPs: 28,449,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1439/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1439\n",
      "\n",
      "Iteration 1440 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.077 MB, Params: 283,240 (1.080 MB), Total: 1.16 MB, FLOPs: 28,413,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1440/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1440\n",
      "\n",
      "Iteration 1441 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 281,195 (1.073 MB), Total: 1.15 MB, FLOPs: 28,389,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 1441/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1441\n",
      "\n",
      "Iteration 1442 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.077 MB, Params: 280,415 (1.070 MB), Total: 1.15 MB, FLOPs: 28,379,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Finished fine tuning.\n",
      "Iteration 1442/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1442\n",
      "\n",
      "Iteration 1443 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.077 MB, Params: 279,522 (1.066 MB), Total: 1.14 MB, FLOPs: 28,337,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1443/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1443\n",
      "\n",
      "Iteration 1444 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.077 MB, Params: 278,629 (1.063 MB), Total: 1.14 MB, FLOPs: 28,294,320\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Finished fine tuning.\n",
      "Iteration 1444/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1444\n",
      "\n",
      "Iteration 1445 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.077 MB, Params: 277,934 (1.060 MB), Total: 1.14 MB, FLOPs: 28,155,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.038%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Finished fine tuning.\n",
      "Iteration 1445/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1445\n",
      "\n",
      "Iteration 1446 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.077 MB, Params: 277,491 (1.059 MB), Total: 1.14 MB, FLOPs: 27,801,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.585%\n",
      "Finished fine tuning.\n",
      "Iteration 1446/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1446\n",
      "\n",
      "Iteration 1447 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.077 MB, Params: 276,598 (1.055 MB), Total: 1.13 MB, FLOPs: 27,759,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 72.131%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1447/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1447\n",
      "\n",
      "Iteration 1448 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 34)]\n",
      "Input: 0.077 MB, Params: 275,903 (1.052 MB), Total: 1.13 MB, FLOPs: 27,620,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1448/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1448\n",
      "\n",
      "Iteration 1449 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.077 MB, Params: 273,867 (1.045 MB), Total: 1.12 MB, FLOPs: 27,595,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1449/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1449\n",
      "\n",
      "Iteration 1450 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.077 MB, Params: 273,096 (1.042 MB), Total: 1.12 MB, FLOPs: 27,586,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.399%\n",
      "Finished fine tuning.\n",
      "Iteration 1450/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1450\n",
      "\n",
      "Iteration 1451 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.077 MB, Params: 272,325 (1.039 MB), Total: 1.12 MB, FLOPs: 27,577,452\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Finished fine tuning.\n",
      "Iteration 1451/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1451\n",
      "\n",
      "Iteration 1452 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.077 MB, Params: 271,360 (1.035 MB), Total: 1.11 MB, FLOPs: 27,463,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1452/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1452\n",
      "\n",
      "Iteration 1453 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.077 MB, Params: 270,476 (1.032 MB), Total: 1.11 MB, FLOPs: 27,421,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1453/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1453\n",
      "\n",
      "Iteration 1454 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.077 MB, Params: 268,458 (1.024 MB), Total: 1.10 MB, FLOPs: 27,397,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1454/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1454\n",
      "\n",
      "Iteration 1455 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 267,502 (1.020 MB), Total: 1.10 MB, FLOPs: 27,284,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1455/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1455\n",
      "\n",
      "Iteration 1456 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.077 MB, Params: 266,740 (1.018 MB), Total: 1.09 MB, FLOPs: 27,274,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1456/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1456\n",
      "\n",
      "Iteration 1457 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 265,865 (1.014 MB), Total: 1.09 MB, FLOPs: 27,232,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1457/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1457\n",
      "\n",
      "Iteration 1458 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.077 MB, Params: 264,990 (1.011 MB), Total: 1.09 MB, FLOPs: 27,190,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1458/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1458\n",
      "\n",
      "Iteration 1459 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.077 MB, Params: 264,313 (1.008 MB), Total: 1.09 MB, FLOPs: 27,055,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1459/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1459\n",
      "\n",
      "Iteration 1460 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.077 MB, Params: 263,438 (1.005 MB), Total: 1.08 MB, FLOPs: 27,013,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1460/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1460\n",
      "\n",
      "Iteration 1461 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 262,518 (1.001 MB), Total: 1.08 MB, FLOPs: 26,903,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Finished fine tuning.\n",
      "Iteration 1461/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1461\n",
      "\n",
      "Iteration 1462 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 77)]\n",
      "Input: 0.077 MB, Params: 261,756 (0.999 MB), Total: 1.08 MB, FLOPs: 26,894,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1462/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1462\n",
      "\n",
      "Iteration 1463 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 2)]\n",
      "Input: 0.077 MB, Params: 261,585 (0.998 MB), Total: 1.07 MB, FLOPs: 25,988,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1463/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1463\n",
      "\n",
      "Iteration 1464 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.077 MB, Params: 259,585 (0.990 MB), Total: 1.07 MB, FLOPs: 25,964,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1464/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1464\n",
      "\n",
      "Iteration 1465 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.077 MB, Params: 258,832 (0.987 MB), Total: 1.06 MB, FLOPs: 25,955,470\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1465/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1465\n",
      "\n",
      "Iteration 1466 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.077 MB, Params: 258,389 (0.986 MB), Total: 1.06 MB, FLOPs: 25,601,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1466/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1466\n",
      "\n",
      "Iteration 1467 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.077 MB, Params: 256,398 (0.978 MB), Total: 1.05 MB, FLOPs: 25,577,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1467/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1467\n",
      "\n",
      "Iteration 1468 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.077 MB, Params: 254,407 (0.970 MB), Total: 1.05 MB, FLOPs: 25,554,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1468/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1468\n",
      "\n",
      "Iteration 1469 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.077 MB, Params: 253,964 (0.969 MB), Total: 1.05 MB, FLOPs: 25,200,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1469/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1469\n",
      "\n",
      "Iteration 1470 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.077 MB, Params: 253,229 (0.966 MB), Total: 1.04 MB, FLOPs: 25,191,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1470/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1470\n",
      "\n",
      "Iteration 1471 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.077 MB, Params: 251,247 (0.958 MB), Total: 1.04 MB, FLOPs: 25,167,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1471/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1471\n",
      "\n",
      "Iteration 1472 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.077 MB, Params: 250,521 (0.956 MB), Total: 1.03 MB, FLOPs: 25,159,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1472/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1472\n",
      "\n",
      "Iteration 1473 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.077 MB, Params: 249,795 (0.953 MB), Total: 1.03 MB, FLOPs: 25,150,602\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1473/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1473\n",
      "\n",
      "Iteration 1474 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.077 MB, Params: 247,831 (0.945 MB), Total: 1.02 MB, FLOPs: 25,127,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1474/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1474\n",
      "\n",
      "Iteration 1475 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.077 MB, Params: 245,867 (0.938 MB), Total: 1.01 MB, FLOPs: 25,103,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1475/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1475\n",
      "\n",
      "Iteration 1476 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.077 MB, Params: 245,622 (0.937 MB), Total: 1.01 MB, FLOPs: 24,881,090\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1476/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1476\n",
      "\n",
      "Iteration 1477 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.077 MB, Params: 244,432 (0.932 MB), Total: 1.01 MB, FLOPs: 24,849,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1477/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1477\n",
      "\n",
      "Iteration 1478 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.077 MB, Params: 243,764 (0.930 MB), Total: 1.01 MB, FLOPs: 24,715,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1478/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1478\n",
      "\n",
      "Iteration 1479 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.077 MB, Params: 242,907 (0.927 MB), Total: 1.00 MB, FLOPs: 24,674,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1479/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1479\n",
      "\n",
      "Iteration 1480 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.077 MB, Params: 242,005 (0.923 MB), Total: 1.00 MB, FLOPs: 24,566,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1480/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1480\n",
      "\n",
      "Iteration 1481 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.077 MB, Params: 240,050 (0.916 MB), Total: 0.99 MB, FLOPs: 24,543,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1481/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1481\n",
      "\n",
      "Iteration 1482 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.077 MB, Params: 239,202 (0.912 MB), Total: 0.99 MB, FLOPs: 24,502,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.945%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1482/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1482\n",
      "\n",
      "Iteration 1483 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.077 MB, Params: 238,039 (0.908 MB), Total: 0.98 MB, FLOPs: 24,471,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1483/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1483\n",
      "\n",
      "Iteration 1484 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.077 MB, Params: 237,380 (0.906 MB), Total: 0.98 MB, FLOPs: 24,340,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1484/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1484\n",
      "\n",
      "Iteration 1485 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.077 MB, Params: 236,541 (0.902 MB), Total: 0.98 MB, FLOPs: 24,300,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1485/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1485\n",
      "\n",
      "Iteration 1486 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.077 MB, Params: 235,882 (0.900 MB), Total: 0.98 MB, FLOPs: 24,168,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1486/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1486\n",
      "\n",
      "Iteration 1487 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.077 MB, Params: 235,043 (0.897 MB), Total: 0.97 MB, FLOPs: 24,128,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1487/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1487\n",
      "\n",
      "Iteration 1488 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 132)]\n",
      "Input: 0.077 MB, Params: 234,344 (0.894 MB), Total: 0.97 MB, FLOPs: 24,119,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1488/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1488\n",
      "\n",
      "Iteration 1489 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.077 MB, Params: 233,645 (0.891 MB), Total: 0.97 MB, FLOPs: 24,111,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1489/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1489\n",
      "\n",
      "Iteration 1490 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.077 MB, Params: 231,717 (0.884 MB), Total: 0.96 MB, FLOPs: 24,088,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1490/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1490\n",
      "\n",
      "Iteration 1491 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 5)]\n",
      "Input: 0.077 MB, Params: 231,058 (0.881 MB), Total: 0.96 MB, FLOPs: 23,956,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1491/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1491\n",
      "\n",
      "Iteration 1492 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.077 MB, Params: 230,368 (0.879 MB), Total: 0.96 MB, FLOPs: 23,948,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1492/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1492\n",
      "\n",
      "Iteration 1493 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.077 MB, Params: 229,520 (0.876 MB), Total: 0.95 MB, FLOPs: 23,847,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.852%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1493/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1493\n",
      "\n",
      "Iteration 1494 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.077 MB, Params: 228,830 (0.873 MB), Total: 0.95 MB, FLOPs: 23,839,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.306%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1494/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1494\n",
      "\n",
      "Iteration 1495 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.077 MB, Params: 228,140 (0.870 MB), Total: 0.95 MB, FLOPs: 23,830,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1495/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1495\n",
      "\n",
      "Iteration 1496 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.077 MB, Params: 226,239 (0.863 MB), Total: 0.94 MB, FLOPs: 23,808,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1496/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1496\n",
      "\n",
      "Iteration 1497 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.077 MB, Params: 225,558 (0.860 MB), Total: 0.94 MB, FLOPs: 23,799,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1497/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1497\n",
      "\n",
      "Iteration 1498 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.077 MB, Params: 223,666 (0.853 MB), Total: 0.93 MB, FLOPs: 23,777,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1498/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1498\n",
      "\n",
      "Iteration 1499 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 222,836 (0.850 MB), Total: 0.93 MB, FLOPs: 23,737,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1499/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1499\n",
      "\n",
      "Iteration 1500 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.077 MB, Params: 222,164 (0.847 MB), Total: 0.92 MB, FLOPs: 23,729,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1500/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1500\n",
      "\n",
      "Iteration 1501 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 6)]\n",
      "Input: 0.077 MB, Params: 221,730 (0.846 MB), Total: 0.92 MB, FLOPs: 23,383,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1501/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1501\n",
      "\n",
      "Iteration 1502 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.077 MB, Params: 220,900 (0.843 MB), Total: 0.92 MB, FLOPs: 23,343,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1502/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1502\n",
      "\n",
      "Iteration 1503 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.077 MB, Params: 220,228 (0.840 MB), Total: 0.92 MB, FLOPs: 23,335,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1503/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1503\n",
      "\n",
      "Iteration 1504 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.077 MB, Params: 219,556 (0.838 MB), Total: 0.91 MB, FLOPs: 23,327,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1504/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1504\n",
      "\n",
      "Iteration 1505 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 23)]\n",
      "Input: 0.077 MB, Params: 218,726 (0.834 MB), Total: 0.91 MB, FLOPs: 23,226,862\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1505/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1505\n",
      "\n",
      "Iteration 1506 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.077 MB, Params: 216,861 (0.827 MB), Total: 0.90 MB, FLOPs: 23,204,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1506/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1506\n",
      "\n",
      "Iteration 1507 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 216,198 (0.825 MB), Total: 0.90 MB, FLOPs: 23,196,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1507/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1507\n",
      "\n",
      "Iteration 1508 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 215,368 (0.822 MB), Total: 0.90 MB, FLOPs: 23,096,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1508/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1508\n",
      "\n",
      "Iteration 1509 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.077 MB, Params: 214,705 (0.819 MB), Total: 0.90 MB, FLOPs: 23,088,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1509/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1509\n",
      "\n",
      "Iteration 1510 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.077 MB, Params: 214,042 (0.817 MB), Total: 0.89 MB, FLOPs: 23,080,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1510/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1510\n",
      "\n",
      "Iteration 1511 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.077 MB, Params: 212,951 (0.812 MB), Total: 0.89 MB, FLOPs: 23,051,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1511/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1511\n",
      "\n",
      "Iteration 1512 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 4)]\n",
      "Input: 0.077 MB, Params: 212,121 (0.809 MB), Total: 0.89 MB, FLOPs: 22,951,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1512/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1512\n",
      "\n",
      "Iteration 1513 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 33)]\n",
      "Input: 0.077 MB, Params: 211,498 (0.807 MB), Total: 0.88 MB, FLOPs: 22,690,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1513/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1513\n",
      "\n",
      "Iteration 1514 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.077 MB, Params: 209,669 (0.800 MB), Total: 0.88 MB, FLOPs: 22,668,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1514/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1514\n",
      "\n",
      "Iteration 1515 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.077 MB, Params: 208,587 (0.796 MB), Total: 0.87 MB, FLOPs: 22,640,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1515/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1515\n",
      "\n",
      "Iteration 1516 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.077 MB, Params: 206,767 (0.789 MB), Total: 0.87 MB, FLOPs: 22,618,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1516/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1516\n",
      "\n",
      "Iteration 1517 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.077 MB, Params: 205,694 (0.785 MB), Total: 0.86 MB, FLOPs: 22,589,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1517/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1517\n",
      "\n",
      "Iteration 1518 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.077 MB, Params: 204,621 (0.781 MB), Total: 0.86 MB, FLOPs: 22,561,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1518/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1518\n",
      "\n",
      "Iteration 1519 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.077 MB, Params: 203,976 (0.778 MB), Total: 0.85 MB, FLOPs: 22,553,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1519/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1519\n",
      "\n",
      "Iteration 1520 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.077 MB, Params: 203,331 (0.776 MB), Total: 0.85 MB, FLOPs: 22,545,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1520/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1520\n",
      "\n",
      "Iteration 1521 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 45)]\n",
      "Input: 0.077 MB, Params: 202,564 (0.773 MB), Total: 0.85 MB, FLOPs: 22,509,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1521/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1521\n",
      "\n",
      "Iteration 1522 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.077 MB, Params: 201,797 (0.770 MB), Total: 0.85 MB, FLOPs: 22,472,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1522/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1522\n",
      "\n",
      "Iteration 1523 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.077 MB, Params: 200,985 (0.767 MB), Total: 0.84 MB, FLOPs: 22,372,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1523/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1523\n",
      "\n",
      "Iteration 1524 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.077 MB, Params: 199,201 (0.760 MB), Total: 0.84 MB, FLOPs: 22,351,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1524/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1524\n",
      "\n",
      "Iteration 1525 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 198,389 (0.757 MB), Total: 0.83 MB, FLOPs: 22,251,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1525/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1525\n",
      "\n",
      "Iteration 1526 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 31)]\n",
      "Input: 0.077 MB, Params: 197,766 (0.754 MB), Total: 0.83 MB, FLOPs: 21,991,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1526/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1526\n",
      "\n",
      "Iteration 1527 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.077 MB, Params: 197,130 (0.752 MB), Total: 0.83 MB, FLOPs: 21,983,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1527/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1527\n",
      "\n",
      "Iteration 1528 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.077 MB, Params: 196,084 (0.748 MB), Total: 0.82 MB, FLOPs: 21,955,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1528/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1528\n",
      "\n",
      "Iteration 1529 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.077 MB, Params: 195,448 (0.746 MB), Total: 0.82 MB, FLOPs: 21,948,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1529/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1529\n",
      "\n",
      "Iteration 1530 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.077 MB, Params: 194,402 (0.742 MB), Total: 0.82 MB, FLOPs: 21,920,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1530/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1530\n",
      "\n",
      "Iteration 1531 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.077 MB, Params: 193,356 (0.738 MB), Total: 0.81 MB, FLOPs: 21,893,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1531/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1531\n",
      "\n",
      "Iteration 1532 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.077 MB, Params: 192,310 (0.734 MB), Total: 0.81 MB, FLOPs: 21,865,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1532/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1532\n",
      "\n",
      "Iteration 1533 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.077 MB, Params: 191,264 (0.730 MB), Total: 0.81 MB, FLOPs: 21,838,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1533/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1533\n",
      "\n",
      "Iteration 1534 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.077 MB, Params: 189,543 (0.723 MB), Total: 0.80 MB, FLOPs: 21,817,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1534/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1534\n",
      "\n",
      "Iteration 1535 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.077 MB, Params: 188,506 (0.719 MB), Total: 0.80 MB, FLOPs: 21,790,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1535/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1535\n",
      "\n",
      "Iteration 1536 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 187,919 (0.717 MB), Total: 0.79 MB, FLOPs: 21,673,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1536/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1536\n",
      "\n",
      "Iteration 1537 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.077 MB, Params: 187,292 (0.714 MB), Total: 0.79 MB, FLOPs: 21,665,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1537/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1537\n",
      "\n",
      "Iteration 1538 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 185,589 (0.708 MB), Total: 0.78 MB, FLOPs: 21,645,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1538/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1538\n",
      "\n",
      "Iteration 1539 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.077 MB, Params: 183,886 (0.701 MB), Total: 0.78 MB, FLOPs: 21,624,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1539/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1539\n",
      "\n",
      "Iteration 1540 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.077 MB, Params: 183,277 (0.699 MB), Total: 0.78 MB, FLOPs: 21,617,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1540/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1540\n",
      "\n",
      "Iteration 1541 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.077 MB, Params: 182,668 (0.697 MB), Total: 0.77 MB, FLOPs: 21,610,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1541/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1541\n",
      "\n",
      "Iteration 1542 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.077 MB, Params: 182,081 (0.695 MB), Total: 0.77 MB, FLOPs: 21,492,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1542/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1542\n",
      "\n",
      "Iteration 1543 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 181,494 (0.692 MB), Total: 0.77 MB, FLOPs: 21,375,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1543/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1543\n",
      "\n",
      "Iteration 1544 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.077 MB, Params: 180,885 (0.690 MB), Total: 0.77 MB, FLOPs: 21,368,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1544/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1544\n",
      "\n",
      "Iteration 1545 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 179,866 (0.686 MB), Total: 0.76 MB, FLOPs: 21,341,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1545/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1545\n",
      "\n",
      "Iteration 1546 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.077 MB, Params: 179,257 (0.684 MB), Total: 0.76 MB, FLOPs: 21,334,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1546/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1546\n",
      "\n",
      "Iteration 1547 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.077 MB, Params: 178,648 (0.681 MB), Total: 0.76 MB, FLOPs: 21,326,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1547/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1547\n",
      "\n",
      "Iteration 1548 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 15)]\n",
      "Input: 0.077 MB, Params: 178,052 (0.679 MB), Total: 0.76 MB, FLOPs: 21,071,330\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1548/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1548\n",
      "\n",
      "Iteration 1549 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 176,403 (0.673 MB), Total: 0.75 MB, FLOPs: 21,051,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1549/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1549\n",
      "\n",
      "Iteration 1550 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.077 MB, Params: 175,803 (0.671 MB), Total: 0.75 MB, FLOPs: 21,044,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1550/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1550\n",
      "\n",
      "Iteration 1551 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.077 MB, Params: 175,396 (0.669 MB), Total: 0.75 MB, FLOPs: 20,719,590\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1551/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1551\n",
      "\n",
      "Iteration 1552 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.077 MB, Params: 174,611 (0.666 MB), Total: 0.74 MB, FLOPs: 20,625,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1552/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1552\n",
      "\n",
      "Iteration 1553 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.077 MB, Params: 174,011 (0.664 MB), Total: 0.74 MB, FLOPs: 20,618,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1553/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1553\n",
      "\n",
      "Iteration 1554 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 173,334 (0.661 MB), Total: 0.74 MB, FLOPs: 20,585,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1554/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1554\n",
      "\n",
      "Iteration 1555 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 172,765 (0.659 MB), Total: 0.74 MB, FLOPs: 20,472,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1555/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1555\n",
      "\n",
      "Iteration 1556 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.077 MB, Params: 172,358 (0.657 MB), Total: 0.73 MB, FLOPs: 20,147,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1556/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1556\n",
      "\n",
      "Iteration 1557 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.077 MB, Params: 171,789 (0.655 MB), Total: 0.73 MB, FLOPs: 20,033,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1557/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1557\n",
      "\n",
      "Iteration 1558 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.077 MB, Params: 171,189 (0.653 MB), Total: 0.73 MB, FLOPs: 20,026,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1558/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1558\n",
      "\n",
      "Iteration 1559 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.077 MB, Params: 170,620 (0.651 MB), Total: 0.73 MB, FLOPs: 19,913,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1559/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1559\n",
      "\n",
      "Iteration 1560 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.077 MB, Params: 170,020 (0.649 MB), Total: 0.73 MB, FLOPs: 19,905,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1560/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1560\n",
      "\n",
      "Iteration 1561 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.077 MB, Params: 169,420 (0.646 MB), Total: 0.72 MB, FLOPs: 19,898,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1561/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1561\n",
      "\n",
      "Iteration 1562 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.077 MB, Params: 168,419 (0.642 MB), Total: 0.72 MB, FLOPs: 19,872,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1562/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1562\n",
      "\n",
      "Iteration 1563 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.077 MB, Params: 167,418 (0.639 MB), Total: 0.72 MB, FLOPs: 19,845,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1563/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1563\n",
      "\n",
      "Iteration 1564 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 22)]\n",
      "Input: 0.077 MB, Params: 166,669 (0.636 MB), Total: 0.71 MB, FLOPs: 19,757,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1564/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1564\n",
      "\n",
      "Iteration 1565 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.077 MB, Params: 166,069 (0.634 MB), Total: 0.71 MB, FLOPs: 19,750,098\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1565/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1565\n",
      "\n",
      "Iteration 1566 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 21)]\n",
      "Input: 0.077 MB, Params: 165,320 (0.631 MB), Total: 0.71 MB, FLOPs: 19,661,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1566/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1566\n",
      "\n",
      "Iteration 1567 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.077 MB, Params: 163,743 (0.625 MB), Total: 0.70 MB, FLOPs: 19,642,954\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1567/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1567\n",
      "\n",
      "Iteration 1568 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.077 MB, Params: 162,166 (0.619 MB), Total: 0.70 MB, FLOPs: 19,624,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1568/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1568\n",
      "\n",
      "Iteration 1569 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 161,417 (0.616 MB), Total: 0.69 MB, FLOPs: 19,535,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1569/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1569\n",
      "\n",
      "Iteration 1570 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.077 MB, Params: 159,840 (0.610 MB), Total: 0.69 MB, FLOPs: 19,516,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1570/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1570\n",
      "\n",
      "Iteration 1571 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 19)]\n",
      "Input: 0.077 MB, Params: 159,091 (0.607 MB), Total: 0.68 MB, FLOPs: 19,428,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Finished fine tuning.\n",
      "Iteration 1571/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1571\n",
      "\n",
      "Iteration 1572 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 11)]\n",
      "Input: 0.077 MB, Params: 158,540 (0.605 MB), Total: 0.68 MB, FLOPs: 19,193,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Finished fine tuning.\n",
      "Iteration 1572/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1572\n",
      "\n",
      "Iteration 1573 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.077 MB, Params: 157,917 (0.602 MB), Total: 0.68 MB, FLOPs: 19,163,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 67.213%\n",
      "Finished fine tuning.\n",
      "Iteration 1573/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1573\n",
      "\n",
      "Iteration 1574 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.077 MB, Params: 157,699 (0.602 MB), Total: 0.68 MB, FLOPs: 18,962,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.667%\n",
      "Finished fine tuning.\n",
      "Iteration 1574/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1574\n",
      "\n",
      "Iteration 1575 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.077 MB, Params: 157,126 (0.599 MB), Total: 0.68 MB, FLOPs: 18,955,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.120%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1575/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1575\n",
      "\n",
      "Iteration 1576 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 156,503 (0.597 MB), Total: 0.67 MB, FLOPs: 18,925,714\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Finished fine tuning.\n",
      "Iteration 1576/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1576\n",
      "\n",
      "Iteration 1577 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.077 MB, Params: 155,930 (0.595 MB), Total: 0.67 MB, FLOPs: 18,918,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1577/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1577\n",
      "\n",
      "Iteration 1578 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.077 MB, Params: 155,406 (0.593 MB), Total: 0.67 MB, FLOPs: 18,814,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1578/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1578\n",
      "\n",
      "Iteration 1579 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 6)]\n",
      "Input: 0.077 MB, Params: 154,864 (0.591 MB), Total: 0.67 MB, FLOPs: 18,580,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1579/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1579\n",
      "\n",
      "Iteration 1580 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.077 MB, Params: 154,484 (0.589 MB), Total: 0.67 MB, FLOPs: 18,277,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1580/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1580\n",
      "\n",
      "Iteration 1581 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 27)]\n",
      "Input: 0.077 MB, Params: 153,951 (0.587 MB), Total: 0.66 MB, FLOPs: 18,050,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1581/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1581\n",
      "\n",
      "Iteration 1582 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.077 MB, Params: 152,392 (0.581 MB), Total: 0.66 MB, FLOPs: 18,031,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1582/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1582\n",
      "\n",
      "Iteration 1583 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 151,445 (0.578 MB), Total: 0.65 MB, FLOPs: 18,006,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1583/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1583\n",
      "\n",
      "Iteration 1584 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 10)]\n",
      "Input: 0.077 MB, Params: 150,939 (0.576 MB), Total: 0.65 MB, FLOPs: 17,905,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1584/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1584\n",
      "\n",
      "Iteration 1585 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.077 MB, Params: 150,226 (0.573 MB), Total: 0.65 MB, FLOPs: 17,821,842\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1585/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1585\n",
      "\n",
      "Iteration 1586 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.077 MB, Params: 149,662 (0.571 MB), Total: 0.65 MB, FLOPs: 17,815,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1586/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1586\n",
      "\n",
      "Iteration 1587 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.077 MB, Params: 149,098 (0.569 MB), Total: 0.65 MB, FLOPs: 17,808,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1587/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1587\n",
      "\n",
      "Iteration 1588 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.077 MB, Params: 148,534 (0.567 MB), Total: 0.64 MB, FLOPs: 17,801,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1588/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1588\n",
      "\n",
      "Iteration 1589 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.077 MB, Params: 147,970 (0.564 MB), Total: 0.64 MB, FLOPs: 17,794,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Finished fine tuning.\n",
      "Iteration 1589/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1589\n",
      "\n",
      "Iteration 1590 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 147,365 (0.562 MB), Total: 0.64 MB, FLOPs: 17,765,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1590/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1590\n",
      "\n",
      "Iteration 1591 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.077 MB, Params: 146,801 (0.560 MB), Total: 0.64 MB, FLOPs: 17,759,190\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1591/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1591\n",
      "\n",
      "Iteration 1592 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.077 MB, Params: 146,237 (0.558 MB), Total: 0.63 MB, FLOPs: 17,752,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1592/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1592\n",
      "\n",
      "Iteration 1593 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.077 MB, Params: 145,713 (0.556 MB), Total: 0.63 MB, FLOPs: 17,527,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1593/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1593\n",
      "\n",
      "Iteration 1594 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 3)]\n",
      "Input: 0.077 MB, Params: 145,189 (0.554 MB), Total: 0.63 MB, FLOPs: 17,302,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.934%\n",
      "Finished fine tuning.\n",
      "Iteration 1594/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1594\n",
      "\n",
      "Iteration 1595 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 144,584 (0.552 MB), Total: 0.63 MB, FLOPs: 17,273,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.388%\n",
      "Finished fine tuning.\n",
      "Iteration 1595/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1595\n",
      "\n",
      "Iteration 1596 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.077 MB, Params: 143,979 (0.549 MB), Total: 0.63 MB, FLOPs: 17,244,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1596/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1596\n",
      "\n",
      "Iteration 1597 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.077 MB, Params: 143,374 (0.547 MB), Total: 0.62 MB, FLOPs: 17,215,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.574%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Finished fine tuning.\n",
      "Iteration 1597/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1597\n",
      "\n",
      "Iteration 1598 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.077 MB, Params: 142,810 (0.545 MB), Total: 0.62 MB, FLOPs: 17,209,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.027%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 64.481%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1598/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1598\n",
      "\n",
      "Iteration 1599 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.077 MB, Params: 142,246 (0.543 MB), Total: 0.62 MB, FLOPs: 17,202,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1599/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1599\n",
      "\n",
      "Iteration 1600 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.077 MB, Params: 141,893 (0.541 MB), Total: 0.62 MB, FLOPs: 16,920,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1600/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1600\n",
      "\n",
      "Iteration 1601 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.077 MB, Params: 140,415 (0.536 MB), Total: 0.61 MB, FLOPs: 16,903,094\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1601/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1601\n",
      "\n",
      "Iteration 1602 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 10)]\n",
      "Input: 0.077 MB, Params: 139,900 (0.534 MB), Total: 0.61 MB, FLOPs: 16,685,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1602/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1602\n",
      "\n",
      "Iteration 1603 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.077 MB, Params: 139,345 (0.532 MB), Total: 0.61 MB, FLOPs: 16,678,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1603/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1603\n",
      "\n",
      "Iteration 1604 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.077 MB, Params: 138,790 (0.529 MB), Total: 0.61 MB, FLOPs: 16,672,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Finished fine tuning.\n",
      "Iteration 1604/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1604\n",
      "\n",
      "Iteration 1605 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 34)]\n",
      "Input: 0.077 MB, Params: 138,320 (0.528 MB), Total: 0.60 MB, FLOPs: 16,578,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1605/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1605\n",
      "\n",
      "Iteration 1606 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.077 MB, Params: 137,765 (0.526 MB), Total: 0.60 MB, FLOPs: 16,571,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1606/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1606\n",
      "\n",
      "Iteration 1607 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.077 MB, Params: 137,210 (0.523 MB), Total: 0.60 MB, FLOPs: 16,565,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.295%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 62.842%\n",
      "Finished fine tuning.\n",
      "Iteration 1607/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1607\n",
      "\n",
      "Iteration 1608 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.077 MB, Params: 136,655 (0.521 MB), Total: 0.60 MB, FLOPs: 16,558,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.202%\n",
      "Finished fine tuning.\n",
      "Iteration 1608/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1608\n",
      "\n",
      "Iteration 1609 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.077 MB, Params: 136,100 (0.519 MB), Total: 0.60 MB, FLOPs: 16,551,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Finished fine tuning.\n",
      "Iteration 1609/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1609\n",
      "\n",
      "Iteration 1610 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 4)]\n",
      "Input: 0.077 MB, Params: 135,900 (0.518 MB), Total: 0.60 MB, FLOPs: 16,365,550\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 31.148%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 42.623%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 1610/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1610\n",
      "\n",
      "Iteration 1611 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.077 MB, Params: 134,476 (0.513 MB), Total: 0.59 MB, FLOPs: 16,348,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1611/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1611\n",
      "\n",
      "Iteration 1612 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.077 MB, Params: 133,583 (0.510 MB), Total: 0.59 MB, FLOPs: 16,325,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1612/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1612\n",
      "\n",
      "Iteration 1613 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.077 MB, Params: 132,168 (0.504 MB), Total: 0.58 MB, FLOPs: 16,308,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1613/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1613\n",
      "\n",
      "Iteration 1614 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.077 MB, Params: 131,284 (0.501 MB), Total: 0.58 MB, FLOPs: 16,284,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1614/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1614\n",
      "\n",
      "Iteration 1615 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 130,697 (0.499 MB), Total: 0.58 MB, FLOPs: 16,256,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1615/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1615\n",
      "\n",
      "Iteration 1616 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 19)]\n",
      "Input: 0.077 MB, Params: 130,038 (0.496 MB), Total: 0.57 MB, FLOPs: 16,176,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1616/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1616\n",
      "\n",
      "Iteration 1617 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.077 MB, Params: 128,632 (0.491 MB), Total: 0.57 MB, FLOPs: 16,159,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1617/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1617\n",
      "\n",
      "Iteration 1618 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.077 MB, Params: 128,104 (0.489 MB), Total: 0.57 MB, FLOPs: 16,153,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1618/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1618\n",
      "\n",
      "Iteration 1619 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.077 MB, Params: 127,576 (0.487 MB), Total: 0.56 MB, FLOPs: 16,147,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1619/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1619\n",
      "\n",
      "Iteration 1620 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.077 MB, Params: 126,188 (0.481 MB), Total: 0.56 MB, FLOPs: 16,130,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1620/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1620\n",
      "\n",
      "Iteration 1621 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.077 MB, Params: 124,800 (0.476 MB), Total: 0.55 MB, FLOPs: 16,114,082\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1621/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1621\n",
      "\n",
      "Iteration 1622 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.077 MB, Params: 123,412 (0.471 MB), Total: 0.55 MB, FLOPs: 16,097,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1622/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1622\n",
      "\n",
      "Iteration 1623 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.077 MB, Params: 122,911 (0.469 MB), Total: 0.55 MB, FLOPs: 16,091,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1623/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1623\n",
      "\n",
      "Iteration 1624 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.077 MB, Params: 122,410 (0.467 MB), Total: 0.54 MB, FLOPs: 16,085,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1624/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1624\n",
      "\n",
      "Iteration 1625 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.077 MB, Params: 121,040 (0.462 MB), Total: 0.54 MB, FLOPs: 16,069,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1625/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1625\n",
      "\n",
      "Iteration 1626 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.077 MB, Params: 119,670 (0.457 MB), Total: 0.53 MB, FLOPs: 16,052,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1626/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1626\n",
      "\n",
      "Iteration 1627 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.077 MB, Params: 119,209 (0.455 MB), Total: 0.53 MB, FLOPs: 15,960,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 61.749%\n",
      "Finished fine tuning.\n",
      "Iteration 1627/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1627\n",
      "\n",
      "Iteration 1628 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.077 MB, Params: 118,748 (0.453 MB), Total: 0.53 MB, FLOPs: 15,868,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1628/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1628\n",
      "\n",
      "Iteration 1629 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.077 MB, Params: 117,378 (0.448 MB), Total: 0.52 MB, FLOPs: 15,852,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Finished fine tuning.\n",
      "Iteration 1629/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1629\n",
      "\n",
      "Iteration 1630 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.077 MB, Params: 116,008 (0.443 MB), Total: 0.52 MB, FLOPs: 15,835,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1630/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1630\n",
      "\n",
      "Iteration 1631 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.077 MB, Params: 115,808 (0.442 MB), Total: 0.52 MB, FLOPs: 15,649,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1631/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1631\n",
      "\n",
      "Iteration 1632 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.077 MB, Params: 115,343 (0.440 MB), Total: 0.52 MB, FLOPs: 15,643,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1632/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1632\n",
      "\n",
      "Iteration 1633 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.077 MB, Params: 114,878 (0.438 MB), Total: 0.52 MB, FLOPs: 15,638,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1633/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1633\n",
      "\n",
      "Iteration 1634 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.077 MB, Params: 114,413 (0.436 MB), Total: 0.51 MB, FLOPs: 15,632,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1634/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1634\n",
      "\n",
      "Iteration 1635 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.077 MB, Params: 113,948 (0.435 MB), Total: 0.51 MB, FLOPs: 15,627,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1635/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1635\n",
      "\n",
      "Iteration 1636 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 5)]\n",
      "Input: 0.077 MB, Params: 113,748 (0.434 MB), Total: 0.51 MB, FLOPs: 15,440,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.109%\n",
      "Finished fine tuning.\n",
      "Iteration 1636/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1636\n",
      "\n",
      "Iteration 1637 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.077 MB, Params: 113,283 (0.432 MB), Total: 0.51 MB, FLOPs: 15,435,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1637/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1637\n",
      "\n",
      "Iteration 1638 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.077 MB, Params: 112,818 (0.430 MB), Total: 0.51 MB, FLOPs: 15,429,710\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1638/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1638\n",
      "\n",
      "Iteration 1639 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 22)]\n",
      "Input: 0.077 MB, Params: 112,330 (0.429 MB), Total: 0.51 MB, FLOPs: 15,217,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1639/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1639\n",
      "\n",
      "Iteration 1640 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.077 MB, Params: 111,014 (0.423 MB), Total: 0.50 MB, FLOPs: 15,201,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1640/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1640\n",
      "\n",
      "Iteration 1641 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.077 MB, Params: 110,436 (0.421 MB), Total: 0.50 MB, FLOPs: 15,174,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1641/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1641\n",
      "\n",
      "Iteration 1642 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.077 MB, Params: 109,858 (0.419 MB), Total: 0.50 MB, FLOPs: 15,146,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.016%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 60.656%\n",
      "Finished fine tuning.\n",
      "Iteration 1642/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1642\n",
      "\n",
      "Iteration 1643 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.077 MB, Params: 109,235 (0.417 MB), Total: 0.49 MB, FLOPs: 15,070,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1643/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1643\n",
      "\n",
      "Iteration 1644 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.077 MB, Params: 108,779 (0.415 MB), Total: 0.49 MB, FLOPs: 15,065,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1644/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1644\n",
      "\n",
      "Iteration 1645 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.077 MB, Params: 108,323 (0.413 MB), Total: 0.49 MB, FLOPs: 15,060,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 59.563%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1645/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1645\n",
      "\n",
      "Iteration 1646 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.077 MB, Params: 107,867 (0.411 MB), Total: 0.49 MB, FLOPs: 15,054,686\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1646/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1646\n",
      "\n",
      "Iteration 1647 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 33)]\n",
      "Input: 0.077 MB, Params: 106,578 (0.407 MB), Total: 0.48 MB, FLOPs: 15,039,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1647/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1647\n",
      "\n",
      "Iteration 1648 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.077 MB, Params: 105,811 (0.404 MB), Total: 0.48 MB, FLOPs: 15,018,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 58.470%\n",
      "Finished fine tuning.\n",
      "Iteration 1648/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1648\n",
      "\n",
      "Iteration 1649 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.077 MB, Params: 105,188 (0.401 MB), Total: 0.48 MB, FLOPs: 14,942,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1649/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1649\n",
      "\n",
      "Iteration 1650 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.077 MB, Params: 104,880 (0.400 MB), Total: 0.48 MB, FLOPs: 14,697,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1650/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1650\n",
      "\n",
      "Iteration 1651 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.077 MB, Params: 104,572 (0.399 MB), Total: 0.48 MB, FLOPs: 14,451,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1651/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1651\n",
      "\n",
      "Iteration 1652 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.077 MB, Params: 103,949 (0.397 MB), Total: 0.47 MB, FLOPs: 14,376,402\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1652/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1652\n",
      "\n",
      "Iteration 1653 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.077 MB, Params: 103,502 (0.395 MB), Total: 0.47 MB, FLOPs: 14,371,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1653/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1653\n",
      "\n",
      "Iteration 1654 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.077 MB, Params: 103,077 (0.393 MB), Total: 0.47 MB, FLOPs: 14,286,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1654/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1654\n",
      "\n",
      "Iteration 1655 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.077 MB, Params: 102,652 (0.392 MB), Total: 0.47 MB, FLOPs: 14,201,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1655/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1655\n",
      "\n",
      "Iteration 1656 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.077 MB, Params: 101,381 (0.387 MB), Total: 0.46 MB, FLOPs: 14,186,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1656/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1656\n",
      "\n",
      "Iteration 1657 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.077 MB, Params: 100,839 (0.385 MB), Total: 0.46 MB, FLOPs: 14,160,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1657/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1657\n",
      "\n",
      "Iteration 1658 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.077 MB, Params: 100,401 (0.383 MB), Total: 0.46 MB, FLOPs: 14,155,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1658/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1658\n",
      "\n",
      "Iteration 1659 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.077 MB, Params: 99,652 (0.380 MB), Total: 0.46 MB, FLOPs: 14,134,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1659/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1659\n",
      "\n",
      "Iteration 1660 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 0)]\n",
      "Input: 0.077 MB, Params: 99,056 (0.378 MB), Total: 0.45 MB, FLOPs: 14,063,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1660/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1660\n",
      "\n",
      "Iteration 1661 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 1)]\n",
      "Input: 0.077 MB, Params: 98,604 (0.376 MB), Total: 0.45 MB, FLOPs: 13,869,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1661/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1661\n",
      "\n",
      "Iteration 1662 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.077 MB, Params: 98,197 (0.375 MB), Total: 0.45 MB, FLOPs: 13,787,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1662/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1662\n",
      "\n",
      "Iteration 1663 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.077 MB, Params: 97,610 (0.372 MB), Total: 0.45 MB, FLOPs: 13,718,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1663/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1663\n",
      "\n",
      "Iteration 1664 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.077 MB, Params: 96,357 (0.368 MB), Total: 0.44 MB, FLOPs: 13,703,398\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1664/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1664\n",
      "\n",
      "Iteration 1665 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.077 MB, Params: 96,058 (0.366 MB), Total: 0.44 MB, FLOPs: 13,464,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1665/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1665\n",
      "\n",
      "Iteration 1666 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.077 MB, Params: 95,629 (0.365 MB), Total: 0.44 MB, FLOPs: 13,459,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1666/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1666\n",
      "\n",
      "Iteration 1667 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.077 MB, Params: 94,385 (0.360 MB), Total: 0.44 MB, FLOPs: 13,444,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1667/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1667\n",
      "\n",
      "Iteration 1668 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.077 MB, Params: 93,870 (0.358 MB), Total: 0.43 MB, FLOPs: 13,420,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Finished fine tuning.\n",
      "Iteration 1668/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1668\n",
      "\n",
      "Iteration 1669 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 92,626 (0.353 MB), Total: 0.43 MB, FLOPs: 13,405,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Finished fine tuning.\n",
      "Iteration 1669/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1669\n",
      "\n",
      "Iteration 1670 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.077 MB, Params: 92,111 (0.351 MB), Total: 0.43 MB, FLOPs: 13,380,710\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.923%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 57.377%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1670/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1670\n",
      "\n",
      "Iteration 1671 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.077 MB, Params: 91,596 (0.349 MB), Total: 0.43 MB, FLOPs: 13,356,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1671/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1671\n",
      "\n",
      "Iteration 1672 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 1)]\n",
      "Input: 0.077 MB, Params: 91,425 (0.349 MB), Total: 0.43 MB, FLOPs: 12,449,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1672/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1672\n",
      "\n",
      "Iteration 1673 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.077 MB, Params: 90,730 (0.346 MB), Total: 0.42 MB, FLOPs: 12,431,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1673/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1673\n",
      "\n",
      "Iteration 1674 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.077 MB, Params: 90,319 (0.345 MB), Total: 0.42 MB, FLOPs: 12,426,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1674/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1674\n",
      "\n",
      "Iteration 1675 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.077 MB, Params: 89,624 (0.342 MB), Total: 0.42 MB, FLOPs: 12,407,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Finished fine tuning.\n",
      "Iteration 1675/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1675\n",
      "\n",
      "Iteration 1676 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.077 MB, Params: 89,213 (0.340 MB), Total: 0.42 MB, FLOPs: 12,402,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Finished fine tuning.\n",
      "Iteration 1676/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1676\n",
      "\n",
      "Iteration 1677 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.077 MB, Params: 88,005 (0.336 MB), Total: 0.41 MB, FLOPs: 12,388,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.645%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1677/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1677\n",
      "\n",
      "Iteration 1678 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.077 MB, Params: 87,706 (0.335 MB), Total: 0.41 MB, FLOPs: 12,149,652\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1678/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1678\n",
      "\n",
      "Iteration 1679 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.077 MB, Params: 87,209 (0.333 MB), Total: 0.41 MB, FLOPs: 12,125,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1679/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1679\n",
      "\n",
      "Iteration 1680 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.077 MB, Params: 86,658 (0.331 MB), Total: 0.41 MB, FLOPs: 12,058,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1680/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1680\n",
      "\n",
      "Iteration 1681 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.077 MB, Params: 85,450 (0.326 MB), Total: 0.40 MB, FLOPs: 12,043,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1681/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1681\n",
      "\n",
      "Iteration 1682 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.077 MB, Params: 85,025 (0.324 MB), Total: 0.40 MB, FLOPs: 11,865,576\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Finished fine tuning.\n",
      "Iteration 1682/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1682\n",
      "\n",
      "Iteration 1683 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.077 MB, Params: 84,357 (0.322 MB), Total: 0.40 MB, FLOPs: 11,847,444\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1683/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1683\n",
      "\n",
      "Iteration 1684 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.077 MB, Params: 83,977 (0.320 MB), Total: 0.40 MB, FLOPs: 11,771,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1684/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1684\n",
      "\n",
      "Iteration 1685 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.077 MB, Params: 82,778 (0.316 MB), Total: 0.39 MB, FLOPs: 11,757,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.738%\n",
      "Finished fine tuning.\n",
      "Iteration 1685/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1685\n",
      "\n",
      "Iteration 1686 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 25)]\n",
      "Input: 0.077 MB, Params: 82,299 (0.314 MB), Total: 0.39 MB, FLOPs: 11,734,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1686/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1686\n",
      "\n",
      "Iteration 1687 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.077 MB, Params: 81,649 (0.311 MB), Total: 0.39 MB, FLOPs: 11,716,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1687/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1687\n",
      "\n",
      "Iteration 1688 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.077 MB, Params: 80,459 (0.307 MB), Total: 0.38 MB, FLOPs: 11,702,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 56.284%\n",
      "Finished fine tuning.\n",
      "Iteration 1688/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1688\n",
      "\n",
      "Iteration 1689 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.077 MB, Params: 80,084 (0.305 MB), Total: 0.38 MB, FLOPs: 11,698,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 55.191%\n",
      "Finished fine tuning.\n",
      "Iteration 1689/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1689\n",
      "\n",
      "Iteration 1690 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.077 MB, Params: 79,551 (0.303 MB), Total: 0.38 MB, FLOPs: 11,632,448\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1690/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1690\n",
      "\n",
      "Iteration 1691 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.077 MB, Params: 79,090 (0.302 MB), Total: 0.38 MB, FLOPs: 11,610,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 54.098%\n",
      "Finished fine tuning.\n",
      "Iteration 1691/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1691\n",
      "\n",
      "Iteration 1692 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 3)]\n",
      "Input: 0.077 MB, Params: 78,674 (0.300 MB), Total: 0.38 MB, FLOPs: 11,434,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1692/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1692\n",
      "\n",
      "Iteration 1693 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 88)]\n",
      "Input: 0.077 MB, Params: 78,299 (0.299 MB), Total: 0.38 MB, FLOPs: 11,429,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1693/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1693\n",
      "\n",
      "Iteration 1694 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 95)]\n",
      "Input: 0.077 MB, Params: 77,924 (0.297 MB), Total: 0.37 MB, FLOPs: 11,425,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.459%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1694/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1694\n",
      "\n",
      "Iteration 1695 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.077 MB, Params: 77,760 (0.297 MB), Total: 0.37 MB, FLOPs: 11,267,640\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.448%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 1695/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1695\n",
      "\n",
      "Iteration 1696 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.077 MB, Params: 76,597 (0.292 MB), Total: 0.37 MB, FLOPs: 11,253,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Finished fine tuning.\n",
      "Iteration 1696/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1696\n",
      "\n",
      "Iteration 1697 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.077 MB, Params: 75,974 (0.290 MB), Total: 0.37 MB, FLOPs: 11,236,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 1697/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1697\n",
      "\n",
      "Iteration 1698 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 17)]\n",
      "Input: 0.077 MB, Params: 74,820 (0.285 MB), Total: 0.36 MB, FLOPs: 11,222,916\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Finished fine tuning.\n",
      "Iteration 1698/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1698\n",
      "\n",
      "Iteration 1699 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.077 MB, Params: 74,206 (0.283 MB), Total: 0.36 MB, FLOPs: 11,206,080\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.366%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.005%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 1699/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1699\n",
      "\n",
      "Iteration 1700 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.077 MB, Params: 73,592 (0.281 MB), Total: 0.36 MB, FLOPs: 11,189,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1700/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1700\n",
      "\n",
      "Iteration 1701 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.077 MB, Params: 73,235 (0.279 MB), Total: 0.36 MB, FLOPs: 11,184,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1701/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1701\n",
      "\n",
      "Iteration 1702 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.077 MB, Params: 72,108 (0.275 MB), Total: 0.35 MB, FLOPs: 11,171,484\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Finished fine tuning.\n",
      "Iteration 1702/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1702\n",
      "\n",
      "Iteration 1703 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.077 MB, Params: 71,503 (0.273 MB), Total: 0.35 MB, FLOPs: 11,154,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 53.552%\n",
      "Finished fine tuning.\n",
      "Iteration 1703/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1703\n",
      "\n",
      "Iteration 1704 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.077 MB, Params: 71,155 (0.271 MB), Total: 0.35 MB, FLOPs: 11,150,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 1704/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1704\n",
      "\n",
      "Iteration 1705 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.077 MB, Params: 70,793 (0.270 MB), Total: 0.35 MB, FLOPs: 11,078,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1705/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1705\n",
      "\n",
      "Iteration 1706 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.077 MB, Params: 69,684 (0.266 MB), Total: 0.34 MB, FLOPs: 11,065,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1706/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1706\n",
      "\n",
      "Iteration 1707 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.077 MB, Params: 69,345 (0.265 MB), Total: 0.34 MB, FLOPs: 11,061,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1707/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1707\n",
      "\n",
      "Iteration 1708 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.077 MB, Params: 68,920 (0.263 MB), Total: 0.34 MB, FLOPs: 11,040,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 1708/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1708\n",
      "\n",
      "Iteration 1709 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.077 MB, Params: 68,333 (0.261 MB), Total: 0.34 MB, FLOPs: 11,024,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Finished fine tuning.\n",
      "Iteration 1709/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1709\n",
      "\n",
      "Iteration 1710 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.077 MB, Params: 67,971 (0.259 MB), Total: 0.34 MB, FLOPs: 10,952,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Finished fine tuning.\n",
      "Iteration 1710/1724 finished in 0m09s\n",
      "Total channels prunned so far: 1710\n",
      "\n",
      "Iteration 1711 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.077 MB, Params: 66,880 (0.255 MB), Total: 0.33 MB, FLOPs: 10,939,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 1711/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1711\n",
      "\n",
      "Iteration 1712 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.077 MB, Params: 65,789 (0.251 MB), Total: 0.33 MB, FLOPs: 10,926,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1712/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1712\n",
      "\n",
      "Iteration 1713 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.077 MB, Params: 65,220 (0.249 MB), Total: 0.33 MB, FLOPs: 10,910,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Finished fine tuning.\n",
      "Iteration 1713/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1713\n",
      "\n",
      "Iteration 1714 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.077 MB, Params: 64,899 (0.248 MB), Total: 0.32 MB, FLOPs: 10,906,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.820%\n",
      "Finished fine tuning.\n",
      "Iteration 1714/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1714\n",
      "\n",
      "Iteration 1715 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.077 MB, Params: 64,578 (0.246 MB), Total: 0.32 MB, FLOPs: 10,902,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.902%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1715/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1715\n",
      "\n",
      "Iteration 1716 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.077 MB, Params: 64,257 (0.245 MB), Total: 0.32 MB, FLOPs: 10,898,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 51.913%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Finished fine tuning.\n",
      "Iteration 1716/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1716\n",
      "\n",
      "Iteration 1717 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.077 MB, Params: 63,760 (0.243 MB), Total: 0.32 MB, FLOPs: 10,837,680\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Finished fine tuning.\n",
      "Iteration 1717/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1717\n",
      "\n",
      "Iteration 1718 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 72)]\n",
      "Input: 0.077 MB, Params: 63,439 (0.242 MB), Total: 0.32 MB, FLOPs: 10,833,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 47.541%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.180%\n",
      "Finished fine tuning.\n",
      "Iteration 1718/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1718\n",
      "\n",
      "Iteration 1719 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.077 MB, Params: 63,086 (0.241 MB), Total: 0.32 MB, FLOPs: 10,763,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 49.727%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 46.995%\n",
      "Finished fine tuning.\n",
      "Iteration 1719/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1719\n",
      "\n",
      "Iteration 1720 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.077 MB, Params: 62,688 (0.239 MB), Total: 0.32 MB, FLOPs: 10,744,408\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 43.716%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.809%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 45.355%\n",
      "Finished fine tuning.\n",
      "Iteration 1720/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1720\n",
      "\n",
      "Iteration 1721 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.077 MB, Params: 62,367 (0.238 MB), Total: 0.31 MB, FLOPs: 10,740,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.087%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 48.634%\n",
      "Finished fine tuning.\n",
      "Iteration 1721/1724 finished in 0m10s\n",
      "Total channels prunned so far: 1721\n",
      "\n",
      "Iteration 1722 of 1722 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.077 MB, Params: 62,203 (0.237 MB), Total: 0.31 MB, FLOPs: 10,582,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 38.251%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 44.262%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 50.273%\n",
      "Finished fine tuning.\n",
      "Iteration 1722/1724 finished in 0m11s\n",
      "Total channels prunned so far: 1722\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 20150)     (4, 1, 10071)         36      362,556\n",
      "  BatchNorm2d-2     (4, 1, 10071)     (4, 1, 10071)          8            0\n",
      "         ReLu-3     (4, 1, 10071)     (4, 1, 10071)          0       40,284\n",
      "       Conv2d-4     (4, 1, 10071)     (32, 1, 5034)        640    3,221,760\n",
      "  BatchNorm2d-5     (32, 1, 5034)     (32, 1, 5034)         64            0\n",
      "         ReLu-6     (32, 1, 5034)     (32, 1, 5034)          0      161,088\n",
      "    MaxPool2d-7     (32, 1, 5034)      (32, 1, 100)          0      160,000\n",
      "      Permute-8      (32, 1, 100)      (1, 32, 100)          0            0\n",
      "       Conv2d-9      (1, 32, 100)      (7, 32, 100)         63      201,600\n",
      " BatchNorm2d-10      (7, 32, 100)      (7, 32, 100)         14            0\n",
      "        ReLu-11      (7, 32, 100)      (7, 32, 100)          0       22,400\n",
      "   MaxPool2d-12      (7, 32, 100)       (7, 16, 50)          0       22,400\n",
      "      Conv2d-13       (7, 16, 50)      (17, 16, 50)      1,071      856,800\n",
      " BatchNorm2d-14      (17, 16, 50)      (17, 16, 50)         34            0\n",
      "        ReLu-15      (17, 16, 50)      (17, 16, 50)          0       13,600\n",
      "      Conv2d-16      (17, 16, 50)      (22, 16, 50)      3,366    2,692,800\n",
      " BatchNorm2d-17      (22, 16, 50)      (22, 16, 50)         44            0\n",
      "        ReLu-18      (22, 16, 50)      (22, 16, 50)          0       17,600\n",
      "   MaxPool2d-19      (22, 16, 50)       (22, 8, 25)          0       17,600\n",
      "      Conv2d-20       (22, 8, 25)       (26, 8, 25)      5,148    1,029,600\n",
      " BatchNorm2d-21       (26, 8, 25)       (26, 8, 25)         52            0\n",
      "        ReLu-22       (26, 8, 25)       (26, 8, 25)          0        5,200\n",
      "      Conv2d-23       (26, 8, 25)       (17, 8, 25)      3,978      795,600\n",
      " BatchNorm2d-24       (17, 8, 25)       (17, 8, 25)         34            0\n",
      "        ReLu-25       (17, 8, 25)       (17, 8, 25)          0        3,400\n",
      "   MaxPool2d-26       (17, 8, 25)       (17, 4, 12)          0        3,264\n",
      "      Conv2d-27       (17, 4, 12)       (27, 4, 12)      4,131      198,288\n",
      " BatchNorm2d-28       (27, 4, 12)       (27, 4, 12)         54            0\n",
      "        ReLu-29       (27, 4, 12)       (27, 4, 12)          0        1,296\n",
      "      Conv2d-30       (27, 4, 12)       (27, 4, 12)      6,561      314,928\n",
      " BatchNorm2d-31       (27, 4, 12)       (27, 4, 12)         54            0\n",
      "        ReLu-32       (27, 4, 12)       (27, 4, 12)          0        1,296\n",
      "   MaxPool2d-33       (27, 4, 12)        (27, 2, 6)          0        1,296\n",
      "      Conv2d-34        (27, 2, 6)        (35, 2, 6)      8,505      102,060\n",
      " BatchNorm2d-35        (35, 2, 6)        (35, 2, 6)         70            0\n",
      "        ReLu-36        (35, 2, 6)        (35, 2, 6)          0          420\n",
      "      Conv2d-37        (35, 2, 6)        (88, 2, 6)     27,720      332,640\n",
      " BatchNorm2d-38        (88, 2, 6)        (88, 2, 6)        176            0\n",
      "        ReLu-39        (88, 2, 6)        (88, 2, 6)          0        1,056\n",
      "   MaxPool2d-40        (88, 2, 6)        (88, 1, 3)          0        1,056\n",
      "      Conv2d-41        (88, 1, 3)         (4, 1, 3)        352        1,056\n",
      " BatchNorm2d-42         (4, 1, 3)         (4, 1, 3)          8            0\n",
      "        ReLu-43         (4, 1, 3)         (4, 1, 3)          0           12\n",
      "   AvgPool2d-44         (4, 1, 3)         (4, 1, 1)          0           12\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 62,203\n",
      "Total FLOPs : 10,582,992\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.08\n",
      "Params size (MB): 0.24\n",
      "Total size (MB) : 0.31\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
