{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bf6d57-a4ca-466b-8573-c0136beedc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import glob;\n",
    "import random;\n",
    "import time;\n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "import json\n",
    "sys.path.append(os.getcwd());\n",
    "sys.path.append('../../');\n",
    "sys.path.append(os.path.abspath('../../../src/'));\n",
    "# sys.path.append(os.path.join(os.getcwd(), 'torch/resources'));\n",
    "import common.utils as U;\n",
    "import common.opts as opts;\n",
    "# import resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "import common.tlopts as tlopts\n",
    "# import resources.train_generator as train_generator;\n",
    "import argparse\n",
    "from itertools import repeat\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7689e377-b82a-49c3-ad0e-39c577601df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SharedLibs.config_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8275f2-c36a-4364-af02-50f1a95649af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8ca33aa-674b-4dd7-811d-7ef3b6837698",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_sec_input_len = 20150;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c39e16-406e-4d15-892b-d2253acc7e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_layers(in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "#     conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "#     nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "#     bn = nn.BatchNorm2d(out_channels);\n",
    "#     return conv, bn;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d912792-acf8-455f-b151-a239265a2d33",
   "metadata": {},
   "source": [
    "## define ACDNet Fundamental Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0a2923-8e53-4dc7-884d-2d00d079c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "#GetACDNetModel中的nclass不能改50以外的值，因為pretrain model本來的分類為50，載入後，下面的函式會再改動後面的分類。\n",
    "def GetACDNetModel(input_len=30225, nclass=50, sr=20000, channel_config=None):\n",
    "    net = ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b962632-05bd-4265-86ba-3fac7ea1b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "net  = GetACDNetModel(input_len=one_sec_input_len, nclass=4, sr=20000, channel_config=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92b3e4f5-16ce-40da-ad20-932fe55c3324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc.summary(net, (1,1,one_sec_input_len));"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecb5972a-6a20-41a4-96de-e1ce90f0b283",
   "metadata": {},
   "source": [
    "+----------------------------------------------------------------------------+\n",
    "+                           Pytorch Model Summary                            +\n",
    "------------------------------------------------------------------------------\n",
    "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
    "==============================================================================\n",
    "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
    "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
    "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
    "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
    "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
    "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
    "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
    "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
    "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
    " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
    "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
    "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
    "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
    " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
    "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
    "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
    " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
    "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
    "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
    "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
    " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
    "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
    "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
    " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
    "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
    "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
    "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
    " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
    "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
    "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
    " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
    "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
    "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
    "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
    " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
    "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
    "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
    " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
    "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
    "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
    "      Conv2d-41       (512, 2, 4)         (4, 2, 4)      2,048       16,384\n",
    " BatchNorm2d-42         (4, 2, 4)         (4, 2, 4)          8            0\n",
    "        ReLu-43         (4, 2, 4)         (4, 2, 4)          0           32\n",
    "   AvgPool2d-44         (4, 2, 4)         (4, 1, 1)          0           32\n",
    "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
    "      Linear-46            (1, 4)            (1, 4)         20           20\n",
    "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
    "==============================================================================\n",
    "Total Params: 4,709,204\n",
    "Total FLOPs : 544,230,312\n",
    "------------------------------------------------------------------------------\n",
    "Input size (MB) : 0.12\n",
    "Params size (MB): 17.96\n",
    "Total size (MB) : 18.08\n",
    "------------------------------------------------------------------------------m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb748e-ab69-4fe8-b773-474ef698f777",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58ade142-c4e4-48b9-8c71-2e28c1828137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples=None, labels=None, options=None, classes_dict=None):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        # print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = classes_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        # batchX, batchY = self.generate_batch_select_fixed_class(batchIndex)\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            # print(f\"nClasses:{self.opt.nClasses}, type of mapdict:{type(self.mapdict)}, type of label1:{type(label1)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        return sounds, labels;\n",
    "\n",
    "    def generate_batch_select_fixed_class(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        #two variables recording alarm and moaning sounds count\n",
    "        alarm_selected = 0;\n",
    "        moaning_selected = 0;\n",
    "        help_eng_selected = 0;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                # print(\"enter while true\")\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                lbl1_int = np.int16(label1);\n",
    "                lbl2_int = np.int16(label2);\n",
    "                # print(f\"label1:{label1} and label2:{label2}\")\n",
    "                # print(f\"label1:{type(label1)} and label2:{type(label2)}\")\n",
    "                if label1 != label2:\n",
    "                    # print(\"enter first layer if\");\n",
    "                    if (lbl1_int == 52 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int ==52):\n",
    "                        # print(\"enter 52 second layer if\");\n",
    "                        # if (alarm_selected < moaning_selected) or (alarm_selected == moaning_selected):\n",
    "                        if (alarm_selected == moaning_selected) and (alarm_selected == help_eng_selected):\n",
    "                            # print(\"enter 52 third layer if\");\n",
    "                            alarm_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 52\");\n",
    "                            break;\n",
    "                    if (lbl1_int == 56 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 56):\n",
    "                        # print(\"enter 56 second layer if\");\n",
    "                        # if (moaning_selected < alarm_selected) or (alarm_selected == moaning_selected):\n",
    "                        if (moaning_selected < alarm_selected) and (moaning_selected == help_eng_selected):\n",
    "                            # print(\"enter 56 third layer if\");\n",
    "                            moaning_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 56\");\n",
    "                            break;\n",
    "                    if (lbl1_int == 71 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 71):\n",
    "                        # print(\"enter 56 second layer if\");\n",
    "                        if (help_eng_selected < alarm_selected) and (help_eng_selected < moaning_selected):\n",
    "                            # print(\"enter 56 third layer if\");\n",
    "                            moaning_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 56\");\n",
    "                            break;\n",
    "            # print(f\"escape for loop\");\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random());\n",
    "            #######make wanted class mix ration above 0.5##########\n",
    "            # iLbl1 = np.int16(label1);\n",
    "            # iLbl2 = np.int16(label2);\n",
    "            # r = 1.0;\n",
    "            # p_ratio1 = 0.4\n",
    "            # p_ratio2 = 0.6\n",
    "            # while True:\n",
    "            #     r = np.array(random.random());\n",
    "            #     if r > p_ratio1 and iLbl1 != 99 :\n",
    "            #         break;\n",
    "            #     if r < p_ratio2 and iLbl2 != 99 :\n",
    "            #         break;\n",
    "            #######################End#######################\n",
    "            # print(f\"r:{r}, lbl1:{label1}, lbl2:{label2}\")  \n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            \n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        # print(f\"alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "        return sounds, labels;\n",
    "    \n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21d70d-b5b1-4711-aa59-d943d1222064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f76e6c-ae8b-483b-804f-0ffb83f3a893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
